"""
Kernel-Guided Fuzzing Benchmark - HKG (Hybrid Kernel-Guided) Edition
=====================================================================

æ ¸å¿ƒå¢å¼º:
1. **DispatcherSpace**: åŸºäº PyTorch Dispatcher æœºåˆ¶çš„çŠ¶æ€è¦†ç›–ç‡è®¡ç®—
   - ç†è®ºå…¨é›†: Dtype Ã— Layout Ã— Device Ã— MemoryFormat Ã— ...
   - å®é™…è¦†ç›–: è¿è¡Œæ—¶æˆåŠŸæ‰§è¡Œçš„å‚æ•°ç»„åˆ
   - è¦†ç›–ç‡: Numerator / Denominator

2. **HKGFuzzEngine**: æ··åˆçƒ­å¯åŠ¨ç­–ç•¥
   - Phase 1 (Warm-up): å‰ warmup_ratio è¿­ä»£ä½¿ç”¨ Random å¿«é€Ÿå¡«å…… Corpus
   - Phase 2 (Evolution): åˆ‡æ¢åˆ° Kernel-Guided æ¨¡å¼æ·±åº¦æ¢ç´¢

3. **CSVLogger**: æµå¼æ—¥å¿—å†™å…¥ï¼Œé¿å…å†…å­˜æº¢å‡º

4. **ä¿æŒå…¼å®¹**: ä¸ç°æœ‰ EnhancedFuzzer å®Œå…¨å…¼å®¹

Author: Research Team
Date: 2025-12-28
"""

import copy
import random
import configparser
import os
import json
import hashlib
import re
import pickle
import shutil
import csv
import itertools
from os.path import join
from pathlib import Path
from typing import Set, List, Dict, Tuple, Optional, Any, FrozenSet
from collections import defaultdict, deque
import matplotlib.pyplot as plt
import numpy as np
import time

# FreeFuzz imports
from classes.database import TorchDatabase
from classes.torch_api import TorchAPI, TorchArgument
from classes.torch_library import TorchLibrary
from classes.argument import Argument, ArgType
from constants.enum import OracleType


# =============================================================================
# DispatcherSpace (åˆ†å‘å™¨çŠ¶æ€ç©ºé—´) - æ ¸å¿ƒåˆ›æ–°
# =============================================================================

class DispatcherSpace:
    """
    Dispatcher State Coverage Calculator
    =====================================
    
    åŸºäº PyTorch Dispatcher æœºåˆ¶çš„çŠ¶æ€è¦†ç›–ç‡è®¡ç®—å™¨ã€‚
    
    æ ¸å¿ƒæ¦‚å¿µ:
    ---------
    PyTorch çš„ Dispatcher æ ¹æ®è¾“å…¥å¼ é‡çš„å¤šä¸ªç»´åº¦é€‰æ‹©å¯¹åº”çš„ Kernel å®ç°:
    - dtype: æ•°æ®ç±»å‹ (float32, int64, bool, etc.)
    - layout: å†…å­˜å¸ƒå±€ (strided, sparse_coo, sparse_csr, etc.)
    - device: è®¾å¤‡ç±»å‹ (cpu, cuda, etc.)
    - memory_format: å†…å­˜æ ¼å¼ (contiguous, channels_last, etc.)
    
    è¦†ç›–ç‡è®¡ç®—å…¬å¼:
    ----------------
    åˆ†æ¯ (Denominator): 
        ç†è®ºå…¨é›† = |dtype| Ã— |layout| Ã— |device| Ã— |memory_format| Ã— ...
        
    åˆ†å­ (Numerator):
        å®é™…æˆåŠŸæ‰§è¡Œçš„å‚æ•°ç»„åˆæ•°é‡ (å»é‡å)
        
    è¦†ç›–ç‡ = Numerator / Denominator Ã— 100%
    
    è®¾è®¡ç›®æ ‡:
    ---------
    ä¼ ç»Ÿçš„ä»£ç è¡Œè¦†ç›–ç‡ (Line Coverage) å¯¹äºæ·±åº¦å­¦ä¹ æ¡†æ¶æµ‹è¯•å¹¶ä¸å¯é ï¼Œå› ä¸º:
    1. åŒä¸€è¡Œä»£ç å¯èƒ½è¢«ä¸åŒçš„ dtype/device ç»„åˆè§¦å‘
    2. Kernel é€‰æ‹©é€»è¾‘æ˜¯è¿è¡Œæ—¶åŠ¨æ€å†³å®šçš„
    
    Dispatcher State Coverage é€šè¿‡é‡åŒ–å‚æ•°ç»„åˆçš„è¦†ç›–æƒ…å†µï¼Œ
    èƒ½æ›´å‡†ç¡®åœ°åæ˜ æµ‹è¯•çš„"é€»è¾‘å®Œå¤‡æ€§"ã€‚
    
    Example:
    --------
    >>> space = DispatcherSpace()
    >>> space.register_api("torch.add", {
    ...     "dtype": ["float32", "float64", "int32", "int64"],
    ...     "device": ["cpu", "cuda"],
    ...     "layout": ["strided", "sparse_coo"]
    ... })
    >>> # ç†è®ºå…¨é›† = 4 Ã— 2 Ã— 2 = 16 ç§ç»„åˆ
    >>> space.record_hit("torch.add", {"dtype": "float32", "device": "cpu", "layout": "strided"})
    >>> print(space.get_coverage("torch.add"))  # è¾“å‡º: 6.25% (1/16)
    """
    
    # PyTorch æ”¯æŒçš„æ•°æ®ç±»å‹ (ä¸ TorchArgument._dtypes å¯¹åº”)
    DEFAULT_DTYPES = [
        "int8", "int16", "int32", "int64",
        "uint8",
        "float16", "float32", "float64", "bfloat16",
        "complex64", "complex128",
        "bool"
    ]
    
    # PyTorch æ”¯æŒçš„å†…å­˜å¸ƒå±€
    DEFAULT_LAYOUTS = [
        "strided",        # æ ‡å‡†å¯†é›†å¼ é‡
        "sparse_coo",     # COO ç¨€ç–æ ¼å¼
        "sparse_csr",     # CSR ç¨€ç–æ ¼å¼
        # "sparse_csc",   # CSC (è¾ƒæ–°ç‰ˆæœ¬)
    ]
    
    # PyTorch æ”¯æŒçš„è®¾å¤‡ç±»å‹
    DEFAULT_DEVICES = [
        "cpu",
        "cuda"
    ]
    
    # PyTorch æ”¯æŒçš„å†…å­˜æ ¼å¼
    DEFAULT_MEMORY_FORMATS = [
        "contiguous_format",
        "channels_last",
        "channels_last_3d",
        "preserve_format"
    ]
    
    def __init__(self, name: str = "default"):
        """
        åˆå§‹åŒ– DispatcherSpace
        
        Args:
            name: ç©ºé—´åç§°ï¼Œç”¨äºåŒºåˆ†ä¸åŒçš„æµ‹è¯•åœºæ™¯
        """
        self.name = name
        
        # API -> ç»´åº¦å®šä¹‰
        # æ ¼å¼: {api_name: {"dtype": [...], "device": [...], ...}}
        self.api_dimensions: Dict[str, Dict[str, List[str]]] = {}
        
        # API -> ç†è®ºå…¨é›†å¤§å° (åˆ†æ¯)
        # æ ¼å¼: {api_name: int}
        self.api_denominator: Dict[str, int] = {}
        
        # API -> å·²è¦†ç›–çš„çŠ¶æ€ç»„åˆ (åˆ†å­ï¼Œä½¿ç”¨ frozenset å­˜å‚¨ä¾¿äºå»é‡)
        # æ ¼å¼: {api_name: Set[FrozenSet[Tuple[str, str]]]}
        # æ¯ä¸ªç»„åˆè¡¨ç¤ºä¸º: frozenset({("dtype", "float32"), ("device", "cpu"), ...})
        self.api_hits: Dict[str, Set[FrozenSet[Tuple[str, str]]]] = defaultdict(set)
        
        # å…¨å±€ç»Ÿè®¡
        self.total_record_calls = 0
        self.total_unique_hits = 0
        
        # å†å²è®°å½• (iteration, coverage_percentage)
        self.coverage_history: List[Tuple[int, float]] = []
        
    def register_api(self, api_name: str, dimensions: Optional[Dict[str, List[str]]] = None):
        """
        æ³¨å†Œä¸€ä¸ª API å¹¶å®šä¹‰å…¶çŠ¶æ€ç©ºé—´ç»´åº¦
        
        Args:
            api_name: API åç§°ï¼Œå¦‚ "torch.add"
            dimensions: ç»´åº¦å®šä¹‰ï¼Œæ ¼å¼: {"dtype": [...], "device": [...], ...}
                        å¦‚æœä¸º Noneï¼Œåˆ™ä½¿ç”¨é»˜è®¤ç»´åº¦
        
        è®¡ç®—å…¬å¼:
            Denominator = |dim1| Ã— |dim2| Ã— ... Ã— |dimN|
            
        Example:
            register_api("torch.nn.Conv2d", {
                "dtype": ["float16", "float32", "float64"],
                "device": ["cpu", "cuda"],
                "layout": ["strided"]
            })
            # Denominator = 3 Ã— 2 Ã— 1 = 6
        """
        if dimensions is None:
            # ä½¿ç”¨ç®€åŒ–çš„é»˜è®¤ç»´åº¦ (é¿å…ç»„åˆçˆ†ç‚¸)
            dimensions = {
                "dtype": self.DEFAULT_DTYPES,
                "device": self.DEFAULT_DEVICES,
            }
        
        self.api_dimensions[api_name] = dimensions
        
        # è®¡ç®—åˆ†æ¯ (ç†è®ºå…¨é›†å¤§å°)
        # å…¬å¼: Denominator = âˆ|dim_i|
        denominator = 1
        for dim_name, dim_values in dimensions.items():
            denominator *= len(dim_values)
        
        self.api_denominator[api_name] = denominator
        
        print(f"[DispatcherSpace] Registered API: {api_name}")
        print(f"  Dimensions: {list(dimensions.keys())}")
        print(f"  Theoretical Space (Denominator): {denominator}")
    
    def _extract_state_from_args(self, api: TorchAPI) -> Dict[str, str]:
        """
        ä» TorchAPI å¯¹è±¡ä¸­æå–å½“å‰çš„çŠ¶æ€ (dtype, device, layout, etc.)
        
        æ ¸å¿ƒé€»è¾‘:
        1. éå†æ‰€æœ‰å‚æ•°
        2. å¯¹äº TORCH_TENSOR ç±»å‹ï¼Œæå– dtype, shape ç­‰ä¿¡æ¯
        3. å¯¹äº TORCH_DTYPE ç±»å‹ï¼Œç›´æ¥æå– dtype
        4. å¯¹äº TORCH_OBJECT ç±»å‹ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯ memory_format
        
        Returns:
            çŠ¶æ€å­—å…¸ï¼Œå¦‚ {"dtype": "float32", "device": "cpu", ...}
        """
        state = {
            "dtype": "unknown",
            "device": "cpu",  # é»˜è®¤ CPU
            "layout": "strided",  # é»˜è®¤ strided
        }
        
        for param_name, arg in api.args.items():
            if arg is None:
                continue
            
            # å¤„ç† Tensor å‚æ•°
            if hasattr(arg, 'type') and arg.type == ArgType.TORCH_TENSOR:
                if hasattr(arg, 'dtype') and arg.dtype is not None:
                    # æå– dtype åç§°ï¼Œå¦‚ "torch.float32" -> "float32"
                    dtype_str = str(arg.dtype)
                    if 'torch.' in dtype_str:
                        dtype_str = dtype_str.split('.')[-1]
                    state["dtype"] = dtype_str
                
                # æ£€æŸ¥ shape æ¥æ¨æ–­å¯èƒ½çš„ layout
                if hasattr(arg, 'shape') and arg.shape:
                    # ç®€åŒ–å¤„ç†ï¼šç›®å‰åªè€ƒè™‘ strided
                    pass
            
            # å¤„ç†æ˜¾å¼çš„ dtype å‚æ•°
            elif hasattr(arg, 'type') and arg.type == ArgType.TORCH_DTYPE:
                if hasattr(arg, 'value') and arg.value is not None:
                    dtype_str = str(arg.value)
                    if 'torch.' in dtype_str:
                        dtype_str = dtype_str.split('.')[-1]
                    state["dtype"] = dtype_str
            
            # å¤„ç† memory_format ç­‰å¯¹è±¡
            elif hasattr(arg, 'type') and arg.type == ArgType.TORCH_OBJECT:
                if hasattr(arg, 'value'):
                    val_str = str(arg.value)
                    if 'memory_format' in val_str.lower():
                        # æå– memory_format ç±»å‹
                        if 'channels_last' in val_str:
                            state["memory_format"] = "channels_last"
                        elif 'contiguous' in val_str:
                            state["memory_format"] = "contiguous_format"
        
        return state
    
    def record_hit(self, api_name: str, api: Optional[TorchAPI] = None, 
                   state_dict: Optional[Dict[str, str]] = None,
                   iteration: Optional[int] = None) -> bool:
        """
        è®°å½•ä¸€æ¬¡æˆåŠŸçš„å‚æ•°ç»„åˆ
        
        Args:
            api_name: API åç§°
            api: TorchAPI å¯¹è±¡ï¼Œå¦‚æœæä¾›åˆ™è‡ªåŠ¨æå–çŠ¶æ€
            state_dict: ç›´æ¥æä¾›çš„çŠ¶æ€å­—å…¸ï¼Œå¦‚ {"dtype": "float32", "device": "cpu"}
            iteration: å½“å‰è¿­ä»£æ¬¡æ•°ï¼Œç”¨äºè®°å½•å†å²
        
        Returns:
            bool: æ˜¯å¦æ˜¯ä¸€ä¸ªæ–°çš„ç»„åˆ (True = æ–°å‘ç°ï¼ŒFalse = å·²å­˜åœ¨)
        
        Note:
            å¦‚æœåŒæ—¶æä¾› api å’Œ state_dictï¼Œä¼˜å…ˆä½¿ç”¨ state_dict
        """
        self.total_record_calls += 1
        
        # ç¡®ä¿ API å·²æ³¨å†Œ
        if api_name not in self.api_dimensions:
            self.register_api(api_name)
        
        # æå–çŠ¶æ€
        if state_dict is None and api is not None:
            state_dict = self._extract_state_from_args(api)
        elif state_dict is None:
            state_dict = {"dtype": "unknown", "device": "cpu"}
        
        # è¿‡æ»¤åªä¿ç•™å·²å®šä¹‰çš„ç»´åº¦
        dimensions = self.api_dimensions[api_name]
        filtered_state = {}
        for dim_name in dimensions.keys():
            if dim_name in state_dict:
                value = state_dict[dim_name]
                # éªŒè¯å€¼æ˜¯å¦åœ¨å®šä¹‰çš„èŒƒå›´å†…
                if value in dimensions[dim_name]:
                    filtered_state[dim_name] = value
                else:
                    # å€¼ä¸åœ¨èŒƒå›´å†…ï¼Œä½¿ç”¨ "other" æ ‡è®°
                    filtered_state[dim_name] = "other"
            else:
                filtered_state[dim_name] = "unknown"
        
        # è½¬æ¢ä¸º frozenset ä¾¿äºå“ˆå¸Œå’Œå»é‡
        state_key = frozenset(filtered_state.items())
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°ç»„åˆ
        is_new = state_key not in self.api_hits[api_name]
        
        if is_new:
            self.api_hits[api_name].add(state_key)
            self.total_unique_hits += 1
        
        # è®°å½•å†å²
        if iteration is not None:
            current_coverage = self.get_overall_coverage()
            self.coverage_history.append((iteration, current_coverage))
        
        return is_new
    
    def get_coverage(self, api_name: str) -> Tuple[int, int, float]:
        """
        è·å–æŒ‡å®š API çš„è¦†ç›–ç‡
        
        Returns:
            (numerator, denominator, percentage)
            numerator: å·²è¦†ç›–çš„ç»„åˆæ•°
            denominator: ç†è®ºå…¨é›†å¤§å°
            percentage: è¦†ç›–ç‡ç™¾åˆ†æ¯”
        """
        if api_name not in self.api_dimensions:
            return (0, 0, 0.0)
        
        numerator = len(self.api_hits[api_name])
        denominator = self.api_denominator[api_name]
        percentage = (numerator / denominator * 100) if denominator > 0 else 0.0
        
        return (numerator, denominator, percentage)
    
    def get_overall_coverage(self) -> float:
        """
        è·å–æ‰€æœ‰å·²æ³¨å†Œ API çš„å¹³å‡è¦†ç›–ç‡
        
        è®¡ç®—å…¬å¼:
            Overall = (âˆ‘ Numerator_i) / (âˆ‘ Denominator_i) Ã— 100%
        """
        total_numerator = 0
        total_denominator = 0
        
        for api_name in self.api_dimensions.keys():
            total_numerator += len(self.api_hits[api_name])
            total_denominator += self.api_denominator[api_name]
        
        if total_denominator == 0:
            return 0.0
        
        return (total_numerator / total_denominator) * 100
    
    def get_uncovered_combinations(self, api_name: str, max_show: int = 10) -> List[Dict[str, str]]:
        """
        è·å–æœªè¦†ç›–çš„å‚æ•°ç»„åˆ
        
        Args:
            api_name: API åç§°
            max_show: æœ€å¤šè¿”å›å¤šå°‘ä¸ªç»„åˆ
        
        Returns:
            æœªè¦†ç›–çš„ç»„åˆåˆ—è¡¨
        """
        if api_name not in self.api_dimensions:
            return []
        
        dimensions = self.api_dimensions[api_name]
        covered = self.api_hits[api_name]
        
        # ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„ç»„åˆ
        dim_names = list(dimensions.keys())
        dim_values = [dimensions[name] for name in dim_names]
        
        uncovered = []
        for combo in itertools.product(*dim_values):
            state_dict = dict(zip(dim_names, combo))
            state_key = frozenset(state_dict.items())
            
            if state_key not in covered:
                uncovered.append(state_dict)
                if len(uncovered) >= max_show:
                    break
        
        return uncovered
    
    def print_summary(self):
        """
        æ‰“å°è¯¦ç»†çš„è¦†ç›–ç‡æŠ¥å‘Š
        """
        print(f"\n{'='*70}")
        print(f"ğŸ“Š DISPATCHER STATE COVERAGE REPORT: {self.name}")
        print(f"{'='*70}")
        
        print(f"\nğŸ“ˆ Overall Statistics:")
        print(f"  Total record_hit calls: {self.total_record_calls}")
        print(f"  Unique combinations discovered: {self.total_unique_hits}")
        print(f"  Overall Coverage: {self.get_overall_coverage():.2f}%")
        
        print(f"\nğŸ“‹ Per-API Coverage:")
        print(f"  {'API Name':<40} {'Covered':>8} {'Total':>8} {'Coverage':>10}")
        print(f"  {'-'*66}")
        
        for api_name in sorted(self.api_dimensions.keys()):
            num, denom, pct = self.get_coverage(api_name)
            print(f"  {api_name:<40} {num:>8} {denom:>8} {pct:>9.2f}%")
        
        # æ˜¾ç¤ºæœªè¦†ç›–çš„ç»„åˆ (ä»…é™ç¬¬ä¸€ä¸ª API)
        if self.api_dimensions:
            first_api = list(self.api_dimensions.keys())[0]
            uncovered = self.get_uncovered_combinations(first_api, max_show=5)
            
            if uncovered:
                print(f"\nâŒ Sample Uncovered Combinations for {first_api}:")
                for combo in uncovered:
                    combo_str = ", ".join([f"{k}={v}" for k, v in combo.items()])
                    print(f"    - {combo_str}")
        
        print(f"\n{'='*70}\n")
    
    def to_dict(self) -> Dict:
        """å¯¼å‡ºä¸ºå­—å…¸æ ¼å¼ï¼Œä¾¿äº JSON åºåˆ—åŒ–"""
        result = {
            "name": self.name,
            "total_record_calls": self.total_record_calls,
            "total_unique_hits": self.total_unique_hits,
            "overall_coverage": self.get_overall_coverage(),
            "api_coverage": {}
        }
        
        for api_name in self.api_dimensions.keys():
            num, denom, pct = self.get_coverage(api_name)
            result["api_coverage"][api_name] = {
                "numerator": num,
                "denominator": denom,
                "percentage": pct
            }
        
        return result


# =============================================================================
# CSVLogger (æµå¼æ—¥å¿—å†™å…¥å™¨)
# =============================================================================

class CSVLogger:
    """
    æµå¼ CSV æ—¥å¿—å†™å…¥å™¨
    ===================
    
    ä¼˜åŠ¿:
    - æµå¼å†™å…¥ï¼Œé¿å…å†…å­˜æº¢å‡º
    - æ”¯æŒæ–­ç‚¹ç»­å†™
    - è‡ªåŠ¨ flush ç¡®ä¿æ•°æ®å®‰å…¨
    
    åˆ—å®šä¹‰:
    - iteration: è¿­ä»£æ¬¡æ•°
    - timestamp: Unix æ—¶é—´æˆ³
    - phase: warm-up / evolution
    - source: random / corpus / exploration
    - strategy: å½“å‰ä½¿ç”¨çš„ç­–ç•¥
    - valid: æ˜¯å¦æ‰§è¡ŒæˆåŠŸ
    - new_kernels: æ–°å‘ç°çš„ kernel æ•°é‡
    - total_kernels: ç´¯è®¡ kernel æ•°é‡
    - corpus_size: Corpus å¤§å°
    - dispatcher_coverage: Dispatcher çŠ¶æ€è¦†ç›–ç‡
    - bug_count: ç´¯è®¡ Bug æ•°é‡
    """
    
    COLUMNS = [
        "iteration", "timestamp", "phase", "source", "strategy",
        "valid", "new_kernels", "total_kernels", "corpus_size",
        "dispatcher_coverage", "bug_count", "features"
    ]
    
    def __init__(self, output_file: str, strategy: str = "hkg"):
        """
        åˆå§‹åŒ– CSVLogger
        
        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            strategy: ç­–ç•¥åç§°
        """
        self.output_file = output_file
        self.strategy = strategy
        self.row_count = 0
        
        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œè¿½åŠ æ¨¡å¼ï¼›å¦åˆ™åˆ›å»ºå¹¶å†™å…¥è¡¨å¤´
        file_exists = os.path.exists(output_file)
        
        self.file_handle = open(output_file, 'a', newline='', encoding='utf-8')
        self.writer = csv.DictWriter(self.file_handle, fieldnames=self.COLUMNS)
        
        if not file_exists:
            self.writer.writeheader()
            self.file_handle.flush()
        
        print(f"[CSVLogger] Logging to: {output_file}")
    
    def log(self, 
            iteration: int,
            phase: str,
            source: str,
            valid: bool,
            new_kernels: int = 0,
            total_kernels: int = 0,
            corpus_size: int = 0,
            dispatcher_coverage: float = 0.0,
            bug_count: int = 0,
            features: str = ""):
        """
        è®°å½•ä¸€è¡Œæ—¥å¿—
        """
        row = {
            "iteration": iteration,
            "timestamp": time.time(),
            "phase": phase,
            "source": source,
            "strategy": self.strategy,
            "valid": valid,
            "new_kernels": new_kernels,
            "total_kernels": total_kernels,
            "corpus_size": corpus_size,
            "dispatcher_coverage": round(dispatcher_coverage, 4),
            "bug_count": bug_count,
            "features": features
        }
        
        self.writer.writerow(row)
        self.row_count += 1
        
        # æ¯ 100 è¡Œ flush ä¸€æ¬¡
        if self.row_count % 100 == 0:
            self.file_handle.flush()
    
    def close(self):
        """å…³é—­æ–‡ä»¶å¥æŸ„"""
        if self.file_handle:
            self.file_handle.flush()
            self.file_handle.close()
    
    def __del__(self):
        self.close()


# =============================================================================
# ä»¥ä¸‹æ˜¯ä»åŸå§‹ benchmark_full_oracle.py å¤åˆ¶çš„è¾…åŠ©ç±»
# (ä¿æŒåŸæœ‰åŠŸèƒ½ä¸å˜)
# =============================================================================

class Speedometer:
    """é€Ÿåº¦ç›‘æ§ - åŠæ—¶å‘ç°æ€§èƒ½é—®é¢˜"""
    def __init__(self, window_size: int = 100, slow_threshold: float = 0.5):
        self.window_size = window_size
        self.slow_threshold = slow_threshold
        self.timestamps = deque(maxlen=window_size)
        self.start_time = None
        self.total_iterations = 0
        self.slow_warnings = 0
    
    def start(self):
        self.start_time = time.time()
        self.timestamps.append(self.start_time)
    
    def tick(self):
        self.total_iterations += 1
        self.timestamps.append(time.time())
    
    def get_speed(self) -> float:
        if len(self.timestamps) < 2:
            return 0.0
        elapsed = self.timestamps[-1] - self.timestamps[0]
        return (len(self.timestamps) - 1) / elapsed if elapsed > 0 else 0.0
    
    def get_average_speed(self) -> float:
        if not self.start_time or self.total_iterations == 0:
            return 0.0
        elapsed = time.time() - self.start_time
        return self.total_iterations / elapsed if elapsed > 0 else 0.0
    
    def estimate_remaining_time(self, current_iter: int, max_iter: int) -> float:
        avg_speed = self.get_average_speed()
        if avg_speed == 0:
            return float('inf')
        return (max_iter - current_iter) / avg_speed
    
    def format_time(self, seconds: float) -> str:
        if seconds == float('inf'):
            return "Unknown"
        hours, minutes, secs = int(seconds // 3600), int((seconds % 3600) // 60), int(seconds % 60)
        if hours > 0:
            return f"{hours}h {minutes}m"
        elif minutes > 0:
            return f"{minutes}m {secs}s"
        return f"{secs}s"
    
    def get_status(self, current_iter: int, max_iter: int) -> str:
        current_speed = self.get_speed()
        avg_speed = self.get_average_speed()
        remaining = self.estimate_remaining_time(current_iter, max_iter)
        elapsed = time.time() - self.start_time if self.start_time else 0
        return (f"{current_speed:.2f} it/s (avg: {avg_speed:.2f}) | "
                f"Elapsed: {self.format_time(elapsed)} | ETA: {self.format_time(remaining)}")


class DiskGuard:
    """ç£ç›˜ç©ºé—´ç›‘æ§ - é˜²æ­¢çˆ†æ»¡å´©æºƒ"""
    def __init__(self, output_dir: str, min_free_gb: float = 1.0, auto_cleanup: bool = True):
        self.output_dir = Path(output_dir)
        self.min_free_gb = min_free_gb
        self.auto_cleanup = auto_cleanup
        self.warnings = 0
        self.cleanups = 0
    
    def get_disk_usage(self) -> Tuple[float, float, float]:
        stat = shutil.disk_usage(self.output_dir)
        return (stat.total / (1024**3), stat.used / (1024**3), stat.free / (1024**3))
    
    def check_and_cleanup(self) -> Tuple[bool, str]:
        total, used, free = self.get_disk_usage()
        if free < self.min_free_gb:
            self.warnings += 1
            if self.auto_cleanup:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                count = 0
                for temp_file in self.output_dir.rglob("temp.py"):
                    try:
                        temp_file.unlink()
                        count += 1
                    except:
                        pass
                if count > 0:
                    self.cleanups += 1
                total, used, free = self.get_disk_usage()
            return free < self.min_free_gb, f"Disk: {free:.2f} GB free"
        return False, ""
    
    def get_status(self) -> str:
        total, used, free = self.get_disk_usage()
        return f"{free:.2f} GB free ({used/total*100:.1f}% used)"


class OutlierFilter:
    """å¼‚å¸¸å‚æ•°è¿‡æ»¤ - é˜²æ­¢ OOM"""
    def __init__(self, max_elements: int = int(1e8)):
        self.max_elements = max_elements
        self.total_checks = 0
        self.filtered_count = 0
    
    def check_api(self, api) -> Tuple[bool, Optional[str]]:
        self.total_checks += 1
        for param_name, arg in api.args.items():
            if arg is None:
                continue
            if hasattr(arg, 'type') and arg.type == ArgType.TORCH_TENSOR:
                if hasattr(arg, 'shape') and arg.shape:
                    num_elements = 1
                    for dim in arg.shape:
                        num_elements *= dim
                    if num_elements > self.max_elements:
                        self.filtered_count += 1
                        return True, f"Too many elements: {num_elements}"
        return False, None
    
    def get_status(self) -> str:
        rate = (self.filtered_count / self.total_checks * 100) if self.total_checks > 0 else 0
        return f"{self.filtered_count}/{self.total_checks} filtered ({rate:.1f}%)"


class EvolutionaryCorpus:
    """è¿›åŒ–ç§å­æ± """
    
    def __init__(self, max_size: int = 100):
        self.corpus: List[TorchAPI] = []
        self.max_size = max_size
        # è®°å½•æ¯ä¸ªç§å­å‘ç°çš„ kernel æ•°é‡ï¼Œç”¨äºä¼˜å…ˆé€‰æ‹©
        self.seed_scores: List[int] = []
    
    def add_seed(self, api: TorchAPI, discovered_kernels: Set[str]):
        if len(discovered_kernels) == 0:
            return
        
        seed_copy = copy.deepcopy(api)
        self.corpus.append(seed_copy)
        self.seed_scores.append(len(discovered_kernels))
        
        if len(self.corpus) > self.max_size:
            self.corpus.pop(0)
            self.seed_scores.pop(0)
    
    def select_parent(self) -> Optional[TorchAPI]:
        """åŠ æƒéšæœºé€‰æ‹©ï¼Œä¼˜å…ˆé€‰æ‹©å‘ç°æ›´å¤š kernel çš„ç§å­"""
        if not self.corpus:
            return None
        
        # ä½¿ç”¨åˆ†æ•°ä½œä¸ºæƒé‡
        total_score = sum(self.seed_scores) or 1
        probs = [s / total_score for s in self.seed_scores]
        
        idx = np.random.choice(len(self.corpus), p=probs)
        return self.corpus[idx]
    
    def size(self) -> int:
        return len(self.corpus)


class EnhancedCoverageTracker:
    """è¦†ç›–ç‡è¿½è¸ªå™¨"""
    
    def __init__(self, name: str):
        self.name = name
        self.all_kernels: Set[str] = set()
        self.kernel_provenance: Dict[str, int] = {}
        self.history: List[Tuple[int, int]] = []
        self.new_kernel_iterations: List[int] = []
    
    def update(self, new_kernels: Set[str], iteration: int) -> int:
        """æ›´æ–°è¦†ç›–ç‡ï¼Œè¿”å›æ–°å‘ç°çš„ kernel æ•°é‡"""
        if not isinstance(new_kernels, set):
            new_kernels = set(new_kernels) if new_kernels else set()
        
        fresh = new_kernels - self.all_kernels
        
        if fresh:
            for kernel in fresh:
                self.kernel_provenance[kernel] = iteration
            self.all_kernels.update(fresh)
            self.new_kernel_iterations.append(iteration)
        
        self.history.append((iteration, len(self.all_kernels)))
        return len(fresh)
    
    def get_total(self) -> int:
        return len(self.all_kernels)


class BugTracker:
    """Bug è¿½è¸ªå™¨"""
    def __init__(self, name: str, output_dir: str):
        self.name = name
        self.output_dir = output_dir
        self.bugs = {"crash": [], "cuda": [], "precision": []}
        self.bug_files = {"crash": set(), "cuda": set(), "precision": set()}
        
    def scan_bugs(self):
        oracle_map = {"crash": "crash-oracle", "cuda": "cuda-oracle", "precision": "precision-oracle"}
        for bug_type, oracle_name in oracle_map.items():
            bug_dir = join(self.output_dir, oracle_name, "potential-bug")
            if not os.path.exists(bug_dir):
                continue
            for root, _, files in os.walk(bug_dir):
                for f in files:
                    if not f.endswith('.py'): continue
                    file_path = join(root, f)
                    if file_path not in self.bug_files[bug_type]:
                        self.bug_files[bug_type].add(file_path)
                        self.bugs[bug_type].append((len(self.bugs[bug_type]), "unknown", file_path))

    def get_total_bugs(self) -> int:
        return sum(len(bugs) for bugs in self.bugs.values())
    
    def get_bugs_by_type(self, bug_type: str) -> int:
        return len(self.bugs.get(bug_type, []))


# =============================================================================
# Mutation Patchers (ä¿æŒä¸åŸå§‹å®ç°å…¼å®¹)
# =============================================================================

_ORIGINAL_DO_SELECT_FROM_DB = None
_POISON_ORIGINAL_FLOAT = None
_POISON_ORIGINAL_INT = None

class ProbabilityPatcher:
    """å°†æ•°æ®åº“é‡‡æ ·æ¦‚ç‡ä» 20% æå‡åˆ° 50%"""
    
    @staticmethod
    def patch_high_db_probability():
        global _ORIGINAL_DO_SELECT_FROM_DB
        try:
            import utils.probability as prob_module
            _ORIGINAL_DO_SELECT_FROM_DB = prob_module.do_select_from_db
            
            def high_db_select() -> bool:
                from numpy.random import rand
                return rand() < 0.5
            
            prob_module.do_select_from_db = high_db_select
            print("[Patch] âœ… Database sampling: 20% â†’ 50%")
        except ImportError:
            print("[Patch] âš ï¸ utils.probability not found, skipping")
    
    @staticmethod
    def restore():
        global _ORIGINAL_DO_SELECT_FROM_DB
        if _ORIGINAL_DO_SELECT_FROM_DB:
            try:
                import utils.probability as prob_module
                prob_module.do_select_from_db = _ORIGINAL_DO_SELECT_FROM_DB
                print("[Patch] ğŸ”„ Database sampling restored")
            except ImportError:
                pass


class PoisonPatcher:
    """
    ç‹¬ç«‹çš„æŠ•æ¯’è¡¥ä¸ - å¯¹ Random å’Œ Guided éƒ½ç”Ÿæ•ˆ
    """
    
    @staticmethod
    def patch():
        global _POISON_ORIGINAL_FLOAT, _POISON_ORIGINAL_INT
        
        _POISON_ORIGINAL_FLOAT = Argument.mutate_float_value
        _POISON_ORIGINAL_INT = Argument.mutate_int_value
        
        def poison_float_mutation(self, value) -> float:
            from numpy.random import rand, choice
            
            roll = rand()
            
            if roll < 0.05:
                return choice([float('inf'), float('-inf')])
            elif roll < 0.10:
                return float('nan')
            elif roll < 0.20:
                return choice([1e20, -1e20, 1e-10, -1e-10])
            elif roll < 0.50:
                return choice(Argument._float_values)
            else:
                return value + (rand() - 0.5) * 8.0
        
        def poison_int_mutation(self, value, _min=None, _max=None) -> int:
            from numpy.random import rand, choice, randint
            
            roll = rand()
            
            if roll < 0.10:
                new_value = choice([0, -1, 1])
            elif roll < 0.20:
                new_value = choice([-999, 999, -2147483648, 2147483647])
            elif roll < 0.30:
                new_value = choice([-2, -3, 256, 512, 7, 11, 0])
            elif roll < 0.60:
                new_value = choice(Argument._int_values)
            else:
                new_value = value + randint(-8, 9)
            
            if _min is not None and new_value < _min and new_value not in [-1, 0]:
                new_value = max(_min, new_value)
            if _max is not None and new_value > _max:
                new_value = min(_max, new_value)
            
            return int(new_value)
        
        Argument.mutate_float_value = poison_float_mutation 
        Argument.mutate_int_value = poison_int_mutation
        print("[Patch] ğŸ§ª Poison Injection enabled")
    
    @staticmethod
    def restore():
        global _POISON_ORIGINAL_FLOAT, _POISON_ORIGINAL_INT
        if _POISON_ORIGINAL_FLOAT:
            Argument.mutate_float_value = _POISON_ORIGINAL_FLOAT
        if _POISON_ORIGINAL_INT:
            Argument.mutate_int_value = _POISON_ORIGINAL_INT
        print("[Patch] ğŸ”„ Poison Injection restored")


# =============================================================================
# ğŸ”¥ HKGFuzzEngine - æ··åˆçƒ­å¯åŠ¨ Fuzzer
# =============================================================================

class HKGFuzzEngine:
    """
    Hybrid Kernel-Guided Fuzz Engine
    =================================
    
    æ ¸å¿ƒè®ºç‚¹:
    ---------
    1. Random Fuzzing (FreeFuzz): ååé‡å¤§ï¼Œå¿«é€Ÿè¦†ç›–æµ…å±‚çŠ¶æ€ï¼Œä½†å®¹æ˜“é¥±å’Œ
    2. Kernel-Guided Fuzzing: ç©¿é€åŠ›å¼ºï¼Œè¦†ç›–æ·±å±‚çŠ¶æ€ï¼Œä½†å†·å¯åŠ¨æ…¢
    3. æœ€ä¼˜ç­–ç•¥: "Warm-up with Random" â†’ "Evolve with Kernel-Guided"
    
    æ‰§è¡Œæµç¨‹:
    ---------
    Phase 1 (Warm-up):
        - å‰ warmup_ratio (é»˜è®¤ 10%) çš„è¿­ä»£
        - å¼ºåˆ¶ä½¿ç”¨ Random ç­–ç•¥
        - ç›®æ ‡: å¿«é€Ÿå¡«æ»¡ Corpusï¼Œå¿«é€Ÿç‚¹äº® DispatcherSpace çš„æµ…å±‚æ ¼å­
    
    Phase 2 (Evolution):
        - åˆ‡æ¢åˆ° Kernel-Guided æ¨¡å¼
        - Îµ-greedy: 90% åˆ©ç”¨ + 10% æ¢ç´¢
        - ç»“æ„åŒ–æŠ•æ¯’: NaN, Inf, è¾¹ç•Œå€¼
        - åŠ¨æ€è°ƒæ•´: åœæ»æ—¶æ‰©å¤§æœç´¢èŒƒå›´
    
    åº¦é‡:
    -----
    - Kernel Coverage: è§¦å‘çš„ CUDA kernel æ•°é‡
    - Dispatcher State Coverage: åˆ†å‘å™¨çŠ¶æ€è¦†ç›–ç‡ (åˆ›æ–°ç‚¹)
    - Bug Count: å‘ç°çš„ Bug æ•°é‡
    """
    
    def __init__(self,
                 api_name: str,
                 output_dir: str,
                 warmup_ratio: float = 0.1,
                 use_all_oracles: bool = True,
                 enable_dispatcher_space: bool = True,
                 enable_csv_logging: bool = True,
                 diff_bound: float = 1e-5):
        """
        åˆå§‹åŒ– HKGFuzzEngine
        
        Args:
            api_name: è¦æµ‹è¯•çš„ API åç§°ï¼Œå¦‚ "torch.nn.LSTM"
            output_dir: è¾“å‡ºç›®å½•
            warmup_ratio: çƒ­å¯åŠ¨é˜¶æ®µçš„è¿­ä»£æ¯”ä¾‹ï¼Œé»˜è®¤ 10%
            use_all_oracles: æ˜¯å¦ä½¿ç”¨æ‰€æœ‰ Oracle (CRASH + CUDA + PRECISION)
            enable_dispatcher_space: æ˜¯å¦å¯ç”¨ Dispatcher çŠ¶æ€è¦†ç›–ç‡è®¡ç®—
            enable_csv_logging: æ˜¯å¦å¯ç”¨ CSV æ—¥å¿—
            diff_bound: ç²¾åº¦å®¹å·®
        """
        self.api_name = api_name
        self.output_dir = output_dir
        self.warmup_ratio = warmup_ratio
        self.use_all_oracles = use_all_oracles
        self.enable_dispatcher_space = enable_dispatcher_space
        self.diff_bound = diff_bound
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # åˆå§‹åŒ– Library
        self.library = TorchLibrary(output_dir, diff_bound=diff_bound)
        
        # Oracle åˆ—è¡¨
        if use_all_oracles:
            self.oracles = [OracleType.CRASH, OracleType.CUDA, OracleType.PRECISION]
        else:
            self.oracles = [OracleType.CRASH]
        
        # Coverage Tracker
        self.coverage = EnhancedCoverageTracker("HKG")
        
        # Bug Tracker
        self.bug_tracker = BugTracker("HKG", output_dir)
        
        # Evolutionary Corpus
        self.corpus = EvolutionaryCorpus(max_size=100)
        
        # Dispatcher Space (åˆ›æ–°ç‚¹)
        self.dispatcher_space = None
        if enable_dispatcher_space:
            self.dispatcher_space = DispatcherSpace(name=api_name)
            self.dispatcher_space.register_api(api_name)
        
        # CSV Logger
        self.csv_logger = None
        if enable_csv_logging:
            api_clean = api_name.replace('.', '_').replace('::', '_')
            log_file = join(output_dir, f"{api_clean}_hkg_trace.csv")
            self.csv_logger = CSVLogger(log_file, strategy="hkg")
        
        # Safety Guards
        self.speedometer = Speedometer(window_size=100, slow_threshold=0.5)
        self.disk_guard = DiskGuard(output_dir, min_free_gb=1.0, auto_cleanup=True)
        self.outlier_filter = OutlierFilter(max_elements=int(1e8))
        
        # çŠ¶æ€
        self.current_phase = "init"
        self.warmup_end_iteration = 0
        
        # Îµ-greedy å‚æ•°
        self.epsilon = 0.1  # 10% æ¢ç´¢
        
        print(f"\n{'='*70}")
        print(f"ğŸš€ HKGFuzzEngine Initialized")
        print(f"{'='*70}")
        print(f"  API: {api_name}")
        print(f"  Warm-up Ratio: {warmup_ratio*100:.0f}%")
        print(f"  Oracles: {[str(o) for o in self.oracles]}")
        print(f"  Dispatcher Space: {'Enabled' if enable_dispatcher_space else 'Disabled'}")
        print(f"  CSV Logging: {'Enabled' if enable_csv_logging else 'Disabled'}")
        print(f"{'='*70}\n")
    
    def _extract_features(self, api: TorchAPI) -> str:
        """æå– API è°ƒç”¨çš„å‚æ•°æŒ‡çº¹"""
        features = []
        for param_name, arg in api.args.items():
            if arg is None:
                continue
            if hasattr(arg, 'type'):
                if arg.type == ArgType.TORCH_TENSOR:
                    shape_str = str(arg.shape) if hasattr(arg, 'shape') else 'unknown'
                    dtype_str = str(arg.dtype).split(".")[-1] if hasattr(arg, 'dtype') else 'unknown'
                    features.append(f"{param_name}:tensor:{dtype_str}:{shape_str}")
                elif arg.type == ArgType.INT:
                    features.append(f"{param_name}:int:{arg.value}")
                elif arg.type == ArgType.FLOAT:
                    features.append(f"{param_name}:float:{arg.value:.2f}")
                elif arg.type == ArgType.BOOL:
                    features.append(f"{param_name}:bool:{arg.value}")
        features.sort()
        return "|".join(features)[:200]  # é™åˆ¶é•¿åº¦
    
    def run(self, max_iterations: int = 10000, checkpoint_interval: int = 100):
        """
        è¿è¡Œ HKG Fuzzing
        
        Args:
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
            checkpoint_interval: æ£€æŸ¥ç‚¹é—´éš”
        """
        print(f"\n{'='*70}")
        print(f"ğŸ”¬ Starting HKG Fuzzing: {self.api_name}")
        print(f"{'='*70}")
        print(f"  Max Iterations: {max_iterations}")
        print(f"  Phase 1 (Warm-up): 0 â†’ {int(max_iterations * self.warmup_ratio)}")
        print(f"  Phase 2 (Evolution): {int(max_iterations * self.warmup_ratio)} â†’ {max_iterations}")
        print(f"{'='*70}\n")
        
        # è®¡ç®—çƒ­å¯åŠ¨ç»“æŸç‚¹
        self.warmup_end_iteration = int(max_iterations * self.warmup_ratio)
        
        # å¯åŠ¨é€Ÿåº¦è®¡
        self.speedometer.start()
        start_time = time.time()
        
        # ä¸»å¾ªç¯
        for i in range(max_iterations):
            self.speedometer.tick()
            
            # =================================================================
            # é˜¶æ®µåˆ¤æ–­
            # =================================================================
            if i < self.warmup_end_iteration:
                self.current_phase = "warmup"
                source = self._warmup_iteration(i)
            else:
                self.current_phase = "evolution"
                source = self._evolution_iteration(i)
            
            # =================================================================
            # ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
            # =================================================================
            api = self._generate_test_case(source)
            
            # Outlier è¿‡æ»¤
            should_filter, _ = self.outlier_filter.check_api(api)
            if should_filter:
                self._log_iteration(i, source, api, valid=False)
                continue
            
            # =================================================================
            # æ‰§è¡Œæµ‹è¯•
            # =================================================================
            all_captured_kernels = set()
            execution_valid = False
            
            for oracle in self.oracles:
                try:
                    captured_kernels = self.library.test_with_oracle(api, oracle)
                    all_captured_kernels.update(captured_kernels)
                    execution_valid = True
                except Exception as e:
                    pass
            
            # =================================================================
            # æ›´æ–°è¦†ç›–ç‡
            # =================================================================
            new_count = self.coverage.update(all_captured_kernels, i)
            
            # æ›´æ–° Dispatcher Space
            if self.dispatcher_space and execution_valid:
                self.dispatcher_space.record_hit(self.api_name, api=api, iteration=i)
            
            # æ›´æ–° Corpus
            if new_count > 0:
                self.corpus.add_seed(api, all_captured_kernels)
            
            # è®°å½•æ—¥å¿—
            self._log_iteration(i, source, api, execution_valid, new_count)
            
            # =================================================================
            # å®šæœŸæ£€æŸ¥
            # =================================================================
            if (i + 1) % checkpoint_interval == 0:
                self._checkpoint(i, max_iterations, start_time)
        
        # =================================================================
        # å®Œæˆ
        # =================================================================
        self._finalize(start_time)
    
    def _warmup_iteration(self, iteration: int) -> str:
        """
        Phase 1: Warm-up é˜¶æ®µ
        
        ç­–ç•¥:
        - 100% Random: å¿«é€Ÿç”Ÿæˆå¤šæ ·åŒ–çš„ç§å­
        - ç›®æ ‡: å¡«å…… Corpusï¼Œç‚¹äº®æµ…å±‚çŠ¶æ€æ ¼å­
        """
        return "random"
    
    def _evolution_iteration(self, iteration: int) -> str:
        """
        Phase 2: Evolution é˜¶æ®µ
        
        ç­–ç•¥:
        - Îµ-greedy: 90% åˆ©ç”¨ Corpusï¼Œ10% æ¢ç´¢
        """
        if random.random() < self.epsilon:
            return "exploration"
        elif self.corpus.size() > 0 and random.random() < 0.7:
            return "corpus"
        else:
            return "random"
    
    def _generate_test_case(self, source: str) -> TorchAPI:
        """
        ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
        """
        if source == "corpus" and self.corpus.size() > 0:
            parent_api = self.corpus.select_parent()
            api = copy.deepcopy(parent_api)
        else:
            api = TorchAPI(self.api_name)
        
        # å˜å¼‚
        api.mutate()
        return api
    
    def _log_iteration(self, iteration: int, source: str, api: TorchAPI, 
                       valid: bool, new_kernels: int = 0):
        """è®°å½•æ—¥å¿—"""
        if self.csv_logger:
            features = self._extract_features(api)
            dispatcher_cov = self.dispatcher_space.get_overall_coverage() if self.dispatcher_space else 0.0
            
            self.csv_logger.log(
                iteration=iteration,
                phase=self.current_phase,
                source=source,
                valid=valid,
                new_kernels=new_kernels,
                total_kernels=self.coverage.get_total(),
                corpus_size=self.corpus.size(),
                dispatcher_coverage=dispatcher_cov,
                bug_count=self.bug_tracker.get_total_bugs(),
                features=features
            )
    
    def _checkpoint(self, iteration: int, max_iterations: int, start_time: float):
        """å®šæœŸæ£€æŸ¥ç‚¹"""
        elapsed = time.time() - start_time
        
        # æ‰«æ Bug
        self.bug_tracker.scan_bugs()
        
        print(f"\n--- Checkpoint: {iteration+1}/{max_iterations} ({elapsed/60:.1f} min) ---")
        print(f"  Phase: {self.current_phase.upper()}")
        print(f"  Kernels: {self.coverage.get_total()}")
        print(f"  Corpus: {self.corpus.size()} seeds")
        print(f"  Bugs: {self.bug_tracker.get_total_bugs()}")
        
        if self.dispatcher_space:
            print(f"  Dispatcher Coverage: {self.dispatcher_space.get_overall_coverage():.2f}%")
        
        print(f"  Speed: {self.speedometer.get_status(iteration, max_iterations)}")
        print(f"  Disk: {self.disk_guard.get_status()}")
        
        # ç£ç›˜æ£€æŸ¥
        is_critical, msg = self.disk_guard.check_and_cleanup()
        if is_critical:
            print(f"\nâš ï¸ {msg}")
    
    def _finalize(self, start_time: float):
        """å®Œæˆå¹¶è¾“å‡ºæŠ¥å‘Š"""
        elapsed = time.time() - start_time
        
        # æœ€ç»ˆ Bug æ‰«æ
        self.bug_tracker.scan_bugs()
        
        print(f"\n{'='*70}")
        print(f"âœ… HKG Fuzzing Completed: {self.api_name}")
        print(f"{'='*70}")
        print(f"  Total Time: {elapsed/60:.1f} minutes")
        print(f"  Total Kernels: {self.coverage.get_total()}")
        print(f"  Total Bugs: {self.bug_tracker.get_total_bugs()}")
        print(f"    - Crash: {self.bug_tracker.get_bugs_by_type('crash')}")
        print(f"    - CUDA: {self.bug_tracker.get_bugs_by_type('cuda')}")
        print(f"    - Precision: {self.bug_tracker.get_bugs_by_type('precision')}")
        print(f"  Corpus Size: {self.corpus.size()}")
        print(f"  Average Speed: {self.speedometer.get_average_speed():.2f} it/s")
        
        # Dispatcher Space æŠ¥å‘Š
        if self.dispatcher_space:
            self.dispatcher_space.print_summary()
        
        # å…³é—­æ—¥å¿—
        if self.csv_logger:
            self.csv_logger.close()
            print(f"\nğŸ“ CSV Log saved: {self.csv_logger.output_file}")
        
        # ä¿å­˜ç»“æœ
        self._save_results()
        
        print(f"{'='*70}\n")
    
    def _save_results(self):
        """ä¿å­˜ç»“æœåˆ° JSON"""
        results = {
            "api": self.api_name,
            "strategy": "HKG (Hybrid Kernel-Guided)",
            "warmup_ratio": self.warmup_ratio,
            "total_kernels": self.coverage.get_total(),
            "bugs": {
                "total": self.bug_tracker.get_total_bugs(),
                "crash": self.bug_tracker.get_bugs_by_type("crash"),
                "cuda": self.bug_tracker.get_bugs_by_type("cuda"),
                "precision": self.bug_tracker.get_bugs_by_type("precision")
            },
            "corpus_size": self.corpus.size()
        }
        
        if self.dispatcher_space:
            results["dispatcher_space"] = self.dispatcher_space.to_dict()
        
        result_file = join(self.output_dir, f"{self.api_name.replace('.', '_')}_hkg_results.json")
        with open(result_file, "w") as f:
            json.dump(results, f, indent=2)
        
        print(f"ğŸ’¾ Results saved: {result_file}")


# =============================================================================
# Visualization (ä¸åŸå§‹å®ç°å…¼å®¹)
# =============================================================================

def plot_hkg_results(coverage: EnhancedCoverageTracker,
                     dispatcher_space: Optional[DispatcherSpace],
                     bug_tracker: BugTracker,
                     api_name: str,
                     output_dir: str):
    """ç»˜åˆ¶ HKG ç»“æœå›¾"""
    
    fig = plt.figure(figsize=(15, 10))
    gs = fig.add_gridspec(2, 2, hspace=0.3, wspace=0.3)
    
    # Kernel è¦†ç›–ç‡æ›²çº¿
    ax1 = fig.add_subplot(gs[0, 0])
    if coverage.history:
        iters, kernels = zip(*coverage.history)
        ax1.plot(iters, kernels, color="#e74c3c", linewidth=2)
    ax1.set_xlabel("Iteration")
    ax1.set_ylabel("Cumulative Kernels")
    ax1.set_title("A) Kernel Coverage")
    ax1.grid(True, alpha=0.3)
    
    # Dispatcher çŠ¶æ€è¦†ç›–ç‡
    ax2 = fig.add_subplot(gs[0, 1])
    if dispatcher_space and dispatcher_space.coverage_history:
        iters, cov = zip(*dispatcher_space.coverage_history)
        ax2.plot(iters, cov, color="#3498db", linewidth=2)
    ax2.set_xlabel("Iteration")
    ax2.set_ylabel("Coverage (%)")
    ax2.set_title("B) Dispatcher State Coverage")
    ax2.grid(True, alpha=0.3)
    
    # Bug ç»Ÿè®¡
    ax3 = fig.add_subplot(gs[1, 0])
    bug_types = ['Crash', 'CUDA', 'Precision']
    bug_counts = [
        bug_tracker.get_bugs_by_type('crash'),
        bug_tracker.get_bugs_by_type('cuda'),
        bug_tracker.get_bugs_by_type('precision')
    ]
    bars = ax3.bar(bug_types, bug_counts, color=['#e74c3c', '#f39c12', '#9b59b6'])
    ax3.set_ylabel("Count")
    ax3.set_title("C) Bugs by Type")
    for bar, count in zip(bars, bug_counts):
        if count > 0:
            ax3.text(bar.get_x() + bar.get_width()/2., bar.get_height(),
                    f'{int(count)}', ha='center', va='bottom')
    
    # ç»Ÿè®¡è¡¨
    ax4 = fig.add_subplot(gs[1, 1])
    ax4.axis('off')
    
    stats_text = f"""
    HKG Fuzzing Statistics
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    API: {api_name}
    
    Kernel Coverage:
      Total Kernels: {coverage.get_total()}
    
    Dispatcher Coverage:
      Overall: {dispatcher_space.get_overall_coverage() if dispatcher_space else 'N/A':.2f}%
    
    Bugs Found:
      Total: {bug_tracker.get_total_bugs()}
      Crash: {bug_tracker.get_bugs_by_type('crash')}
      CUDA: {bug_tracker.get_bugs_by_type('cuda')}
      Precision: {bug_tracker.get_bugs_by_type('precision')}
    """
    ax4.text(0.1, 0.9, stats_text, transform=ax4.transAxes, fontsize=10,
             verticalalignment='top', fontfamily='monospace')
    ax4.set_title("D) Summary")
    
    fig.suptitle(f"HKG Fuzzing Results: {api_name}", fontsize=14, fontweight='bold')
    
    plt.tight_layout()
    
    plot_file = join(output_dir, f"{api_name.replace('.', '_')}_hkg_plot.png")
    plt.savefig(plot_file, dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"\nğŸ“Š Plot saved: {plot_file}")


# =============================================================================
# Main Experiment Runner
# =============================================================================

def run_hkg_experiment(
    api_name: str,
    max_iterations: int,
    output_dir: str,
    config_file: str = "demo_torch.conf",
    warmup_ratio: float = 0.1,
    diff_bound: float = 1e-5
):
    """
    è¿è¡Œ HKG å®éªŒ
    
    Args:
        api_name: API åç§°
        max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
        output_dir: è¾“å‡ºç›®å½•
        config_file: é…ç½®æ–‡ä»¶
        warmup_ratio: çƒ­å¯åŠ¨æ¯”ä¾‹
        diff_bound: ç²¾åº¦å®¹å·®
    """
    os.makedirs(output_dir, exist_ok=True)
    
    # é…ç½®æ•°æ®åº“
    config = configparser.ConfigParser()
    possible_paths = [
        join("config", config_file),
        join("..", "config", config_file),
        config_file,
    ]
    
    config_path = None
    for path in possible_paths:
        if os.path.exists(path):
            config_path = path
            break
    
    if not config_path:
        print("âš ï¸ Config file not found, using default settings")
    else:
        print(f"ğŸ“ Config: {os.path.abspath(config_path)}")
        config.read(config_path)
        
        TorchDatabase.database_config(
            config["mongodb"]["host"],
            int(config["mongodb"]["port"]),
            config["mongodb"]["torch_database"]
        )
    
    # å¯ç”¨æŠ•æ¯’
    PoisonPatcher.patch()
    ProbabilityPatcher.patch_high_db_probability()
    
    try:
        # åˆ›å»ºå¹¶è¿è¡Œ HKGFuzzEngine
        engine = HKGFuzzEngine(
            api_name=api_name,
            output_dir=output_dir,
            warmup_ratio=warmup_ratio,
            use_all_oracles=True,
            enable_dispatcher_space=True,
            enable_csv_logging=True,
            diff_bound=diff_bound
        )
        
        engine.run(
            max_iterations=max_iterations,
            checkpoint_interval=max(100, max_iterations // 20)
        )
        
        # ç»˜å›¾
        plot_hkg_results(
            engine.coverage,
            engine.dispatcher_space,
            engine.bug_tracker,
            api_name,
            output_dir
        )
        
    finally:
        ProbabilityPatcher.restore()
        PoisonPatcher.restore()


# =============================================================================
# Main
# =============================================================================

def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description="HKG (Hybrid Kernel-Guided) Fuzzing Benchmark"
    )
    parser.add_argument("--api", type=str, default="torch.nn.LSTM",
                        help="API to test")
    parser.add_argument("--max-iterations", type=int, default=10000,
                        help="Maximum iterations")
    parser.add_argument("--output", type=str, default="hkg_output")
    parser.add_argument("--conf", type=str, default="demo_torch.conf")
    parser.add_argument("--warmup-ratio", type=float, default=0.1,
                        help="Warm-up phase ratio (default: 0.1 = 10%)")
    parser.add_argument("--diff-bound", type=float, default=1e-5,
                        help="Precision tolerance")
    
    args = parser.parse_args()
    
    print("="*70)
    print("ğŸ”¬ HKG (HYBRID KERNEL-GUIDED) FUZZING")
    print("="*70)
    print(f"API: {args.api}")
    print(f"Max Iterations: {args.max_iterations:,}")
    print(f"Warm-up Ratio: {args.warmup_ratio*100:.0f}%")
    print(f"  Phase 1 (Warm-up): 0 â†’ {int(args.max_iterations * args.warmup_ratio)}")
    print(f"  Phase 2 (Evolution): {int(args.max_iterations * args.warmup_ratio)} â†’ {args.max_iterations}")
    print(f"Oracles: CRASH + CUDA + PRECISION")
    print("="*70)
    
    run_hkg_experiment(
        api_name=args.api,
        max_iterations=args.max_iterations,
        output_dir=args.output,
        config_file=args.conf,
        warmup_ratio=args.warmup_ratio,
        diff_bound=args.diff_bound
    )


if __name__ == "__main__":
    main()