{"iteration": 0, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:sum|parameter:1:int:8", "kernels": []}
{"iteration": 1, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1", "kernels": ["Activity Buffer Request", "cudaMalloc", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaDeviceGetStreamPriorityRange"]}
{"iteration": 2, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.38|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaGetSymbolAddress", "cudaMalloc", "Runtime Triggered Module Loading", "cudaGetDriverEntryPoint", "cudaDeviceGetAttribute", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaFree", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags", "cudaStreamIsCapturing"]}
{"iteration": 3, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-37", "kernels": []}
{"iteration": 4, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:0.00|parameter:1:int:-5", "kernels": []}
{"iteration": 5, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:False", "kernels": []}
{"iteration": 6, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Runtime Triggered Module Loading", "ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 7, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:471|parameter:1:int:-35", "kernels": []}
{"iteration": 8, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Runtime Triggered Module Loading", "cudaMalloc", "ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 9, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 10, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-41|input_signature:list:len3|parameter:0:str:reflect|parameter:1:int:8", "kernels": []}
{"iteration": 11, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 12, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:0|parameter:1:float:1024.00", "kernels": []}
{"iteration": 13, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 14, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:458|parameter:1:int:1024", "kernels": []}
{"iteration": 15, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 16, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 17, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:33", "kernels": []}
{"iteration": 18, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:str:reflect", "kernels": []}
{"iteration": 19, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 20, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 21, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:12", "kernels": []}
{"iteration": 22, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 23, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-25", "kernels": []}
{"iteration": 24, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.14|input_signature:list:len3|parameter:0:int:512|parameter:1:int:51", "kernels": []}
{"iteration": 25, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:60", "kernels": []}
{"iteration": 26, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 27, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 28, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 29, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:553|parameter:1:int:8", "kernels": []}
{"iteration": 30, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.33|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 31, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1", "kernels": []}
{"iteration": 32, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1024|parameter:1:int:8", "kernels": []}
{"iteration": 33, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 34, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.62|input_signature:list:len3|parameter:0:int:563|parameter:1:int:8", "kernels": []}
{"iteration": 35, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:466|parameter:1:int:-1024", "kernels": []}
{"iteration": 36, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:456|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 37, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.08|input_signature:list:len3|parameter:0:int:474|parameter:1:int:23", "kernels": []}
{"iteration": 38, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:518|parameter:1:int:8", "kernels": []}
{"iteration": 39, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.93|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-20", "kernels": []}
{"iteration": 40, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:38", "kernels": []}
{"iteration": 41, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:36|parameter:1:int:8", "kernels": []}
{"iteration": 42, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-26", "kernels": []}
{"iteration": 43, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 44, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:1|parameter:1:int:8", "kernels": []}
{"iteration": 45, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 46, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:505|parameter:1:int:8", "kernels": []}
{"iteration": 47, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-27", "kernels": []}
{"iteration": 48, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 49, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 50, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.09|input_signature:list:len3|parameter:0:int:556|parameter:1:int:8", "kernels": []}
{"iteration": 51, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.17|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-32", "kernels": []}
{"iteration": 52, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 53, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:533|parameter:1:int:8", "kernels": []}
{"iteration": 54, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 55, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 56, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:12", "kernels": []}
{"iteration": 57, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 58, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 59, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:102|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 60, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:43", "kernels": []}
{"iteration": 61, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:1024|parameter:1:int:19", "kernels": []}
{"iteration": 62, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:569|parameter:1:int:5", "kernels": []}
{"iteration": 63, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-20|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 64, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1024.00|input_signature:list:len3|parameter:0:int:-1024|parameter:1:int:8", "kernels": []}
{"iteration": 65, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:1024|parameter:1:int:-51", "kernels": []}
{"iteration": 66, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:471|parameter:1:int:1024", "kernels": []}
{"iteration": 67, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:525|parameter:1:int:-27", "kernels": []}
{"iteration": 68, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 69, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:482|parameter:1:int:8", "kernels": []}
{"iteration": 70, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-32", "kernels": []}
{"iteration": 71, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 72, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-49|input_signature:list:len3|parameter:0:int:450|parameter:1:int:16", "kernels": []}
{"iteration": 73, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.51|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 74, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:35", "kernels": []}
{"iteration": 75, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:494|parameter:1:int:8", "kernels": []}
{"iteration": 76, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:16|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 77, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.12|input_signature:list:len3|parameter:0:int:512|parameter:1:float:1.63", "kernels": []}
{"iteration": 78, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 79, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 80, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1024", "kernels": []}
{"iteration": 81, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 82, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.00|input_signature:list:len3|parameter:0:int:-1024|parameter:1:int:-1024", "kernels": []}
{"iteration": 83, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:-1024|parameter:1:str:replicate", "kernels": []}
{"iteration": 84, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 85, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 86, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-14", "kernels": []}
{"iteration": 87, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.00|input_signature:list:len3|parameter:0:int:0|parameter:1:int:8", "kernels": []}
{"iteration": 88, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 89, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 90, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 91, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 92, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 93, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:524|parameter:1:int:8", "kernels": []}
{"iteration": 94, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-16", "kernels": []}
{"iteration": 95, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:540|parameter:1:int:1055", "kernels": []}
{"iteration": 96, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 97, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 98, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:513|parameter:1:int:8", "kernels": []}
{"iteration": 99, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:560|parameter:1:str:max", "kernels": []}
{"iteration": 100, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-47|parameter:1:int:8", "kernels": []}
{"iteration": 101, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 102, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:43|input_signature:list:len3|parameter:0:int:544|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 103, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 104, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 105, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:16", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 106, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:469|parameter:1:int:-10", "kernels": []}
{"iteration": 107, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 108, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:16|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 109, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:-1029.20|parameter:1:int:55", "kernels": []}
{"iteration": 110, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:53", "kernels": []}
{"iteration": 111, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:1024|parameter:1:int:-5", "kernels": []}
{"iteration": 112, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.00|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 113, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 114, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.22|input_signature:list:len3|parameter:0:int:495|parameter:1:str:circular", "kernels": []}
{"iteration": 115, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:507|parameter:1:int:8", "kernels": []}
{"iteration": 116, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.85|input_signature:list:len3|parameter:0:int:533|parameter:1:int:1", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 117, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 118, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 119, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-16|parameter:1:int:-23", "kernels": []}
{"iteration": 120, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.38|input_signature:list:len3|parameter:0:int:460|parameter:1:int:8", "kernels": []}
{"iteration": 121, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:63.00|input_signature:list:len3|parameter:0:int:534|parameter:1:int:-30", "kernels": []}
{"iteration": 122, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.43|input_signature:list:len3|parameter:0:int:555|parameter:1:bool:True", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 123, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 124, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:563|parameter:1:int:52", "kernels": []}
{"iteration": 125, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.98|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-37", "kernels": []}
{"iteration": 126, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1|parameter:1:int:8", "kernels": []}
{"iteration": 127, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:1024|parameter:1:int:8", "kernels": []}
{"iteration": 128, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 129, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 130, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:0.00", "kernels": []}
{"iteration": 131, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 132, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-5.25|input_signature:list:len3|parameter:0:int:467|parameter:1:int:8", "kernels": []}
{"iteration": 133, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:63.00|input_signature:list:len3|parameter:0:int:530|parameter:1:int:8", "kernels": []}
{"iteration": 134, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:sum", "kernels": []}
{"iteration": 135, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:500|parameter:1:int:8", "kernels": []}
{"iteration": 136, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:45|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 137, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:540|parameter:1:int:8", "kernels": []}
{"iteration": 138, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:480|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 139, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-76", "kernels": []}
{"iteration": 140, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 141, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 142, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-17|input_signature:list:len3|parameter:0:int:512|parameter:1:int:55", "kernels": []}
{"iteration": 143, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 144, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-55", "kernels": []}
{"iteration": 145, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 146, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 147, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-9", "kernels": []}
{"iteration": 148, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:556|parameter:1:int:8", "kernels": []}
{"iteration": 149, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-20|parameter:1:int:8", "kernels": []}
{"iteration": 150, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:483|parameter:1:str:max", "kernels": []}
{"iteration": 151, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 152, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:6", "kernels": []}
{"iteration": 153, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 154, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 155, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-9|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-36", "kernels": []}
{"iteration": 156, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 157, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 158, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.12|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-21", "kernels": []}
{"iteration": 159, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:498|parameter:1:int:8", "kernels": []}
{"iteration": 160, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.00|input_signature:list:len3|parameter:0:float:-3.13|parameter:1:int:8", "kernels": []}
{"iteration": 161, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 162, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-15|input_signature:list:len3|parameter:0:int:551|parameter:1:bool:True", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 163, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 164, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.82|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 165, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:570|parameter:1:int:8", "kernels": []}
{"iteration": 166, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 167, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:607|parameter:1:int:8", "kernels": []}
{"iteration": 168, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.17|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 169, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.74|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:False", "kernels": []}
{"iteration": 170, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:37", "kernels": []}
{"iteration": 171, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 172, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaLaunchKernel", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 173, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 174, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:0.00|parameter:1:bool:False", "kernels": []}
{"iteration": 175, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 176, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:17", "kernels": []}
{"iteration": 177, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 178, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 179, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-65", "kernels": []}
{"iteration": 180, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 181, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:520|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 182, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.98|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 183, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 184, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-4", "kernels": []}
{"iteration": 185, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:5", "kernels": []}
{"iteration": 186, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:500|parameter:1:int:-69", "kernels": []}
{"iteration": 187, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:533|parameter:1:int:-34", "kernels": []}
{"iteration": 188, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 189, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 190, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 191, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:replicate|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 192, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 193, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1024", "kernels": []}
{"iteration": 194, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.43|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-18", "kernels": []}
{"iteration": 195, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 196, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.30|input_signature:list:len3|parameter:0:int:474|parameter:1:int:8", "kernels": []}
{"iteration": 197, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 198, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-16", "kernels": []}
{"iteration": 199, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-16", "kernels": []}
{"iteration": 200, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:551|parameter:1:int:8", "kernels": []}
{"iteration": 201, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:54", "kernels": []}
{"iteration": 202, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:0|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 203, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-41", "kernels": []}
{"iteration": 204, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 205, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.17|input_signature:list:len3|parameter:0:int:459|parameter:1:int:8", "kernels": []}
{"iteration": 206, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 207, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 208, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 209, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:511|parameter:1:int:8", "kernels": []}
{"iteration": 210, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 211, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 212, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:circular", "kernels": []}
{"iteration": 213, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:16|parameter:1:int:-20", "kernels": []}
{"iteration": 214, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.88|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 215, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:467|parameter:1:int:8", "kernels": []}
{"iteration": 216, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.72|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-21", "kernels": []}
{"iteration": 217, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:0|parameter:1:int:8", "kernels": []}
{"iteration": 218, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 219, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1024", "kernels": []}
{"iteration": 220, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.49|input_signature:list:len3|parameter:0:int:503|parameter:1:int:8", "kernels": []}
{"iteration": 221, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:16|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-33", "kernels": []}
{"iteration": 222, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:12|input_signature:list:len3|parameter:0:int:1024|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 223, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.75|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1016", "kernels": []}
{"iteration": 224, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 225, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 226, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:57", "kernels": []}
{"iteration": 227, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 228, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 229, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 230, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:49", "kernels": []}
{"iteration": 231, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-19", "kernels": []}
{"iteration": 232, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.95|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 233, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:491|parameter:1:int:8", "kernels": []}
{"iteration": 234, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.09|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 235, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 236, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 237, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 238, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1024.00|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 239, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.97|input_signature:list:len3|parameter:0:int:540|parameter:1:int:8", "kernels": []}
{"iteration": 240, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:499|parameter:1:int:8", "kernels": []}
{"iteration": 241, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.18|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 242, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:491|parameter:1:int:8", "kernels": []}
{"iteration": 243, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.85|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 244, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:4.03|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 245, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:455|parameter:1:int:25", "kernels": []}
{"iteration": 246, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.61|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 247, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 248, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 249, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-28|parameter:1:int:8", "kernels": []}
{"iteration": 250, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.04|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 251, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 252, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 253, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-22", "kernels": []}
{"iteration": 254, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.68|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 255, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:471|parameter:1:int:8", "kernels": []}
{"iteration": 256, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.00|input_signature:list:len3|parameter:0:int:490|parameter:1:int:8", "kernels": []}
{"iteration": 257, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 258, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.15|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 259, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 260, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1|parameter:1:bool:False", "kernels": []}
{"iteration": 261, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.48|input_signature:list:len3|parameter:0:float:3.80|parameter:1:int:8", "kernels": []}
{"iteration": 262, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 263, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:569|parameter:1:bool:False", "kernels": []}
{"iteration": 264, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:574|parameter:1:int:8", "kernels": []}
{"iteration": 265, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 266, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:450|parameter:1:int:8", "kernels": []}
{"iteration": 267, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 268, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:494|parameter:1:int:8", "kernels": []}
{"iteration": 269, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 270, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:38", "kernels": []}
{"iteration": 271, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:0.00", "kernels": []}
{"iteration": 272, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:-1006|parameter:1:int:8", "kernels": []}
{"iteration": 273, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:483|parameter:1:int:-37", "kernels": []}
{"iteration": 274, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:int:26", "kernels": []}
{"iteration": 275, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1|parameter:1:int:0", "kernels": []}
{"iteration": 276, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.61|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 277, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1", "kernels": []}
{"iteration": 278, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.73|input_signature:list:len3|parameter:0:int:1024|parameter:1:int:0", "kernels": []}
{"iteration": 279, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.67|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 280, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 281, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.05|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 282, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 283, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.48|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 284, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:505|parameter:1:int:-1024", "kernels": []}
{"iteration": 285, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:float:nan|parameter:1:int:8", "kernels": []}
{"iteration": 286, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-19|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 287, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:23", "kernels": []}
{"iteration": 288, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 289, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:43", "kernels": []}
{"iteration": 290, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 291, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:521|parameter:1:int:8", "kernels": []}
{"iteration": 292, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 293, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1|parameter:1:int:-1", "kernels": []}
{"iteration": 294, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 295, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.04|input_signature:list:len3|parameter:0:int:512|parameter:1:int:16", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 296, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.00|input_signature:list:len3|parameter:0:str:max|parameter:1:int:59", "kernels": []}
{"iteration": 297, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-29", "kernels": []}
{"iteration": 298, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 299, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 300, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:492|parameter:1:int:8", "kernels": []}
{"iteration": 301, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 302, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.66|input_signature:list:len3|parameter:0:int:11|parameter:1:int:8", "kernels": []}
{"iteration": 303, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:38", "kernels": []}
{"iteration": 304, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-22", "kernels": []}
{"iteration": 305, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.49|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 306, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.63|input_signature:list:len3|parameter:0:int:505|parameter:1:int:8", "kernels": []}
{"iteration": 307, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 308, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 309, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:535|parameter:1:int:8", "kernels": []}
{"iteration": 310, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:0", "kernels": []}
{"iteration": 311, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 312, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 313, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-47", "kernels": []}
{"iteration": 314, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.78|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 315, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 316, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-33|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 317, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 318, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 319, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.42|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-19", "kernels": []}
{"iteration": 320, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 321, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 322, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.37|input_signature:list:len3|parameter:0:int:492|parameter:1:int:8", "kernels": []}
{"iteration": 323, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:510|parameter:1:int:-1", "kernels": []}
{"iteration": 324, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:477|parameter:1:int:8", "kernels": []}
{"iteration": 325, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:-4.37", "kernels": []}
{"iteration": 326, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-63.00|input_signature:list:len3|parameter:0:int:472|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 327, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 328, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:508|parameter:1:int:49", "kernels": []}
{"iteration": 329, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:534|parameter:1:int:1", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 330, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:1051|parameter:1:int:33", "kernels": []}
{"iteration": 331, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 332, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-1|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 333, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.97|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 334, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 335, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 336, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:496|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 337, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:496|parameter:1:int:-41", "kernels": []}
{"iteration": 338, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:477|parameter:1:int:8", "kernels": []}
{"iteration": 339, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:561|parameter:1:int:1", "kernels": []}
{"iteration": 340, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:74|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 341, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.18|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 342, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.42|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 343, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.12|input_signature:list:len3|parameter:0:int:512|parameter:1:float:63.00", "kernels": []}
{"iteration": 344, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:1|parameter:1:int:8", "kernels": []}
{"iteration": 345, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:545|parameter:1:int:37", "kernels": []}
{"iteration": 346, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:452|parameter:1:int:23", "kernels": []}
{"iteration": 347, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1024|parameter:1:int:8", "kernels": []}
{"iteration": 348, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:sum", "kernels": []}
{"iteration": 349, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.26|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 350, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1", "kernels": []}
{"iteration": 351, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-16|input_signature:list:len3|parameter:0:int:512|parameter:1:float:63.00", "kernels": []}
{"iteration": 352, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 353, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:529|parameter:1:int:-54", "kernels": []}
{"iteration": 354, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1", "kernels": []}
{"iteration": 355, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-11", "kernels": []}
{"iteration": 356, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.65|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 357, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.73|input_signature:list:len3|parameter:0:int:512|parameter:1:int:59", "kernels": []}
{"iteration": 358, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 359, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:0", "kernels": []}
{"iteration": 360, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:556|parameter:1:int:8", "kernels": []}
{"iteration": 361, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.53|input_signature:list:len3|parameter:0:int:512|parameter:1:int:16", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 362, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:0|parameter:1:int:8", "kernels": []}
{"iteration": 363, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 364, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 365, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.78|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 366, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:16", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 367, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:563|parameter:1:int:-6", "kernels": []}
{"iteration": 368, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:462|parameter:1:int:8", "kernels": []}
{"iteration": 369, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:16|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 370, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 371, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:0|parameter:1:int:8", "kernels": []}
{"iteration": 372, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:63.00", "kernels": []}
{"iteration": 373, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-50", "kernels": []}
{"iteration": 374, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 375, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-78", "kernels": []}
{"iteration": 376, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:1|parameter:1:int:8", "kernels": []}
{"iteration": 377, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:reflect|parameter:1:bool:False", "kernels": []}
{"iteration": 378, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:-41", "kernels": []}
{"iteration": 379, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:505|parameter:1:int:8", "kernels": []}
{"iteration": 380, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1024", "kernels": []}
{"iteration": 381, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 382, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:518|parameter:1:int:8", "kernels": []}
{"iteration": 383, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 384, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:2", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 385, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 386, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.13|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 387, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 388, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.00|input_signature:list:len3|parameter:0:int:463|parameter:1:int:8", "kernels": []}
{"iteration": 389, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 390, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 391, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-10", "kernels": []}
{"iteration": 392, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 393, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.86|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 394, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:zeros|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 395, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-33", "kernels": []}
{"iteration": 396, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:100000000000000000000.00", "kernels": []}
{"iteration": 397, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:503|parameter:1:int:8", "kernels": []}
{"iteration": 398, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:1024.00|parameter:1:int:67", "kernels": []}
{"iteration": 399, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:551|parameter:1:int:8", "kernels": []}
{"iteration": 400, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:506|parameter:1:int:8", "kernels": []}
{"iteration": 401, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:527|parameter:1:int:8", "kernels": []}
{"iteration": 402, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:544|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 403, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:470|parameter:1:int:8", "kernels": []}
{"iteration": 404, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.96|input_signature:list:len3|parameter:0:int:557|parameter:1:int:44", "kernels": []}
{"iteration": 405, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-968|parameter:1:int:-37", "kernels": []}
{"iteration": 406, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.53|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 407, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.20|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-53", "kernels": []}
{"iteration": 408, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:40", "kernels": []}
{"iteration": 409, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-8", "kernels": []}
{"iteration": 410, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:15", "kernels": []}
{"iteration": 411, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:-1.00|parameter:1:int:8", "kernels": []}
{"iteration": 412, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 413, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.87|input_signature:list:len3|parameter:0:int:455|parameter:1:int:-51", "kernels": []}
{"iteration": 414, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-42", "kernels": []}
{"iteration": 415, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 416, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 417, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-17|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 418, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.45|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 419, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:0|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 420, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-84|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 421, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:2", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 422, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 423, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:str:max|parameter:1:int:-46", "kernels": []}
{"iteration": 424, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:1024|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 425, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-21", "kernels": []}
{"iteration": 426, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:replicate|input_signature:list:len3|parameter:0:int:512|parameter:1:int:41", "kernels": []}
{"iteration": 427, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:100|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-40", "kernels": []}
{"iteration": 428, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.70|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 429, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:29|input_signature:list:len3|parameter:0:int:0|parameter:1:str:reflect", "kernels": []}
{"iteration": 430, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:inf|input_signature:list:len3|parameter:0:int:487|parameter:1:int:-16", "kernels": []}
{"iteration": 431, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:522|parameter:1:int:8", "kernels": []}
{"iteration": 432, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 433, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:-1|parameter:1:int:8", "kernels": []}
{"iteration": 434, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:484|parameter:1:int:57", "kernels": []}
{"iteration": 435, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-1|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 436, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:34|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 437, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:504|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 438, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:564|parameter:1:int:45", "kernels": []}
{"iteration": 439, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1024.00|input_signature:list:len3|parameter:0:int:16|parameter:1:int:48", "kernels": []}
{"iteration": 440, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 441, "strategy": "random", "source": "random", "valid": false, "features": "dropout:str:sum|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 442, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:-47", "kernels": []}
{"iteration": 443, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 444, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:492|parameter:1:int:8", "kernels": []}
{"iteration": 445, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 446, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-29|input_signature:list:len3|parameter:0:int:544|parameter:1:int:13", "kernels": []}
{"iteration": 447, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 448, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 449, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.63|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1024", "kernels": []}
{"iteration": 450, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:452|parameter:1:int:8", "kernels": []}
{"iteration": 451, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:str:max", "kernels": []}
{"iteration": 452, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-31", "kernels": []}
{"iteration": 453, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-37", "kernels": []}
{"iteration": 454, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:51|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 455, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 456, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-19", "kernels": []}
{"iteration": 457, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:69", "kernels": []}
{"iteration": 458, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:-1024|parameter:1:int:-1", "kernels": []}
{"iteration": 459, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 460, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-31", "kernels": []}
{"iteration": 461, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:63|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 462, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.67|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 463, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:392|parameter:1:int:21", "kernels": []}
{"iteration": 464, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 465, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.70|input_signature:list:len3|parameter:0:int:512|parameter:1:int:23", "kernels": []}
{"iteration": 466, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.00|input_signature:list:len3|parameter:0:int:-1024|parameter:1:int:20", "kernels": []}
{"iteration": 467, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:480|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 468, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-24", "kernels": []}
{"iteration": 469, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:100000000000000000000.00", "kernels": []}
{"iteration": 470, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 471, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 472, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 473, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1024", "kernels": []}
{"iteration": 474, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 475, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.25|input_signature:list:len3|parameter:0:int:494|parameter:1:int:20", "kernels": []}
{"iteration": 476, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 477, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:454|parameter:1:bool:False", "kernels": []}
{"iteration": 478, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:454|parameter:1:int:8", "kernels": []}
{"iteration": 479, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 480, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-1052|input_signature:list:len3|parameter:0:int:512|parameter:1:int:64", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 481, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:4", "kernels": []}
{"iteration": 482, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:32", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 483, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:-1024|parameter:1:int:8", "kernels": []}
{"iteration": 484, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1024|parameter:1:int:8", "kernels": []}
{"iteration": 485, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-70|input_signature:list:len3|parameter:0:int:512|parameter:1:int:14", "kernels": []}
{"iteration": 486, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:-inf|parameter:1:int:-4", "kernels": []}
{"iteration": 487, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 488, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 489, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:29", "kernels": []}
{"iteration": 490, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:540|parameter:1:int:8", "kernels": []}
{"iteration": 491, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 492, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 493, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-32", "kernels": []}
{"iteration": 494, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 495, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:0.30|parameter:1:int:8", "kernels": []}
{"iteration": 496, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:546|parameter:1:int:8", "kernels": []}
{"iteration": 497, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 498, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:circular|parameter:1:int:8", "kernels": []}
{"iteration": 499, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 500, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:485|parameter:1:int:8", "kernels": []}
{"iteration": 501, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.03|input_signature:list:len3|parameter:0:int:481|parameter:1:int:8", "kernels": []}
{"iteration": 502, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 503, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-13", "kernels": []}
{"iteration": 504, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 505, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 506, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:reflect|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-16", "kernels": []}
{"iteration": 507, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:574|parameter:1:int:8", "kernels": []}
{"iteration": 508, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:489|parameter:1:int:8", "kernels": []}
{"iteration": 509, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.36|input_signature:list:len3|parameter:0:int:481|parameter:1:int:8", "kernels": []}
{"iteration": 510, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.43|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 511, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 512, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:reflect", "kernels": []}
{"iteration": 513, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.54|input_signature:list:len3|parameter:0:int:-1|parameter:1:int:8", "kernels": []}
{"iteration": 514, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:63.00|parameter:1:int:8", "kernels": []}
{"iteration": 515, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 516, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-39", "kernels": []}
{"iteration": 517, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:21", "kernels": []}
{"iteration": 518, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 519, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:569|parameter:1:int:8", "kernels": []}
{"iteration": 520, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-1073|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 521, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 522, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 523, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 524, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:504|parameter:1:int:-17", "kernels": []}
{"iteration": 525, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.78|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 526, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1024.00|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:-23", "kernels": []}
{"iteration": 527, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 528, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-13", "kernels": []}
{"iteration": 529, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.89|input_signature:list:len3|parameter:0:int:466|parameter:1:int:8", "kernels": []}
{"iteration": 530, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:570|parameter:1:int:8", "kernels": []}
{"iteration": 531, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:473|parameter:1:int:8", "kernels": []}
{"iteration": 532, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:25", "kernels": []}
{"iteration": 533, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:507|parameter:1:float:1024.00", "kernels": []}
{"iteration": 534, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 535, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 536, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:463|parameter:1:int:8", "kernels": []}
{"iteration": 537, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 538, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:507|parameter:1:int:8", "kernels": []}
{"iteration": 539, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1", "kernels": []}
{"iteration": 540, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.01|input_signature:list:len3|parameter:0:int:474|parameter:1:int:8", "kernels": []}
{"iteration": 541, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-16|parameter:1:int:-16", "kernels": []}
{"iteration": 542, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:512|parameter:1:int:18", "kernels": []}
{"iteration": 543, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-16", "kernels": []}
{"iteration": 544, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.17|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 545, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 546, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:0|parameter:1:int:8", "kernels": []}
{"iteration": 547, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 548, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 549, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:520|parameter:1:int:41", "kernels": []}
{"iteration": 550, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:511|parameter:1:int:-16", "kernels": []}
{"iteration": 551, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 552, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:12", "kernels": []}
{"iteration": 553, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 554, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 555, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:circular|input_signature:list:len3|parameter:0:int:454|parameter:1:int:8", "kernels": []}
{"iteration": 556, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 557, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:471|parameter:1:int:8", "kernels": []}
{"iteration": 558, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.36|input_signature:list:len3|parameter:0:int:512|parameter:1:int:23", "kernels": []}
{"iteration": 559, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 560, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-12", "kernels": []}
{"iteration": 561, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 562, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 563, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:23", "kernels": []}
{"iteration": 564, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-57|input_signature:list:len3|parameter:0:int:512|parameter:1:int:16", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 565, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:14", "kernels": []}
{"iteration": 566, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:448|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 567, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:558|parameter:1:int:-4", "kernels": []}
{"iteration": 568, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.44|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 569, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 570, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:539|parameter:1:int:8", "kernels": []}
{"iteration": 571, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:replicate", "kernels": []}
{"iteration": 572, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:inf|input_signature:list:len3|parameter:0:float:-1.00|parameter:1:int:8", "kernels": []}
{"iteration": 573, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:485|parameter:1:int:8", "kernels": []}
{"iteration": 574, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:inf|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 575, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:503|parameter:1:float:nan", "kernels": []}
{"iteration": 576, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 577, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:546|parameter:1:int:8", "kernels": []}
{"iteration": 578, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:557|parameter:1:int:-28", "kernels": []}
{"iteration": 579, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:514|parameter:1:int:32", "kernels": []}
{"iteration": 580, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 581, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:544|parameter:1:float:inf", "kernels": []}
{"iteration": 582, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:float:-0.08", "kernels": []}
{"iteration": 583, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 584, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.95|input_signature:list:len3|parameter:0:int:468|parameter:1:int:8", "kernels": []}
{"iteration": 585, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:37", "kernels": []}
{"iteration": 586, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.68|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-46", "kernels": []}
{"iteration": 587, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-inf|input_signature:list:len3|parameter:0:int:570|parameter:1:int:8", "kernels": []}
{"iteration": 588, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-8", "kernels": []}
{"iteration": 589, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:488|parameter:1:bool:True", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 590, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 591, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 592, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.17|input_signature:list:len3|parameter:0:int:532|parameter:1:int:8", "kernels": []}
{"iteration": 593, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 594, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 595, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:47", "kernels": []}
{"iteration": 596, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 597, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 598, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:527|parameter:1:int:8", "kernels": []}
{"iteration": 599, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 600, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 601, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:60", "kernels": []}
{"iteration": 602, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 603, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:-17", "kernels": []}
{"iteration": 604, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.92|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 605, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:1024|parameter:1:int:56", "kernels": []}
{"iteration": 606, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:47", "kernels": []}
{"iteration": 607, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.05|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 608, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-16|parameter:1:int:8", "kernels": []}
{"iteration": 609, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:64", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 610, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 611, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:nan|parameter:1:int:8", "kernels": []}
{"iteration": 612, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 613, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1024.00|input_signature:list:len3|parameter:0:str:sum|parameter:1:int:8", "kernels": []}
{"iteration": 614, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:69", "kernels": []}
{"iteration": 615, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.30|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 616, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.23|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-52", "kernels": []}
{"iteration": 617, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:24", "kernels": []}
{"iteration": 618, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 619, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 620, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 621, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:969", "kernels": []}
{"iteration": 622, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 623, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.35|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 624, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 625, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:52", "kernels": []}
{"iteration": 626, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:481|parameter:1:int:8", "kernels": []}
{"iteration": 627, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:515|parameter:1:bool:True", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 628, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 629, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:451|parameter:1:int:8", "kernels": []}
{"iteration": 630, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 631, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1025.73|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 632, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.34|input_signature:list:len3|parameter:0:int:512|parameter:1:int:23", "kernels": []}
{"iteration": 633, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-28", "kernels": []}
{"iteration": 634, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 635, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 636, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-47", "kernels": []}
{"iteration": 637, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-84|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 638, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:496|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 639, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-7", "kernels": []}
{"iteration": 640, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-47", "kernels": []}
{"iteration": 641, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.68|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 642, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 643, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 644, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.06|input_signature:list:len3|parameter:0:str:sum|parameter:1:int:8", "kernels": []}
{"iteration": 645, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.76|input_signature:list:len3|parameter:0:int:562|parameter:1:int:8", "kernels": []}
{"iteration": 646, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:zeros|input_signature:list:len3|parameter:0:int:1024|parameter:1:int:67", "kernels": []}
{"iteration": 647, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:18", "kernels": []}
{"iteration": 648, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:4|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 649, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:-12", "kernels": []}
{"iteration": 650, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:482|parameter:1:int:8", "kernels": []}
{"iteration": 651, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:4.09|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": []}
{"iteration": 652, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 653, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:63", "kernels": []}
{"iteration": 654, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 655, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:-inf", "kernels": []}
{"iteration": 656, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:535|parameter:1:int:-1024", "kernels": []}
{"iteration": 657, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 658, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 659, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 660, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:510|parameter:1:int:8", "kernels": []}
{"iteration": 661, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1|parameter:1:int:8", "kernels": []}
{"iteration": 662, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 663, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 664, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 665, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:11", "kernels": []}
{"iteration": 666, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 667, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:520|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 668, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:mean|input_signature:list:len3|parameter:0:int:1024|parameter:1:int:8", "kernels": []}
{"iteration": 669, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-56|parameter:1:int:8", "kernels": []}
{"iteration": 670, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:516|parameter:1:int:8", "kernels": []}
{"iteration": 671, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:int:0", "kernels": []}
{"iteration": 672, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-28", "kernels": []}
{"iteration": 673, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-23", "kernels": []}
{"iteration": 674, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:464|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 675, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:488|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 676, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:28", "kernels": []}
{"iteration": 677, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 678, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 679, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:mean|input_signature:list:len3|parameter:0:int:-1024|parameter:1:int:1", "kernels": []}
{"iteration": 680, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 681, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.78|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 682, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 683, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 684, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:16", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 685, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.47|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 686, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 687, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 688, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-10|parameter:1:int:8", "kernels": []}
{"iteration": 689, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:45|parameter:1:int:8", "kernels": []}
{"iteration": 690, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:502|parameter:1:int:8", "kernels": []}
{"iteration": 691, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:531|parameter:1:int:8", "kernels": []}
{"iteration": 692, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1024", "kernels": []}
{"iteration": 693, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:63.00|input_signature:list:len3|parameter:0:int:497|parameter:1:int:8", "kernels": []}
{"iteration": 694, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.80|input_signature:list:len3|parameter:0:int:512|parameter:1:int:17", "kernels": []}
{"iteration": 695, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 696, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 697, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:502|parameter:1:int:8", "kernels": []}
{"iteration": 698, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:70", "kernels": []}
{"iteration": 699, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:0", "kernels": []}
{"iteration": 700, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-16", "kernels": []}
{"iteration": 701, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 702, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.38|input_signature:list:len3|parameter:0:int:479|parameter:1:int:-48", "kernels": []}
{"iteration": 703, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:-78", "kernels": []}
{"iteration": 704, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 705, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:16|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 706, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-7", "kernels": []}
{"iteration": 707, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:533|parameter:1:int:8", "kernels": []}
{"iteration": 708, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:False", "kernels": []}
{"iteration": 709, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 710, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:False", "kernels": []}
{"iteration": 711, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.37|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 712, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.68|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-40", "kernels": []}
{"iteration": 713, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:28", "kernels": []}
{"iteration": 714, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 715, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-41", "kernels": []}
{"iteration": 716, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:63", "kernels": []}
{"iteration": 717, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 718, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:547|parameter:1:int:8", "kernels": []}
{"iteration": 719, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 720, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 721, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-42|input_signature:list:len3|parameter:0:int:495|parameter:1:int:8", "kernels": []}
{"iteration": 722, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:20", "kernels": []}
{"iteration": 723, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1024", "kernels": []}
{"iteration": 724, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:478|parameter:1:int:8", "kernels": []}
{"iteration": 725, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 726, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:46", "kernels": []}
{"iteration": 727, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-20", "kernels": []}
{"iteration": 728, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-27", "kernels": []}
{"iteration": 729, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 730, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:float:-0.59|parameter:1:int:51", "kernels": []}
{"iteration": 731, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:19", "kernels": []}
{"iteration": 732, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.11|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-16", "kernels": []}
{"iteration": 733, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-55", "kernels": []}
{"iteration": 734, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:-2.08|parameter:1:int:8", "kernels": []}
{"iteration": 735, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:540|parameter:1:int:8", "kernels": []}
{"iteration": 736, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 737, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:26", "kernels": []}
{"iteration": 738, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:60", "kernels": []}
{"iteration": 739, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 740, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 741, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:570|parameter:1:int:8", "kernels": []}
{"iteration": 742, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 743, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:492|parameter:1:int:-31", "kernels": []}
{"iteration": 744, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.47|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1", "kernels": []}
{"iteration": 745, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 746, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.89|input_signature:list:len3|parameter:0:int:16|parameter:1:int:1", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 747, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:47", "kernels": []}
{"iteration": 748, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 749, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:29", "kernels": []}
{"iteration": 750, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-16", "kernels": []}
{"iteration": 751, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 752, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 753, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.70|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 754, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-54", "kernels": []}
{"iteration": 755, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 756, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 757, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:70", "kernels": []}
{"iteration": 758, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:478|parameter:1:int:46", "kernels": []}
{"iteration": 759, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 760, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 761, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 762, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 763, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-54", "kernels": []}
{"iteration": 764, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.22|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 765, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 766, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:521|parameter:1:int:19", "kernels": []}
{"iteration": 767, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 768, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 769, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:1024.00|parameter:1:int:8", "kernels": []}
{"iteration": 770, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:-63.00|parameter:1:int:8", "kernels": []}
{"iteration": 771, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.82|input_signature:list:len3|parameter:0:int:37|parameter:1:str:max", "kernels": []}
{"iteration": 772, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:53", "kernels": []}
{"iteration": 773, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.52|input_signature:list:len3|parameter:0:int:545|parameter:1:int:8", "kernels": []}
{"iteration": 774, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 775, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-31", "kernels": []}
{"iteration": 776, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 777, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 778, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:str:sum", "kernels": []}
{"iteration": 779, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:541|parameter:1:int:8", "kernels": []}
{"iteration": 780, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:6", "kernels": []}
{"iteration": 781, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 782, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:46", "kernels": []}
{"iteration": 783, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:428|parameter:1:int:-22", "kernels": []}
{"iteration": 784, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:1|parameter:1:int:8", "kernels": []}
{"iteration": 785, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.32|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 786, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:486|parameter:1:int:8", "kernels": []}
{"iteration": 787, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 788, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:4.05|input_signature:list:len3|parameter:0:int:512|parameter:1:int:30", "kernels": []}
{"iteration": 789, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 790, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 791, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 792, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.50|input_signature:list:len3|parameter:0:float:1024.00|parameter:1:int:8", "kernels": []}
{"iteration": 793, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 794, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:38", "kernels": []}
{"iteration": 795, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 796, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:505|parameter:1:int:8", "kernels": []}
{"iteration": 797, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 798, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:506|parameter:1:int:8", "kernels": []}
{"iteration": 799, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.80|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-47", "kernels": []}
{"iteration": 800, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.76|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 801, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:509|parameter:1:int:8", "kernels": []}
{"iteration": 802, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:460|parameter:1:int:8", "kernels": []}
{"iteration": 803, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.24|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 804, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:zeros|parameter:1:int:8", "kernels": []}
{"iteration": 805, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 806, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:-60.15", "kernels": []}
{"iteration": 807, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.32|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 808, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:circular", "kernels": []}
{"iteration": 809, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:572|parameter:1:int:15", "kernels": []}
{"iteration": 810, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:1|parameter:1:int:16", "kernels": []}
{"iteration": 811, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.89|input_signature:list:len3|parameter:0:int:512|parameter:1:int:0", "kernels": []}
{"iteration": 812, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:500|parameter:1:str:max", "kernels": []}
{"iteration": 813, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 814, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:495|parameter:1:int:8", "kernels": []}
{"iteration": 815, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1024|parameter:1:int:8", "kernels": []}
{"iteration": 816, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:552|parameter:1:int:8", "kernels": []}
{"iteration": 817, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 818, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 819, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:1|parameter:1:int:23", "kernels": []}
{"iteration": 820, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-12", "kernels": []}
{"iteration": 821, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:-2.10|parameter:1:int:8", "kernels": []}
{"iteration": 822, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 823, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 824, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 825, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 826, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 827, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-63.00|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 828, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.91|input_signature:list:len3|parameter:0:int:572|parameter:1:int:1024", "kernels": []}
{"iteration": 829, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1024", "kernels": []}
{"iteration": 830, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:489|parameter:1:int:16", "kernels": []}
{"iteration": 831, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:521|parameter:1:int:8", "kernels": []}
{"iteration": 832, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:492|parameter:1:int:8", "kernels": []}
{"iteration": 833, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:55", "kernels": []}
{"iteration": 834, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:16", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 835, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:562|parameter:1:int:-39", "kernels": []}
{"iteration": 836, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:482|parameter:1:int:8", "kernels": []}
{"iteration": 837, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 838, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:89", "kernels": []}
{"iteration": 839, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.82|input_signature:list:len3|parameter:0:float:-0.05|parameter:1:int:8", "kernels": []}
{"iteration": 840, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 841, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 842, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:32|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 843, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.45|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 844, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.46|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 845, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:469|parameter:1:int:8", "kernels": []}
{"iteration": 846, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1024|parameter:1:int:8", "kernels": []}
{"iteration": 847, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:0", "kernels": []}
{"iteration": 848, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:43", "kernels": []}
{"iteration": 849, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 850, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 851, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:6", "kernels": []}
{"iteration": 852, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:515|parameter:1:int:-1", "kernels": []}
{"iteration": 853, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 854, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.35|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 855, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:511|parameter:1:int:8", "kernels": []}
{"iteration": 856, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1024|parameter:1:float:inf", "kernels": []}
{"iteration": 857, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 858, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 859, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 860, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:0|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 861, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-67.46|input_signature:list:len3|parameter:0:int:1|parameter:1:int:8", "kernels": []}
{"iteration": 862, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 863, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:511|parameter:1:int:8", "kernels": []}
{"iteration": 864, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 865, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:502|parameter:1:int:8", "kernels": []}
{"iteration": 866, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:False", "kernels": []}
{"iteration": 867, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 868, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 869, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.34|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 870, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:54|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 871, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 872, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 873, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-62.46|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-36", "kernels": []}
{"iteration": 874, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 875, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:85", "kernels": []}
{"iteration": 876, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:470|parameter:1:int:8", "kernels": []}
{"iteration": 877, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:459|parameter:1:int:8", "kernels": []}
{"iteration": 878, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 879, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:inf|input_signature:list:len3|parameter:0:int:533|parameter:1:int:8", "kernels": []}
{"iteration": 880, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 881, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:551|parameter:1:int:54", "kernels": []}
{"iteration": 882, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 883, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:483|parameter:1:int:8", "kernels": []}
{"iteration": 884, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:550|parameter:1:int:8", "kernels": []}
{"iteration": 885, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 886, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 887, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.49|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 888, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:533|parameter:1:int:8", "kernels": []}
{"iteration": 889, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 890, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:inf|input_signature:list:len3|parameter:0:int:551|parameter:1:int:-36", "kernels": []}
{"iteration": 891, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:473|parameter:1:int:8", "kernels": []}
{"iteration": 892, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 893, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 894, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaLaunchKernel", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 895, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 896, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-46", "kernels": []}
{"iteration": 897, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 898, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 899, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-18", "kernels": []}
{"iteration": 900, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:1024|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 901, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-21", "kernels": []}
{"iteration": 902, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:-1.00|parameter:1:int:8", "kernels": []}
{"iteration": 903, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:498|parameter:1:int:-4", "kernels": []}
{"iteration": 904, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1024.00|input_signature:list:len3|parameter:0:int:1|parameter:1:int:8", "kernels": []}
{"iteration": 905, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:41|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 906, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1024|parameter:1:int:8", "kernels": []}
{"iteration": 907, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 908, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.86|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 909, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.85|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 910, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 911, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:569|parameter:1:int:8", "kernels": []}
{"iteration": 912, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:1024", "kernels": []}
{"iteration": 913, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 914, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 915, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:str:replicate", "kernels": []}
{"iteration": 916, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:548|parameter:1:int:8", "kernels": []}
{"iteration": 917, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:566|parameter:1:float:0.55", "kernels": []}
{"iteration": 918, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 919, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.16|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 920, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 921, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:536|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 922, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:29", "kernels": []}
{"iteration": 923, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 924, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 925, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:595|parameter:1:int:-19", "kernels": []}
{"iteration": 926, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.00|input_signature:list:len3|parameter:0:int:0|parameter:1:int:8", "kernels": []}
{"iteration": 927, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 928, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:0", "kernels": []}
{"iteration": 929, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 930, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 931, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-31", "kernels": []}
{"iteration": 932, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:59", "kernels": []}
{"iteration": 933, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:float:1.83", "kernels": []}
{"iteration": 934, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 935, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:1024|parameter:1:int:10", "kernels": []}
{"iteration": 936, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:571|parameter:1:int:8", "kernels": []}
{"iteration": 937, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-16|parameter:1:int:-29", "kernels": []}
{"iteration": 938, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 939, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:1|parameter:1:int:8", "kernels": []}
{"iteration": 940, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 941, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.00|input_signature:list:len3|parameter:0:int:527|parameter:1:int:8", "kernels": []}
{"iteration": 942, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:489|parameter:1:int:8", "kernels": []}
{"iteration": 943, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:56", "kernels": []}
{"iteration": 944, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.88|input_signature:list:len3|parameter:0:int:535|parameter:1:int:8", "kernels": []}
{"iteration": 945, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.62|input_signature:list:len3|parameter:0:float:-3.00|parameter:1:int:8", "kernels": []}
{"iteration": 946, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:484|parameter:1:int:8", "kernels": []}
{"iteration": 947, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 948, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:478|parameter:1:int:8", "kernels": []}
{"iteration": 949, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 950, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-16", "kernels": []}
{"iteration": 951, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 952, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 953, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:63.00|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 954, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:534|parameter:1:int:-8", "kernels": []}
{"iteration": 955, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 956, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.62|input_signature:list:len3|parameter:0:int:483|parameter:1:int:8", "kernels": []}
{"iteration": 957, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:483|parameter:1:int:-16", "kernels": []}
{"iteration": 958, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaMemsetAsync", "cudaLaunchKernel", "cudaStreamSynchronize", "ampere_sgemm_32x128_tn", "Memset (Device)", "cudaDeviceSynchronize"]}
{"iteration": 959, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1|parameter:1:int:8", "kernels": []}
{"iteration": 960, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:False", "kernels": []}
{"iteration": 961, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 962, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 963, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 964, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:551|parameter:1:int:8", "kernels": []}
{"iteration": 965, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:35", "kernels": []}
{"iteration": 966, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:543|parameter:1:int:-986", "kernels": []}
{"iteration": 967, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:sum|parameter:1:int:8", "kernels": []}
{"iteration": 968, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:505|parameter:1:int:8", "kernels": []}
{"iteration": 969, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:537|parameter:1:str:max", "kernels": []}
{"iteration": 970, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 971, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:543|parameter:1:int:8", "kernels": []}
{"iteration": 972, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 973, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:float:-1026.54", "kernels": []}
{"iteration": 974, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 975, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:10", "kernels": []}
{"iteration": 976, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 977, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.91|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 978, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.04|input_signature:list:len3|parameter:0:int:462|parameter:1:str:reflect", "kernels": []}
{"iteration": 979, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:zeros|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 980, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:1024|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 981, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:35", "kernels": []}
{"iteration": 982, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:559|parameter:1:float:3.22", "kernels": []}
{"iteration": 983, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:100", "kernels": []}
{"iteration": 984, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:495|parameter:1:int:66", "kernels": []}
{"iteration": 985, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 986, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.84|input_signature:list:len3|parameter:0:int:553|parameter:1:int:0", "kernels": []}
{"iteration": 987, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:486|parameter:1:int:8", "kernels": []}
{"iteration": 988, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:110|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-40", "kernels": []}
{"iteration": 989, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:int:6", "kernels": []}
{"iteration": 990, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-22|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 991, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 992, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 993, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:0.00|parameter:1:int:8", "kernels": []}
{"iteration": 994, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:float:1.18|parameter:1:int:8", "kernels": []}
{"iteration": 995, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.17|input_signature:list:len3|parameter:0:str:mean|parameter:1:int:8", "kernels": []}
{"iteration": 996, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:77", "kernels": []}
{"iteration": 997, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:53", "kernels": []}
{"iteration": 998, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-5.17|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 999, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1000, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-18|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 1001, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:26", "kernels": []}
{"iteration": 1002, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.28|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1003, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:sum|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1004, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:False", "kernels": []}
{"iteration": 1005, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-26|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1006, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1007, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1008, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1009, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1010, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 1011, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:inf|input_signature:list:len3|parameter:0:int:563|parameter:1:int:8", "kernels": []}
{"iteration": 1012, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:-1|parameter:1:int:8", "kernels": []}
{"iteration": 1013, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-75|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 1014, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.79|input_signature:list:len3|parameter:0:int:500|parameter:1:int:-1", "kernels": []}
{"iteration": 1015, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 1016, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1017, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1018, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:1|parameter:1:int:8", "kernels": []}
{"iteration": 1019, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.55|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 1020, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.93|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1021, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 1022, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1023, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 1024, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1025, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1026, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-31|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:False", "kernels": []}
{"iteration": 1027, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1028, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-3", "kernels": []}
{"iteration": 1029, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 1030, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:486|parameter:1:str:reflect", "kernels": []}
{"iteration": 1031, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.86|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-48", "kernels": []}
{"iteration": 1032, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:18", "kernels": []}
{"iteration": 1033, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1024", "kernels": []}
{"iteration": 1034, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:569|parameter:1:int:-1022", "kernels": []}
{"iteration": 1035, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1036, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:zeros", "kernels": []}
{"iteration": 1037, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1038, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:12", "kernels": []}
{"iteration": 1039, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1024|parameter:1:int:40", "kernels": []}
{"iteration": 1040, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 1041, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.00|input_signature:list:len3|parameter:0:int:-51|parameter:1:int:8", "kernels": []}
{"iteration": 1042, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:62", "kernels": []}
{"iteration": 1043, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1044, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:-63.00", "kernels": []}
{"iteration": 1045, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:489|parameter:1:int:8", "kernels": []}
{"iteration": 1046, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1047, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1048, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-23", "kernels": []}
{"iteration": 1049, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:510|parameter:1:int:8", "kernels": []}
{"iteration": 1050, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.32|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 1051, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:512|parameter:1:int:45", "kernels": []}
{"iteration": 1052, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:492|parameter:1:int:15", "kernels": []}
{"iteration": 1053, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 1054, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-1024|input_signature:list:len3|parameter:0:float:-1.00|parameter:1:int:8", "kernels": []}
{"iteration": 1055, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:35|input_signature:list:len3|parameter:0:int:569|parameter:1:int:8", "kernels": []}
{"iteration": 1056, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:610|parameter:1:int:6", "kernels": []}
{"iteration": 1057, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:511|parameter:1:int:8", "kernels": []}
{"iteration": 1058, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-63", "kernels": []}
{"iteration": 1059, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1060, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:459|parameter:1:float:-0.00", "kernels": []}
{"iteration": 1061, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.73|input_signature:list:len3|parameter:0:int:523|parameter:1:int:8", "kernels": []}
{"iteration": 1062, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:495|parameter:1:int:8", "kernels": []}
{"iteration": 1063, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-40", "kernels": []}
{"iteration": 1064, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 1065, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:49", "kernels": []}
{"iteration": 1066, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 1067, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 1068, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-39|input_signature:list:len3|parameter:0:int:514|parameter:1:int:8", "kernels": []}
{"iteration": 1069, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:76|input_signature:list:len3|parameter:0:int:463|parameter:1:int:8", "kernels": []}
{"iteration": 1070, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:506|parameter:1:int:8", "kernels": []}
{"iteration": 1071, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:472|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1072, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:1024|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1073, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1074, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:527|parameter:1:int:58", "kernels": []}
{"iteration": 1075, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:64", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1076, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-1|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1077, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:1024|parameter:1:float:63.00", "kernels": []}
{"iteration": 1078, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 1079, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:502|parameter:1:int:8", "kernels": []}
{"iteration": 1080, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:511|parameter:1:int:-7", "kernels": []}
{"iteration": 1081, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.82|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:False", "kernels": []}
{"iteration": 1082, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1083, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1084, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 1085, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1086, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-56", "kernels": []}
{"iteration": 1087, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:1024|parameter:1:str:max", "kernels": []}
{"iteration": 1088, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1089, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-16|parameter:1:int:8", "kernels": []}
{"iteration": 1090, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.31|input_signature:list:len3|parameter:0:float:-inf|parameter:1:int:8", "kernels": []}
{"iteration": 1091, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:541|parameter:1:int:8", "kernels": []}
{"iteration": 1092, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 1093, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:0.37|parameter:1:int:50", "kernels": []}
{"iteration": 1094, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:480|parameter:1:int:49", "kernels": []}
{"iteration": 1095, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:64|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1096, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1097, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 1098, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 1099, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-63.00|input_signature:list:len3|parameter:0:str:circular|parameter:1:int:-89", "kernels": []}
{"iteration": 1100, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:51", "kernels": []}
{"iteration": 1101, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:29", "kernels": []}
{"iteration": 1102, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.52|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1103, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:37", "kernels": []}
{"iteration": 1104, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1105, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1106, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:3", "kernels": []}
{"iteration": 1107, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.02|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1108, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-17", "kernels": []}
{"iteration": 1109, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.70|input_signature:list:len3|parameter:0:int:512|parameter:1:int:65", "kernels": []}
{"iteration": 1110, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1111, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:555|parameter:1:int:1024", "kernels": []}
{"iteration": 1112, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-27", "kernels": []}
{"iteration": 1113, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1114, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:53", "kernels": []}
{"iteration": 1115, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:-0.00|parameter:1:int:-41", "kernels": []}
{"iteration": 1116, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1117, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1118, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:4.06|input_signature:list:len3|parameter:0:int:512|parameter:1:int:10", "kernels": []}
{"iteration": 1119, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 1120, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 1121, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1122, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1123, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:575|parameter:1:int:8", "kernels": []}
{"iteration": 1124, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:524|parameter:1:int:8", "kernels": []}
{"iteration": 1125, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-5", "kernels": []}
{"iteration": 1126, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.54|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1127, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.11|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 1128, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:circular|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1", "kernels": []}
{"iteration": 1129, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:520|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1130, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.32|input_signature:list:len3|parameter:0:int:572|parameter:1:int:8", "kernels": []}
{"iteration": 1131, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1132, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1024", "kernels": []}
{"iteration": 1133, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1024|parameter:1:int:8", "kernels": []}
{"iteration": 1134, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:inf|input_signature:list:len3|parameter:0:int:493|parameter:1:int:8", "kernels": []}
{"iteration": 1135, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:503|parameter:1:int:8", "kernels": []}
{"iteration": 1136, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:480|parameter:1:int:70", "kernels": []}
{"iteration": 1137, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:535|parameter:1:int:8", "kernels": []}
{"iteration": 1138, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1139, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.67|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-2", "kernels": []}
{"iteration": 1140, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1141, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.22|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1142, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:-1024.00", "kernels": []}
{"iteration": 1143, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.99|input_signature:list:len3|parameter:0:int:532|parameter:1:int:1", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1144, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1|parameter:1:int:8", "kernels": []}
{"iteration": 1145, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:48", "kernels": []}
{"iteration": 1146, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1147, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1148, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:529|parameter:1:int:8", "kernels": []}
{"iteration": 1149, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-16", "kernels": []}
{"iteration": 1150, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:-1.00", "kernels": []}
{"iteration": 1151, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-51", "kernels": []}
{"iteration": 1152, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1153, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.68|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1154, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1155, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:516|parameter:1:int:8", "kernels": []}
{"iteration": 1156, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:46", "kernels": []}
{"iteration": 1157, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-inf|input_signature:list:len3|parameter:0:int:540|parameter:1:int:8", "kernels": []}
{"iteration": 1158, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:False", "kernels": []}
{"iteration": 1159, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:566|parameter:1:int:8", "kernels": []}
{"iteration": 1160, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-26", "kernels": []}
{"iteration": 1161, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1162, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:470|parameter:1:int:70", "kernels": []}
{"iteration": 1163, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:482|parameter:1:int:8", "kernels": []}
{"iteration": 1164, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-47", "kernels": []}
{"iteration": 1165, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:16|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1166, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.00|input_signature:list:len3|parameter:0:int:494|parameter:1:int:8", "kernels": []}
{"iteration": 1167, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1168, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.91|input_signature:list:len3|parameter:0:int:0|parameter:1:int:8", "kernels": []}
{"iteration": 1169, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 1170, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:32|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1171, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.55|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1172, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.87|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1173, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 1174, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1175, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:514|parameter:1:int:8", "kernels": []}
{"iteration": 1176, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:546|parameter:1:int:8", "kernels": []}
{"iteration": 1177, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:2.87|parameter:1:int:8", "kernels": []}
{"iteration": 1178, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:500|parameter:1:int:8", "kernels": []}
{"iteration": 1179, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:replicate", "kernels": []}
{"iteration": 1180, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:87|input_signature:list:len3|parameter:0:int:473|parameter:1:int:46", "kernels": []}
{"iteration": 1181, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:13", "kernels": []}
{"iteration": 1182, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1183, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 1184, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:60|input_signature:list:len3|parameter:0:int:524|parameter:1:int:8", "kernels": []}
{"iteration": 1185, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-30", "kernels": []}
{"iteration": 1186, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1187, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 1188, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-16", "kernels": []}
{"iteration": 1189, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1190, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1191, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:28", "kernels": []}
{"iteration": 1192, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1193, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:477|parameter:1:int:8", "kernels": []}
{"iteration": 1194, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-inf|input_signature:list:len3|parameter:0:int:546|parameter:1:int:8", "kernels": []}
{"iteration": 1195, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1196, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-65.45|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1197, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1198, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1199, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1200, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:59|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1201, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.34|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1202, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:516|parameter:1:int:8", "kernels": []}
{"iteration": 1203, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.89|input_signature:list:len3|parameter:0:int:465|parameter:1:int:8", "kernels": []}
{"iteration": 1204, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1205, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.17|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1206, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1207, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:1.00", "kernels": ["Activity Buffer Request", "cudaMemsetAsync", "cudaLaunchKernel", "cudaStreamSynchronize", "ampere_sgemm_32x128_tn", "Memset (Device)", "cudaDeviceSynchronize"]}
{"iteration": 1208, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:-51", "kernels": []}
{"iteration": 1209, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1210, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 1211, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:46", "kernels": []}
{"iteration": 1212, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:514|parameter:1:int:8", "kernels": []}
{"iteration": 1213, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-10", "kernels": []}
{"iteration": 1214, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-4", "kernels": []}
{"iteration": 1215, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1216, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:-1024", "kernels": []}
{"iteration": 1217, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1218, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:515|parameter:1:int:8", "kernels": []}
{"iteration": 1219, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1220, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1221, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.42|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:-5", "kernels": []}
{"iteration": 1222, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1223, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:0.50|parameter:1:int:8", "kernels": []}
{"iteration": 1224, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 1225, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:50|parameter:1:int:-1", "kernels": []}
{"iteration": 1226, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1227, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1024", "kernels": []}
{"iteration": 1228, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-26", "kernels": []}
{"iteration": 1229, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1230, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.61|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1231, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:491|parameter:1:int:8", "kernels": []}
{"iteration": 1232, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:460|parameter:1:int:8", "kernels": []}
{"iteration": 1233, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1234, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:1024|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1235, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1016", "kernels": []}
{"iteration": 1236, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 1237, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:458|parameter:1:int:98", "kernels": []}
{"iteration": 1238, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:549|parameter:1:int:-16", "kernels": []}
{"iteration": 1239, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:563|parameter:1:int:-9", "kernels": []}
{"iteration": 1240, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1241, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-63.00|input_signature:list:len3|parameter:0:int:0|parameter:1:int:8", "kernels": []}
{"iteration": 1242, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.23|input_signature:list:len3|parameter:0:int:512|parameter:1:int:67", "kernels": []}
{"iteration": 1243, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.98|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1244, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.00|input_signature:list:len3|parameter:0:int:500|parameter:1:int:8", "kernels": []}
{"iteration": 1245, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1246, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1247, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.83|input_signature:list:len3|parameter:0:int:512|parameter:1:int:17", "kernels": []}
{"iteration": 1248, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1249, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:48", "kernels": []}
{"iteration": 1250, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.49|input_signature:list:len3|parameter:0:int:496|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1251, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 1252, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:453|parameter:1:int:8", "kernels": []}
{"iteration": 1253, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1254, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-24", "kernels": []}
{"iteration": 1255, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.55|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 1256, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1257, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:544|parameter:1:str:max", "kernels": []}
{"iteration": 1258, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:0", "kernels": []}
{"iteration": 1259, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1260, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-29", "kernels": []}
{"iteration": 1261, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1262, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:63.00", "kernels": []}
{"iteration": 1263, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 1264, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:46", "kernels": []}
{"iteration": 1265, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:479|parameter:1:int:8", "kernels": []}
{"iteration": 1266, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1267, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:546|parameter:1:int:8", "kernels": []}
{"iteration": 1268, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:-100000000000000000000.00|parameter:1:int:8", "kernels": []}
{"iteration": 1269, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:False", "kernels": []}
{"iteration": 1270, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 1271, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1272, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1273, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:0.00", "kernels": []}
{"iteration": 1274, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1275, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:55", "kernels": []}
{"iteration": 1276, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:501|parameter:1:bool:False", "kernels": []}
{"iteration": 1277, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:-63.00", "kernels": []}
{"iteration": 1278, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.52|input_signature:list:len3|parameter:0:int:512|parameter:1:int:65", "kernels": []}
{"iteration": 1279, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1280, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:520|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1281, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:486|parameter:1:int:-14", "kernels": []}
{"iteration": 1282, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.40|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1283, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 1284, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 1285, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1286, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:0|parameter:1:int:8", "kernels": []}
{"iteration": 1287, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1288, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-18", "kernels": []}
{"iteration": 1289, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 1290, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:453|parameter:1:int:8", "kernels": []}
{"iteration": 1291, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1292, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-19", "kernels": []}
{"iteration": 1293, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1294, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1295, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-3", "kernels": []}
{"iteration": 1296, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:mean|parameter:1:int:8", "kernels": []}
{"iteration": 1297, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 1298, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1299, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:545|parameter:1:int:8", "kernels": []}
{"iteration": 1300, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:466|parameter:1:int:-5", "kernels": []}
{"iteration": 1301, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1024.00|input_signature:list:len3|parameter:0:int:-16|parameter:1:int:8", "kernels": []}
{"iteration": 1302, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.50|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1303, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1304, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1305, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 1306, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1307, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-63.00|input_signature:list:len3|parameter:0:int:-16|parameter:1:int:46", "kernels": []}
{"iteration": 1308, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.95|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1309, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.60|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-4", "kernels": []}
{"iteration": 1310, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 1311, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1312, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:-0.69|parameter:1:int:8", "kernels": []}
{"iteration": 1313, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:112", "kernels": []}
{"iteration": 1314, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1315, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:23", "kernels": []}
{"iteration": 1316, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.21|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1317, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-96|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:False", "kernels": []}
{"iteration": 1318, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:False", "kernels": []}
{"iteration": 1319, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:47", "kernels": []}
{"iteration": 1320, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:0", "kernels": []}
{"iteration": 1321, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-35", "kernels": []}
{"iteration": 1322, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1323, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.48|input_signature:list:len3|parameter:0:int:512|parameter:1:int:60", "kernels": []}
{"iteration": 1324, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:542|parameter:1:int:-22", "kernels": []}
{"iteration": 1325, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.00|input_signature:list:len3|parameter:0:int:-1067|parameter:1:int:1", "kernels": []}
{"iteration": 1326, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:500|parameter:1:int:8", "kernels": []}
{"iteration": 1327, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:534|parameter:1:int:8", "kernels": []}
{"iteration": 1328, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-21", "kernels": []}
{"iteration": 1329, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:-1|parameter:1:int:12", "kernels": []}
{"iteration": 1330, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:circular|input_signature:list:len3|parameter:0:int:517|parameter:1:int:8", "kernels": []}
{"iteration": 1331, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1024|parameter:1:bool:False", "kernels": []}
{"iteration": 1332, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:47", "kernels": []}
{"iteration": 1333, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1334, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:False", "kernels": []}
{"iteration": 1335, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 1336, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:561|parameter:1:int:8", "kernels": []}
{"iteration": 1337, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:20", "kernels": []}
{"iteration": 1338, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:561|parameter:1:int:10", "kernels": []}
{"iteration": 1339, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:1024|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1340, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1341, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 1342, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-16", "kernels": []}
{"iteration": 1343, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:578|parameter:1:float:-61.76", "kernels": []}
{"iteration": 1344, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:63.00|input_signature:list:len3|parameter:0:int:454|parameter:1:int:8", "kernels": []}
{"iteration": 1345, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1024|parameter:1:int:70", "kernels": []}
{"iteration": 1346, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:0", "kernels": []}
{"iteration": 1347, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.64|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1348, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-44", "kernels": []}
{"iteration": 1349, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:reflect|input_signature:list:len3|parameter:0:int:512|parameter:1:float:3.52", "kernels": []}
{"iteration": 1350, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:548|parameter:1:int:8", "kernels": []}
{"iteration": 1351, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-40", "kernels": []}
{"iteration": 1352, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:0|parameter:1:int:16", "kernels": []}
{"iteration": 1353, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.76|input_signature:list:len3|parameter:0:int:512|parameter:1:int:16", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1354, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:486|parameter:1:int:8", "kernels": []}
{"iteration": 1355, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.83|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 1356, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:467|parameter:1:int:8", "kernels": []}
{"iteration": 1357, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:521|parameter:1:int:8", "kernels": []}
{"iteration": 1358, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:82|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1359, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:1024", "kernels": []}
{"iteration": 1360, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-15", "kernels": []}
{"iteration": 1361, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:84", "kernels": []}
{"iteration": 1362, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:479|parameter:1:int:8", "kernels": []}
{"iteration": 1363, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:16", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1364, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1365, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 1366, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:35|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1367, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1368, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:16|parameter:1:int:0", "kernels": []}
{"iteration": 1369, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 1370, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.82|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1371, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1372, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1373, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1374, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:459|parameter:1:int:8", "kernels": []}
{"iteration": 1375, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.86|input_signature:list:len3|parameter:0:int:513|parameter:1:int:8", "kernels": []}
{"iteration": 1376, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1024.00|input_signature:list:len3|parameter:0:int:527|parameter:1:int:8", "kernels": []}
{"iteration": 1377, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:85|input_signature:list:len3|parameter:0:int:534|parameter:1:int:8", "kernels": []}
{"iteration": 1378, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-16|parameter:1:int:8", "kernels": []}
{"iteration": 1379, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:reflect|parameter:1:int:8", "kernels": []}
{"iteration": 1380, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:23|input_signature:list:len3|parameter:0:int:503|parameter:1:int:8", "kernels": []}
{"iteration": 1381, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 1382, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:455|parameter:1:int:8", "kernels": []}
{"iteration": 1383, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 1384, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.80|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 1385, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1386, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.62|input_signature:list:len3|parameter:0:int:512|parameter:1:int:43", "kernels": []}
{"iteration": 1387, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:int:63", "kernels": []}
{"iteration": 1388, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.00|input_signature:list:len3|parameter:0:int:-16|parameter:1:int:8", "kernels": []}
{"iteration": 1389, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.20|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1390, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.74|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-973", "kernels": []}
{"iteration": 1391, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1392, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:str:mean", "kernels": []}
{"iteration": 1393, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:6.23", "kernels": []}
{"iteration": 1394, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-49", "kernels": []}
{"iteration": 1395, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:1.00|parameter:1:int:62", "kernels": []}
{"iteration": 1396, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:replicate", "kernels": []}
{"iteration": 1397, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.30|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 1398, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-28", "kernels": []}
{"iteration": 1399, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:455|parameter:1:int:8", "kernels": []}
{"iteration": 1400, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-12", "kernels": []}
{"iteration": 1401, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1402, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:0|parameter:1:int:8", "kernels": []}
{"iteration": 1403, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1", "kernels": []}
{"iteration": 1404, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.78|input_signature:list:len3|parameter:0:int:512|parameter:1:str:mean", "kernels": []}
{"iteration": 1405, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 1406, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:51", "kernels": []}
{"iteration": 1407, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-73|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1408, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 1409, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.28|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1410, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 1411, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 1412, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 1413, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1024", "kernels": []}
{"iteration": 1414, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:40|input_signature:list:len3|parameter:0:int:512|parameter:1:int:55", "kernels": []}
{"iteration": 1415, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.26|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1416, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1417, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.75|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-29", "kernels": []}
{"iteration": 1418, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:49|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1419, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1420, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:459|parameter:1:int:-52", "kernels": []}
{"iteration": 1421, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-72|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 1422, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1423, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 1424, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-84|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:False", "kernels": []}
{"iteration": 1425, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1426, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 1427, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:-100000000000000000000.00|parameter:1:int:40", "kernels": []}
{"iteration": 1428, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:497|parameter:1:int:40", "kernels": []}
{"iteration": 1429, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1430, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.99|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1431, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:571|parameter:1:int:8", "kernels": []}
{"iteration": 1432, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:53", "kernels": []}
{"iteration": 1433, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:537|parameter:1:int:8", "kernels": []}
{"iteration": 1434, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1", "kernels": []}
{"iteration": 1435, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:449|parameter:1:int:25", "kernels": []}
{"iteration": 1436, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1437, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1438, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-24|input_signature:list:len3|parameter:0:int:454|parameter:1:float:inf", "kernels": []}
{"iteration": 1439, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:zeros", "kernels": []}
{"iteration": 1440, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:63.00|input_signature:list:len3|parameter:0:int:515|parameter:1:int:8", "kernels": []}
{"iteration": 1441, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1442, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-16", "kernels": []}
{"iteration": 1443, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:560|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1444, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1445, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 1446, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:571|parameter:1:int:8", "kernels": []}
{"iteration": 1447, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:circular|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1448, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:0|parameter:1:int:8", "kernels": []}
{"iteration": 1449, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:423|parameter:1:int:8", "kernels": []}
{"iteration": 1450, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1451, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-27", "kernels": []}
{"iteration": 1452, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.78|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1453, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:-3.24|parameter:1:int:40", "kernels": []}
{"iteration": 1454, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 1455, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1456, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.71|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1457, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:544|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1458, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:-16", "kernels": []}
{"iteration": 1459, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.82|input_signature:list:len3|parameter:0:int:516|parameter:1:int:8", "kernels": []}
{"iteration": 1460, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1461, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:546|parameter:1:int:8", "kernels": []}
{"iteration": 1462, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1463, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:69", "kernels": []}
{"iteration": 1464, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1465, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1466, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:521|parameter:1:int:-21", "kernels": []}
{"iteration": 1467, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1468, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.69|input_signature:list:len3|parameter:0:int:512|parameter:1:int:64", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 1469, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1470, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:514|parameter:1:int:8", "kernels": []}
{"iteration": 1471, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:16", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1472, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:25", "kernels": []}
{"iteration": 1473, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 1474, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1475, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-30", "kernels": []}
{"iteration": 1476, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.55|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-7", "kernels": []}
{"iteration": 1477, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:49", "kernels": []}
{"iteration": 1478, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1479, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:100000000000000000000.00|parameter:1:int:8", "kernels": []}
{"iteration": 1480, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:37|parameter:1:int:8", "kernels": []}
{"iteration": 1481, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:45|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-48", "kernels": []}
{"iteration": 1482, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.00|input_signature:list:len3|parameter:0:int:469|parameter:1:int:8", "kernels": []}
{"iteration": 1483, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:1024|parameter:1:int:-10", "kernels": []}
{"iteration": 1484, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 1485, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1024.00|input_signature:list:len3|parameter:0:float:4.61|parameter:1:int:-28", "kernels": []}
{"iteration": 1486, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1487, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.64|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1488, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:545|parameter:1:int:8", "kernels": []}
{"iteration": 1489, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:16", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1490, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.48|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1491, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1492, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:573|parameter:1:int:8", "kernels": []}
{"iteration": 1493, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.30|input_signature:list:len3|parameter:0:float:1.46|parameter:1:int:8", "kernels": []}
{"iteration": 1494, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.60|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 1495, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:16|parameter:1:int:-2", "kernels": []}
{"iteration": 1496, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1024|parameter:1:float:0.00", "kernels": []}
{"iteration": 1497, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:476|parameter:1:int:-16", "kernels": []}
{"iteration": 1498, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:38|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1499, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-6", "kernels": []}
{"iteration": 1500, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 1501, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:0|parameter:1:int:72", "kernels": []}
{"iteration": 1502, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.84|input_signature:list:len3|parameter:0:str:zeros|parameter:1:int:8", "kernels": []}
{"iteration": 1503, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-16", "kernels": []}
{"iteration": 1504, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1505, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1506, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1507, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-25", "kernels": []}
{"iteration": 1508, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 1509, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:535|parameter:1:int:8", "kernels": []}
{"iteration": 1510, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1511, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1512, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:float:-61.97", "kernels": []}
{"iteration": 1513, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:571|parameter:1:bool:False", "kernels": []}
{"iteration": 1514, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1515, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-16|parameter:1:int:8", "kernels": []}
{"iteration": 1516, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:544|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1517, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1518, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:498|parameter:1:int:-55", "kernels": []}
{"iteration": 1519, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:sum|parameter:1:int:8", "kernels": []}
{"iteration": 1520, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:449|parameter:1:int:8", "kernels": []}
{"iteration": 1521, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.01|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-18", "kernels": []}
{"iteration": 1522, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.95|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1", "kernels": []}
{"iteration": 1523, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:550|parameter:1:int:-12", "kernels": []}
{"iteration": 1524, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 1525, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.66|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 1526, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:448|parameter:1:int:49", "kernels": []}
{"iteration": 1527, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.73|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 1528, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:0|parameter:1:int:-16", "kernels": []}
{"iteration": 1529, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:69", "kernels": []}
{"iteration": 1530, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-46", "kernels": []}
{"iteration": 1531, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:49", "kernels": []}
{"iteration": 1532, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:511|parameter:1:int:8", "kernels": []}
{"iteration": 1533, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-27|parameter:1:int:8", "kernels": []}
{"iteration": 1534, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 1535, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:41", "kernels": []}
{"iteration": 1536, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-16|parameter:1:int:8", "kernels": []}
{"iteration": 1537, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.76|input_signature:list:len3|parameter:0:int:477|parameter:1:int:8", "kernels": []}
{"iteration": 1538, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-52", "kernels": []}
{"iteration": 1539, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-21", "kernels": []}
{"iteration": 1540, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:-34", "kernels": []}
{"iteration": 1541, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 1542, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:502|parameter:1:int:2", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1543, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1544, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-49", "kernels": []}
{"iteration": 1545, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1546, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1024", "kernels": []}
{"iteration": 1547, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:503|parameter:1:int:8", "kernels": []}
{"iteration": 1548, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1549, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1550, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:456|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1551, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1552, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:51", "kernels": []}
{"iteration": 1553, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1554, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1555, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:-1.00|parameter:1:int:8", "kernels": []}
{"iteration": 1556, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:5.51|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 1557, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:0|parameter:1:int:8", "kernels": []}
{"iteration": 1558, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1", "kernels": []}
{"iteration": 1559, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-44", "kernels": []}
{"iteration": 1560, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-38", "kernels": []}
{"iteration": 1561, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:10", "kernels": []}
{"iteration": 1562, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:570|parameter:1:int:8", "kernels": []}
{"iteration": 1563, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1564, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1565, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 1566, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 1567, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-53", "kernels": []}
{"iteration": 1568, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:21", "kernels": []}
{"iteration": 1569, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-4", "kernels": []}
{"iteration": 1570, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:sum", "kernels": []}
{"iteration": 1571, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:508|parameter:1:int:-6", "kernels": []}
{"iteration": 1572, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:-0.21", "kernels": []}
{"iteration": 1573, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.66|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 1574, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.76|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1575, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 1576, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1577, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-61|parameter:1:int:64", "kernels": []}
{"iteration": 1578, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1579, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 1580, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1581, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-8", "kernels": []}
{"iteration": 1582, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.31|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 1583, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.21|input_signature:list:len3|parameter:0:int:498|parameter:1:int:8", "kernels": []}
{"iteration": 1584, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1585, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 1586, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1587, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 1588, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-16|parameter:1:int:8", "kernels": []}
{"iteration": 1589, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:7", "kernels": []}
{"iteration": 1590, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:-1024.00|parameter:1:int:54", "kernels": []}
{"iteration": 1591, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.00|input_signature:list:len3|parameter:0:int:526|parameter:1:int:8", "kernels": []}
{"iteration": 1592, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.54|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1024", "kernels": []}
{"iteration": 1593, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1594, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.26|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 1595, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.60|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1596, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1597, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1598, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1599, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:18", "kernels": []}
{"iteration": 1600, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1601, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1602, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1603, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1604, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1605, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-12|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 1606, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.59|input_signature:list:len3|parameter:0:int:483|parameter:1:int:-11", "kernels": []}
{"iteration": 1607, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1024.00|input_signature:list:len3|parameter:0:int:486|parameter:1:int:8", "kernels": []}
{"iteration": 1608, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1024", "kernels": []}
{"iteration": 1609, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.29|input_signature:list:len3|parameter:0:int:1024|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1610, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1611, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:547|parameter:1:int:8", "kernels": []}
{"iteration": 1612, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:reflect|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1613, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:490|parameter:1:int:60", "kernels": []}
{"iteration": 1614, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1615, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1616, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:55", "kernels": []}
{"iteration": 1617, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:circular|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1618, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:9|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1619, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1620, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:492|parameter:1:int:8", "kernels": []}
{"iteration": 1621, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:False", "kernels": []}
{"iteration": 1622, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:542|parameter:1:int:8", "kernels": []}
{"iteration": 1623, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1624, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:37", "kernels": []}
{"iteration": 1625, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1626, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:511|parameter:1:int:8", "kernels": []}
{"iteration": 1627, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.25|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1628, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1629, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:467|parameter:1:int:8", "kernels": []}
{"iteration": 1630, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1631, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1024", "kernels": []}
{"iteration": 1632, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:50|parameter:1:int:1024", "kernels": []}
{"iteration": 1633, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1634, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:568|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1635, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.75|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1636, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.74|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1637, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1638, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1639, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:571|parameter:1:int:8", "kernels": []}
{"iteration": 1640, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:481|parameter:1:str:max", "kernels": []}
{"iteration": 1641, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:544|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1642, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1643, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:48", "kernels": []}
{"iteration": 1644, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:468|parameter:1:int:-23", "kernels": []}
{"iteration": 1645, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:1|parameter:1:bool:True", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1646, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1|parameter:1:int:8", "kernels": []}
{"iteration": 1647, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.88|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:-9", "kernels": []}
{"iteration": 1648, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:26", "kernels": []}
{"iteration": 1649, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:0|parameter:1:int:8", "kernels": []}
{"iteration": 1650, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:452|parameter:1:int:8", "kernels": []}
{"iteration": 1651, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 1652, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:4.07|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1653, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:526|parameter:1:int:8", "kernels": []}
{"iteration": 1654, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1655, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:25", "kernels": []}
{"iteration": 1656, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.66|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1657, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.12|input_signature:list:len3|parameter:0:int:-1|parameter:1:int:8", "kernels": []}
{"iteration": 1658, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1659, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.00|input_signature:list:len3|parameter:0:int:525|parameter:1:int:58", "kernels": []}
{"iteration": 1660, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.56|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 1661, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-9", "kernels": []}
{"iteration": 1662, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:63", "kernels": []}
{"iteration": 1663, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1664, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:float:-100000000000000000000.00|parameter:1:int:8", "kernels": []}
{"iteration": 1665, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-7", "kernels": []}
{"iteration": 1666, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1667, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.74|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-29", "kernels": []}
{"iteration": 1668, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1669, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:0", "kernels": []}
{"iteration": 1670, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:nan", "kernels": []}
{"iteration": 1671, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:7", "kernels": []}
{"iteration": 1672, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:545|parameter:1:int:8", "kernels": []}
{"iteration": 1673, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1674, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-17", "kernels": []}
{"iteration": 1675, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:40", "kernels": []}
{"iteration": 1676, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1677, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1024", "kernels": []}
{"iteration": 1678, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.35|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 1679, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:512|parameter:1:int:26", "kernels": []}
{"iteration": 1680, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:65", "kernels": []}
{"iteration": 1681, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1682, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1", "kernels": []}
{"iteration": 1683, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:replicate|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1684, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1", "kernels": []}
{"iteration": 1685, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.00|input_signature:list:len3|parameter:0:int:496|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1686, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-40", "kernels": []}
{"iteration": 1687, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 1688, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:511|parameter:1:int:8", "kernels": []}
{"iteration": 1689, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:-1024.00", "kernels": []}
{"iteration": 1690, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1691, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.44|input_signature:list:len3|parameter:0:int:542|parameter:1:int:0", "kernels": []}
{"iteration": 1692, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:516|parameter:1:int:8", "kernels": []}
{"iteration": 1693, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:520|parameter:1:int:8", "kernels": []}
{"iteration": 1694, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1024", "kernels": []}
{"iteration": 1695, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:570|parameter:1:int:8", "kernels": []}
{"iteration": 1696, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1024", "kernels": []}
{"iteration": 1697, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:486|parameter:1:int:-9", "kernels": []}
{"iteration": 1698, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-16|parameter:1:int:8", "kernels": []}
{"iteration": 1699, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:3", "kernels": []}
{"iteration": 1700, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 1701, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:525|parameter:1:int:-29", "kernels": []}
{"iteration": 1702, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:561|parameter:1:int:8", "kernels": []}
{"iteration": 1703, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.85|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 1704, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1705, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:456|parameter:1:int:-50", "kernels": []}
{"iteration": 1706, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-3", "kernels": []}
{"iteration": 1707, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:563|parameter:1:int:8", "kernels": []}
{"iteration": 1708, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1709, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.36|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaDeviceSynchronize", "Activity Buffer Request", "cudaMalloc", "cudaStreamSynchronize", "cudaStreamIsCapturing"]}
{"iteration": 1710, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-46", "kernels": []}
{"iteration": 1711, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1712, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1713, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:10|parameter:1:int:977", "kernels": []}
{"iteration": 1714, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:9", "kernels": []}
{"iteration": 1715, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 1716, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 1717, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 1718, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1", "kernels": []}
{"iteration": 1719, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1720, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1721, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 1722, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:-100000000000000000000.00|parameter:1:int:8", "kernels": []}
{"iteration": 1723, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 1724, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:-63.00", "kernels": []}
{"iteration": 1725, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:453|parameter:1:int:8", "kernels": []}
{"iteration": 1726, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.51|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1727, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.22|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-14", "kernels": []}
{"iteration": 1728, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-25", "kernels": []}
{"iteration": 1729, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1730, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1731, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1732, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:sum|parameter:1:int:8", "kernels": []}
{"iteration": 1733, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:68", "kernels": []}
{"iteration": 1734, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1735, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:527|parameter:1:int:-1063", "kernels": []}
{"iteration": 1736, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1737, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:476|parameter:1:bool:True", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1738, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:554|parameter:1:float:1.00", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1739, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1740, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 1741, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 1742, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1743, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.67|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1744, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 1745, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:63", "kernels": []}
{"iteration": 1746, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:1|parameter:1:int:8", "kernels": []}
{"iteration": 1747, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 1748, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1749, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:511|parameter:1:int:5", "kernels": []}
{"iteration": 1750, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:-63.11", "kernels": []}
{"iteration": 1751, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.62|input_signature:list:len3|parameter:0:str:replicate|parameter:1:int:8", "kernels": []}
{"iteration": 1752, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 1753, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:508|parameter:1:int:-2", "kernels": []}
{"iteration": 1754, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1|parameter:1:int:8", "kernels": []}
{"iteration": 1755, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:1080|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1756, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.36|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1757, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-1026|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1758, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:34", "kernels": []}
{"iteration": 1759, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-9|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1760, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-81|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1761, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:489|parameter:1:bool:False", "kernels": []}
{"iteration": 1762, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 1763, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 1764, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:557|parameter:1:int:8", "kernels": []}
{"iteration": 1765, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:-100000000000000000000.00|parameter:1:int:8", "kernels": []}
{"iteration": 1766, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:478|parameter:1:int:8", "kernels": []}
{"iteration": 1767, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:460|parameter:1:int:8", "kernels": []}
{"iteration": 1768, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1769, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 1770, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 1771, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:492|parameter:1:int:8", "kernels": []}
{"iteration": 1772, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 1773, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:473|parameter:1:int:1", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1774, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.40|input_signature:list:len3|parameter:0:int:512|parameter:1:int:4", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1775, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:512|parameter:1:float:-2.39", "kernels": []}
{"iteration": 1776, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 1777, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1778, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:522|parameter:1:int:8", "kernels": []}
{"iteration": 1779, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 1780, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:False", "kernels": []}
{"iteration": 1781, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1782, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.91|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1783, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:float:100000000000000000000.00|parameter:1:int:8", "kernels": []}
{"iteration": 1784, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 1785, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1786, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1787, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:mean", "kernels": []}
{"iteration": 1788, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1789, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.00|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 1790, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.72|input_signature:list:len3|parameter:0:int:-1051|parameter:1:int:8", "kernels": []}
{"iteration": 1791, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1792, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1793, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1794, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:-inf|parameter:1:int:-19", "kernels": []}
{"iteration": 1795, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1796, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:558|parameter:1:int:8", "kernels": []}
{"iteration": 1797, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:502|parameter:1:int:8", "kernels": []}
{"iteration": 1798, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-24", "kernels": []}
{"iteration": 1799, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:12", "kernels": []}
{"iteration": 1800, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:461|parameter:1:float:-1024.00", "kernels": []}
{"iteration": 1801, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:-12", "kernels": []}
{"iteration": 1802, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:str:max|parameter:1:int:-21", "kernels": []}
{"iteration": 1803, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:468|parameter:1:int:-31", "kernels": []}
{"iteration": 1804, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-1024|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 1805, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1806, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-16|parameter:1:int:8", "kernels": []}
{"iteration": 1807, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.13|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1808, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1024", "kernels": []}
{"iteration": 1809, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.12|input_signature:list:len3|parameter:0:int:512|parameter:1:float:-60.35", "kernels": []}
{"iteration": 1810, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:511|parameter:1:int:8", "kernels": []}
{"iteration": 1811, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.18|input_signature:list:len3|parameter:0:int:572|parameter:1:str:replicate", "kernels": []}
{"iteration": 1812, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:520|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1813, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1814, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:11", "kernels": []}
{"iteration": 1815, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaDeviceSynchronize", "Activity Buffer Request", "cudaMalloc", "cudaStreamSynchronize", "cudaStreamIsCapturing"]}
{"iteration": 1816, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1024", "kernels": []}
{"iteration": 1817, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.30|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1818, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-65", "kernels": []}
{"iteration": 1819, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 1820, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.23|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1821, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:reflect", "kernels": []}
{"iteration": 1822, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-75|parameter:1:int:8", "kernels": []}
{"iteration": 1823, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1824, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 1825, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-37", "kernels": []}
{"iteration": 1826, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.00|input_signature:list:len3|parameter:0:int:554|parameter:1:int:8", "kernels": []}
{"iteration": 1827, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-23|input_signature:list:len3|parameter:0:int:512|parameter:1:int:68", "kernels": []}
{"iteration": 1828, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1829, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1830, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:16", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1831, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-45", "kernels": []}
{"iteration": 1832, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-48|parameter:1:int:8", "kernels": []}
{"iteration": 1833, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:-1024.00", "kernels": []}
{"iteration": 1834, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.00|input_signature:list:len3|parameter:0:int:572|parameter:1:int:-20", "kernels": []}
{"iteration": 1835, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1836, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:59", "kernels": []}
{"iteration": 1837, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:565|parameter:1:int:8", "kernels": []}
{"iteration": 1838, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:0", "kernels": []}
{"iteration": 1839, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-6", "kernels": []}
{"iteration": 1840, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 1841, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:605|parameter:1:int:8", "kernels": []}
{"iteration": 1842, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.00|input_signature:list:len3|parameter:0:float:1.00|parameter:1:int:8", "kernels": []}
{"iteration": 1843, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1844, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-23|parameter:1:int:8", "kernels": []}
{"iteration": 1845, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:538|parameter:1:int:8", "kernels": []}
{"iteration": 1846, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:62|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1847, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1848, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:466|parameter:1:int:8", "kernels": []}
{"iteration": 1849, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1850, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.64|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:False", "kernels": []}
{"iteration": 1851, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.74|input_signature:list:len3|parameter:0:int:585|parameter:1:int:22", "kernels": []}
{"iteration": 1852, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:float:3.71|parameter:1:int:8", "kernels": []}
{"iteration": 1853, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 1854, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-18", "kernels": []}
{"iteration": 1855, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:442|parameter:1:int:8", "kernels": []}
{"iteration": 1856, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:24|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 1857, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.07|input_signature:list:len3|parameter:0:int:478|parameter:1:str:max", "kernels": []}
{"iteration": 1858, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:511|parameter:1:int:8", "kernels": []}
{"iteration": 1859, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1860, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 1861, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 1862, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-44|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 1863, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.92|input_signature:list:len3|parameter:0:int:486|parameter:1:int:-14", "kernels": []}
{"iteration": 1864, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:2", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1865, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-46", "kernels": []}
{"iteration": 1866, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1867, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.75|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1868, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:574|parameter:1:bool:True", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1869, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.72|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 1870, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1024", "kernels": []}
{"iteration": 1871, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-24", "kernels": []}
{"iteration": 1872, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1873, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1", "kernels": []}
{"iteration": 1874, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1875, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:517|parameter:1:int:8", "kernels": []}
{"iteration": 1876, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1877, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-16", "kernels": []}
{"iteration": 1878, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:516|parameter:1:int:8", "kernels": []}
{"iteration": 1879, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:540|parameter:1:bool:False", "kernels": []}
{"iteration": 1880, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-16|input_signature:list:len3|parameter:0:int:512|parameter:1:int:16", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1881, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1882, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1883, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.60|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:16", "kernels": []}
{"iteration": 1884, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:19", "kernels": []}
{"iteration": 1885, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-5.67|input_signature:list:len3|parameter:0:int:497|parameter:1:int:8", "kernels": []}
{"iteration": 1886, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:0", "kernels": []}
{"iteration": 1887, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1888, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1889, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-1084|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 1890, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:550|parameter:1:bool:True", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1891, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.22|input_signature:list:len3|parameter:0:int:538|parameter:1:int:8", "kernels": []}
{"iteration": 1892, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1893, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:False", "kernels": []}
{"iteration": 1894, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-16", "kernels": []}
{"iteration": 1895, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.92|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-13", "kernels": []}
{"iteration": 1896, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1897, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 1898, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:575|parameter:1:int:-33", "kernels": []}
{"iteration": 1899, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:16|parameter:1:int:-1024", "kernels": []}
{"iteration": 1900, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:zeros", "kernels": []}
{"iteration": 1901, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:519|parameter:1:int:8", "kernels": []}
{"iteration": 1902, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1903, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:496|parameter:1:str:max", "kernels": []}
{"iteration": 1904, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:1024|parameter:1:int:27", "kernels": []}
{"iteration": 1905, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1906, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1907, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:539|parameter:1:int:8", "kernels": []}
{"iteration": 1908, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:481|parameter:1:int:8", "kernels": []}
{"iteration": 1909, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 1910, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1911, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1912, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.61|input_signature:list:len3|parameter:0:int:509|parameter:1:int:8", "kernels": []}
{"iteration": 1913, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:490|parameter:1:int:-50", "kernels": []}
{"iteration": 1914, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:replicate", "kernels": []}
{"iteration": 1915, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 1916, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1024", "kernels": []}
{"iteration": 1917, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1918, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1919, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-34|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1920, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:489|parameter:1:int:8", "kernels": []}
{"iteration": 1921, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:495|parameter:1:int:8", "kernels": []}
{"iteration": 1922, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 1923, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:571|parameter:1:int:25", "kernels": []}
{"iteration": 1924, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:57", "kernels": []}
{"iteration": 1925, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:485|parameter:1:int:8", "kernels": []}
{"iteration": 1926, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1927, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 1928, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:555|parameter:1:str:sum", "kernels": []}
{"iteration": 1929, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:533|parameter:1:int:8", "kernels": []}
{"iteration": 1930, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:451|parameter:1:int:8", "kernels": []}
{"iteration": 1931, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:473|parameter:1:int:44", "kernels": []}
{"iteration": 1932, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1933, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-26", "kernels": []}
{"iteration": 1934, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1935, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1936, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:12", "kernels": []}
{"iteration": 1937, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.56|input_signature:list:len3|parameter:0:int:512|parameter:1:int:16", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1938, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-58|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1939, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.62|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1940, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:replicate|parameter:1:int:69", "kernels": []}
{"iteration": 1941, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1942, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.71|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1943, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1944, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.14|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1945, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:539|parameter:1:int:-33", "kernels": []}
{"iteration": 1946, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:1024|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1947, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:33", "kernels": []}
{"iteration": 1948, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.98|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1949, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.59|input_signature:list:len3|parameter:0:int:465|parameter:1:int:8", "kernels": []}
{"iteration": 1950, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1951, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 1952, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.63|input_signature:list:len3|parameter:0:int:589|parameter:1:int:8", "kernels": []}
{"iteration": 1953, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:570|parameter:1:int:33", "kernels": []}
{"iteration": 1954, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:float:61.65", "kernels": []}
{"iteration": 1955, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1956, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1957, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:reflect|parameter:1:int:8", "kernels": []}
{"iteration": 1958, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:563|parameter:1:int:16", "kernels": []}
{"iteration": 1959, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.70|input_signature:list:len3|parameter:0:int:560|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1960, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.85|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 1961, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:459|parameter:1:int:8", "kernels": []}
{"iteration": 1962, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-33", "kernels": []}
{"iteration": 1963, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1964, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 1965, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:16|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 1966, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-63.00|input_signature:list:len3|parameter:0:float:0.13|parameter:1:int:8", "kernels": []}
{"iteration": 1967, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:561|parameter:1:int:20", "kernels": []}
{"iteration": 1968, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.48|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1969, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:536|parameter:1:int:8", "kernels": []}
{"iteration": 1970, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:-29", "kernels": []}
{"iteration": 1971, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.19|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 1972, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1973, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:79", "kernels": []}
{"iteration": 1974, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1975, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1976, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 1977, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 1978, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:525|parameter:1:int:8", "kernels": []}
{"iteration": 1979, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1980, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:516|parameter:1:int:22", "kernels": []}
{"iteration": 1981, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 1982, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1983, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:reflect|parameter:1:int:8", "kernels": []}
{"iteration": 1984, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:497|parameter:1:int:10", "kernels": []}
{"iteration": 1985, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:1024|parameter:1:int:8", "kernels": []}
{"iteration": 1986, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1", "kernels": []}
{"iteration": 1987, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 1988, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:500|parameter:1:int:47", "kernels": []}
{"iteration": 1989, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:35", "kernels": []}
{"iteration": 1990, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:466|parameter:1:int:8", "kernels": []}
{"iteration": 1991, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 1992, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:535|parameter:1:int:8", "kernels": []}
{"iteration": 1993, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:str:max", "kernels": []}
{"iteration": 1994, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:463|parameter:1:int:8", "kernels": []}
{"iteration": 1995, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.56|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 1996, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:False", "kernels": []}
{"iteration": 1997, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:circular|parameter:1:int:8", "kernels": []}
{"iteration": 1998, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:491|parameter:1:int:8", "kernels": []}
{"iteration": 1999, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.37|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2000, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2001, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.33|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2002, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:465|parameter:1:int:8", "kernels": []}
{"iteration": 2003, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-16|parameter:1:bool:True", "kernels": []}
{"iteration": 2004, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-2|input_signature:list:len3|parameter:0:int:499|parameter:1:int:8", "kernels": []}
{"iteration": 2005, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:485|parameter:1:int:8", "kernels": []}
{"iteration": 2006, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:452|parameter:1:int:8", "kernels": []}
{"iteration": 2007, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2008, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:541|parameter:1:str:sum", "kernels": []}
{"iteration": 2009, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:14|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2010, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2011, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:427|parameter:1:int:8", "kernels": []}
{"iteration": 2012, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2013, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:489|parameter:1:int:8", "kernels": []}
{"iteration": 2014, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.00|input_signature:list:len3|parameter:0:int:502|parameter:1:int:8", "kernels": []}
{"iteration": 2015, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-32", "kernels": []}
{"iteration": 2016, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2017, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2018, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:534|parameter:1:int:-23", "kernels": []}
{"iteration": 2019, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:38", "kernels": []}
{"iteration": 2020, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:460|parameter:1:int:1024", "kernels": []}
{"iteration": 2021, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2022, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.09|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2023, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2024, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2025, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-25", "kernels": []}
{"iteration": 2026, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.56|input_signature:list:len3|parameter:0:int:498|parameter:1:int:8", "kernels": []}
{"iteration": 2027, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2028, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:23", "kernels": []}
{"iteration": 2029, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:484|parameter:1:int:1", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2030, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2031, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:31|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2032, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:4.03|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2033, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 2034, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2035, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2036, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2037, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2038, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.61|input_signature:list:len3|parameter:0:int:512|parameter:1:int:28", "kernels": []}
{"iteration": 2039, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-16|parameter:1:int:8", "kernels": []}
{"iteration": 2040, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:492|parameter:1:int:8", "kernels": []}
{"iteration": 2041, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2042, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:485|parameter:1:int:33", "kernels": []}
{"iteration": 2043, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:1024|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2044, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:468|parameter:1:int:8", "kernels": []}
{"iteration": 2045, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:452|parameter:1:int:8", "kernels": []}
{"iteration": 2046, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-4", "kernels": []}
{"iteration": 2047, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-53", "kernels": []}
{"iteration": 2048, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2049, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.00|input_signature:list:len3|parameter:0:int:39|parameter:1:int:8", "kernels": []}
{"iteration": 2050, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2051, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2052, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:25", "kernels": []}
{"iteration": 2053, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 2054, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 2055, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:63.00", "kernels": []}
{"iteration": 2056, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2057, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:553|parameter:1:int:8", "kernels": []}
{"iteration": 2058, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:31", "kernels": []}
{"iteration": 2059, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2060, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:16", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2061, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.35|input_signature:list:len3|parameter:0:float:4.70|parameter:1:int:8", "kernels": []}
{"iteration": 2062, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2063, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:mean|input_signature:list:len3|parameter:0:int:550|parameter:1:int:8", "kernels": []}
{"iteration": 2064, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:459|parameter:1:int:-1", "kernels": []}
{"iteration": 2065, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2066, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-4.98|input_signature:list:len3|parameter:0:int:542|parameter:1:int:8", "kernels": []}
{"iteration": 2067, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-9", "kernels": []}
{"iteration": 2068, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.77|input_signature:list:len3|parameter:0:int:512|parameter:1:int:40", "kernels": []}
{"iteration": 2069, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-1|input_signature:list:len3|parameter:0:int:512|parameter:1:int:5", "kernels": []}
{"iteration": 2070, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2071, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.38|input_signature:list:len3|parameter:0:int:512|parameter:1:int:2", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2072, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1|parameter:1:int:108", "kernels": []}
{"iteration": 2073, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2074, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:558|parameter:1:int:8", "kernels": []}
{"iteration": 2075, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2076, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:zeros|input_signature:list:len3|parameter:0:int:453|parameter:1:int:8", "kernels": []}
{"iteration": 2077, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2078, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2079, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2080, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-54", "kernels": []}
{"iteration": 2081, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2082, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:509|parameter:1:int:8", "kernels": []}
{"iteration": 2083, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:6", "kernels": []}
{"iteration": 2084, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:505|parameter:1:int:8", "kernels": []}
{"iteration": 2085, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.58|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 2086, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.67|input_signature:list:len3|parameter:0:int:512|parameter:1:int:47", "kernels": []}
{"iteration": 2087, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2088, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:0", "kernels": []}
{"iteration": 2089, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:571|parameter:1:str:max", "kernels": []}
{"iteration": 2090, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2091, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1024", "kernels": []}
{"iteration": 2092, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.38|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2093, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:1|parameter:1:int:8", "kernels": []}
{"iteration": 2094, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:12", "kernels": []}
{"iteration": 2095, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2096, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:468|parameter:1:int:8", "kernels": []}
{"iteration": 2097, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.96|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2098, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.03|input_signature:list:len3|parameter:0:int:16|parameter:1:int:-55", "kernels": []}
{"iteration": 2099, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:1|input_signature:list:len3|parameter:0:int:1024|parameter:1:str:max", "kernels": []}
{"iteration": 2100, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2101, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:598|parameter:1:float:-0.00", "kernels": []}
{"iteration": 2102, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2103, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2104, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:459|parameter:1:int:8", "kernels": []}
{"iteration": 2105, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2106, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-35", "kernels": []}
{"iteration": 2107, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:bool:True", "kernels": []}
{"iteration": 2108, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.24|input_signature:list:len3|parameter:0:int:16|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2109, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2110, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:0.00", "kernels": []}
{"iteration": 2111, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:0.00|parameter:1:int:2", "kernels": []}
{"iteration": 2112, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.40|input_signature:list:len3|parameter:0:int:512|parameter:1:int:16", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2113, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 2114, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:float:-2.38", "kernels": []}
{"iteration": 2115, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:554|parameter:1:int:8", "kernels": []}
{"iteration": 2116, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:16|parameter:1:int:-30", "kernels": []}
{"iteration": 2117, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:473|parameter:1:int:8", "kernels": []}
{"iteration": 2118, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2119, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-inf|input_signature:list:len3|parameter:0:int:482|parameter:1:int:8", "kernels": []}
{"iteration": 2120, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:489|parameter:1:int:9", "kernels": []}
{"iteration": 2121, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.63|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 2122, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 2123, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2124, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:563|parameter:1:int:8", "kernels": []}
{"iteration": 2125, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.35|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2126, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-48|input_signature:list:len3|parameter:0:int:16|parameter:1:float:-3.92", "kernels": []}
{"iteration": 2127, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:40", "kernels": []}
{"iteration": 2128, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.46|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2129, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.18|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2130, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.96|input_signature:list:len3|parameter:0:int:493|parameter:1:int:8", "kernels": []}
{"iteration": 2131, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2132, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:560|parameter:1:int:36", "kernels": []}
{"iteration": 2133, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:float:-64.37", "kernels": []}
{"iteration": 2134, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.15|input_signature:list:len3|parameter:0:float:-1024.00|parameter:1:int:-47", "kernels": []}
{"iteration": 2135, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2136, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:519|parameter:1:int:8", "kernels": []}
{"iteration": 2137, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:20", "kernels": []}
{"iteration": 2138, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:17", "kernels": []}
{"iteration": 2139, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2140, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.88|input_signature:list:len3|parameter:0:float:100000000000000000000.00|parameter:1:int:18", "kernels": []}
{"iteration": 2141, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:531|parameter:1:float:-3.42", "kernels": []}
{"iteration": 2142, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.33|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-4", "kernels": []}
{"iteration": 2143, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2144, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:34", "kernels": []}
{"iteration": 2145, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:455|parameter:1:int:8", "kernels": []}
{"iteration": 2146, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2147, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:16|parameter:1:int:69", "kernels": []}
{"iteration": 2148, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2149, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.34|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2150, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:56", "kernels": []}
{"iteration": 2151, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:459|parameter:1:int:8", "kernels": []}
{"iteration": 2152, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2153, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2154, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.17|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2155, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:float:nan", "kernels": []}
{"iteration": 2156, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2157, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.65|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2158, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:45|input_signature:list:len3|parameter:0:int:512|parameter:1:int:70", "kernels": []}
{"iteration": 2159, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2160, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1024", "kernels": []}
{"iteration": 2161, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1024|parameter:1:int:8", "kernels": []}
{"iteration": 2162, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2163, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1024", "kernels": []}
{"iteration": 2164, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:543|parameter:1:int:8", "kernels": []}
{"iteration": 2165, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-53", "kernels": []}
{"iteration": 2166, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 2167, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:50|parameter:1:int:8", "kernels": []}
{"iteration": 2168, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:554|parameter:1:bool:False", "kernels": []}
{"iteration": 2169, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:63.00|input_signature:list:len3|parameter:0:int:491|parameter:1:int:-4", "kernels": []}
{"iteration": 2170, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 2171, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-7", "kernels": []}
{"iteration": 2172, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.96|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2173, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2174, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2175, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:501|parameter:1:int:8", "kernels": []}
{"iteration": 2176, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.42|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2177, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2178, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:False", "kernels": []}
{"iteration": 2179, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:replicate|input_signature:list:len3|parameter:0:int:482|parameter:1:int:8", "kernels": []}
{"iteration": 2180, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.82|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2181, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1024", "kernels": []}
{"iteration": 2182, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-28", "kernels": []}
{"iteration": 2183, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.84|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2184, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2185, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-37|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 2186, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-6", "kernels": []}
{"iteration": 2187, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:False", "kernels": []}
{"iteration": 2188, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2189, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-11", "kernels": []}
{"iteration": 2190, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2191, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.21|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 2192, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:0", "kernels": []}
{"iteration": 2193, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.04|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2194, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2195, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:bool:False", "kernels": []}
{"iteration": 2196, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-34", "kernels": []}
{"iteration": 2197, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:476|parameter:1:int:-15", "kernels": []}
{"iteration": 2198, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2199, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.87|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1", "kernels": []}
{"iteration": 2200, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.95|input_signature:list:len3|parameter:0:int:512|parameter:1:int:52", "kernels": []}
{"iteration": 2201, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.53|input_signature:list:len3|parameter:0:int:1024|parameter:1:int:63", "kernels": []}
{"iteration": 2202, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2203, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:0", "kernels": []}
{"iteration": 2204, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2205, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.99|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 2206, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-14", "kernels": []}
{"iteration": 2207, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:50", "kernels": []}
{"iteration": 2208, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:circular", "kernels": []}
{"iteration": 2209, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2210, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.19|input_signature:list:len3|parameter:0:int:449|parameter:1:int:8", "kernels": []}
{"iteration": 2211, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:456|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2212, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:538|parameter:1:int:8", "kernels": []}
{"iteration": 2213, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-25", "kernels": []}
{"iteration": 2214, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:502|parameter:1:int:8", "kernels": []}
{"iteration": 2215, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:488|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2216, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.04|input_signature:list:len3|parameter:0:int:564|parameter:1:int:8", "kernels": []}
{"iteration": 2217, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1024|parameter:1:int:8", "kernels": []}
{"iteration": 2218, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.71|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-29", "kernels": []}
{"iteration": 2219, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.84|input_signature:list:len3|parameter:0:int:-1|parameter:1:int:8", "kernels": []}
{"iteration": 2220, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1|parameter:1:int:8", "kernels": []}
{"iteration": 2221, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2222, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:16|parameter:1:int:-16", "kernels": []}
{"iteration": 2223, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.18|input_signature:list:len3|parameter:0:str:replicate|parameter:1:int:8", "kernels": []}
{"iteration": 2224, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:463|parameter:1:int:8", "kernels": []}
{"iteration": 2225, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2226, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2227, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:0.00|parameter:1:int:8", "kernels": []}
{"iteration": 2228, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:86", "kernels": []}
{"iteration": 2229, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:100000000000000000000.00", "kernels": []}
{"iteration": 2230, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:18|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1", "kernels": []}
{"iteration": 2231, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-26|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2232, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2233, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2234, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:14", "kernels": []}
{"iteration": 2235, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2236, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:str:zeros", "kernels": []}
{"iteration": 2237, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:532|parameter:1:int:8", "kernels": []}
{"iteration": 2238, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:1", "kernels": []}
{"iteration": 2239, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:-63.00|parameter:1:int:8", "kernels": []}
{"iteration": 2240, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:36|input_signature:list:len3|parameter:0:int:-1024|parameter:1:int:8", "kernels": []}
{"iteration": 2241, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.23|input_signature:list:len3|parameter:0:int:512|parameter:1:int:17", "kernels": []}
{"iteration": 2242, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2243, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:False", "kernels": []}
{"iteration": 2244, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:565|parameter:1:int:-12", "kernels": []}
{"iteration": 2245, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2246, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2247, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:inf|input_signature:list:len3|parameter:0:str:max|parameter:1:int:-13", "kernels": []}
{"iteration": 2248, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.07|input_signature:list:len3|parameter:0:int:512|parameter:1:int:21", "kernels": []}
{"iteration": 2249, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:bool:True", "kernels": []}
{"iteration": 2250, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-inf|input_signature:list:len3|parameter:0:int:499|parameter:1:int:8", "kernels": []}
{"iteration": 2251, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 2252, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.67|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2253, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:504|parameter:1:int:7", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2254, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.43|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2255, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:38", "kernels": []}
{"iteration": 2256, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:533|parameter:1:int:8", "kernels": []}
{"iteration": 2257, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:456|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2258, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": []}
{"iteration": 2259, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 2260, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 2261, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:571|parameter:1:int:8", "kernels": []}
{"iteration": 2262, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:564|parameter:1:float:0.04", "kernels": []}
{"iteration": 2263, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:531|parameter:1:int:8", "kernels": []}
{"iteration": 2264, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2265, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2266, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2267, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:28", "kernels": []}
{"iteration": 2268, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.61|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2269, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:100000000000000000000.00", "kernels": []}
{"iteration": 2270, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.80|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2271, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:548|parameter:1:int:8", "kernels": []}
{"iteration": 2272, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2273, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 2274, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2275, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:7", "kernels": []}
{"iteration": 2276, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:497|parameter:1:int:8", "kernels": []}
{"iteration": 2277, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:2.45", "kernels": []}
{"iteration": 2278, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:0", "kernels": []}
{"iteration": 2279, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:488|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2280, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:14", "kernels": []}
{"iteration": 2281, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 2282, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.65|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2283, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2284, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2285, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:452|parameter:1:int:-51", "kernels": []}
{"iteration": 2286, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:53", "kernels": []}
{"iteration": 2287, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2288, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:2|input_signature:list:len3|parameter:0:int:500|parameter:1:int:8", "kernels": []}
{"iteration": 2289, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 2290, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.56|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2291, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1073", "kernels": []}
{"iteration": 2292, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:533|parameter:1:int:8", "kernels": []}
{"iteration": 2293, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-42", "kernels": []}
{"iteration": 2294, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:519|parameter:1:int:-1024", "kernels": []}
{"iteration": 2295, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:51", "kernels": []}
{"iteration": 2296, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2297, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2298, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 2299, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2300, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:32", "kernels": []}
{"iteration": 2301, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 2302, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2303, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:6|input_signature:list:len3|parameter:0:int:512|parameter:1:int:18", "kernels": []}
{"iteration": 2304, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:20", "kernels": []}
{"iteration": 2305, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-54", "kernels": []}
{"iteration": 2306, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2307, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.24|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 2308, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-11", "kernels": []}
{"iteration": 2309, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:-63.00|parameter:1:int:32", "kernels": []}
{"iteration": 2310, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:503|parameter:1:int:8", "kernels": []}
{"iteration": 2311, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2312, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2313, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:482|parameter:1:int:8", "kernels": []}
{"iteration": 2314, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.00|input_signature:list:len3|parameter:0:int:478|parameter:1:float:inf", "kernels": []}
{"iteration": 2315, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaLaunchKernel", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 2316, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2317, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2318, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-36", "kernels": []}
{"iteration": 2319, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2320, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:40", "kernels": []}
{"iteration": 2321, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2322, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 2323, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:-0.00|parameter:1:int:-26", "kernels": []}
{"iteration": 2324, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:reflect", "kernels": []}
{"iteration": 2325, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.03|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 2326, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:str:zeros|parameter:1:int:8", "kernels": []}
{"iteration": 2327, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.49|input_signature:list:len3|parameter:0:int:460|parameter:1:int:8", "kernels": []}
{"iteration": 2328, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1", "kernels": []}
{"iteration": 2329, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2330, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2331, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2332, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:451|parameter:1:int:8", "kernels": []}
{"iteration": 2333, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:554|parameter:1:str:max", "kernels": []}
{"iteration": 2334, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-61|input_signature:list:len3|parameter:0:int:466|parameter:1:int:8", "kernels": []}
{"iteration": 2335, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.77|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2336, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.00|input_signature:list:len3|parameter:0:str:max|parameter:1:str:max", "kernels": []}
{"iteration": 2337, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:float:1.08", "kernels": []}
{"iteration": 2338, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2339, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:14", "kernels": []}
{"iteration": 2340, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:nan", "kernels": []}
{"iteration": 2341, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2342, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2343, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:539|parameter:1:int:-16", "kernels": []}
{"iteration": 2344, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:472|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2345, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:1|parameter:1:int:1", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2346, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2347, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 2348, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2349, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:37", "kernels": []}
{"iteration": 2350, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2351, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.72|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-21", "kernels": []}
{"iteration": 2352, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:nan|parameter:1:int:8", "kernels": []}
{"iteration": 2353, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:-1", "kernels": []}
{"iteration": 2354, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.33|input_signature:list:len3|parameter:0:int:0|parameter:1:str:max", "kernels": []}
{"iteration": 2355, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:455|parameter:1:int:8", "kernels": []}
{"iteration": 2356, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-26", "kernels": []}
{"iteration": 2357, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1024|parameter:1:int:8", "kernels": []}
{"iteration": 2358, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-55", "kernels": []}
{"iteration": 2359, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2360, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2361, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.41|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2362, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2363, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.55|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2364, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.86|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1024", "kernels": []}
{"iteration": 2365, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1024", "kernels": []}
{"iteration": 2366, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:499|parameter:1:int:8", "kernels": []}
{"iteration": 2367, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:522|parameter:1:int:8", "kernels": []}
{"iteration": 2368, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.16|input_signature:list:len3|parameter:0:str:circular|parameter:1:int:8", "kernels": []}
{"iteration": 2369, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:15", "kernels": []}
{"iteration": 2370, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:453|parameter:1:int:8", "kernels": []}
{"iteration": 2371, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1024.00|input_signature:list:len3|parameter:0:int:542|parameter:1:int:8", "kernels": []}
{"iteration": 2372, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 2373, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:488|parameter:1:int:16", "kernels": []}
{"iteration": 2374, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:27", "kernels": []}
{"iteration": 2375, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-36", "kernels": []}
{"iteration": 2376, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:1026.74|parameter:1:int:-1024", "kernels": []}
{"iteration": 2377, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2378, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2379, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2380, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.44|input_signature:list:len3|parameter:0:float:-1.19|parameter:1:int:8", "kernels": []}
{"iteration": 2381, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:4", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 2382, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.58|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2383, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.06|input_signature:list:len3|parameter:0:float:3.67|parameter:1:int:8", "kernels": []}
{"iteration": 2384, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2385, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:487|parameter:1:int:8", "kernels": []}
{"iteration": 2386, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2387, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:57", "kernels": []}
{"iteration": 2388, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:565|parameter:1:int:8", "kernels": []}
{"iteration": 2389, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.82|input_signature:list:len3|parameter:0:int:512|parameter:1:int:13", "kernels": []}
{"iteration": 2390, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:458|parameter:1:bool:False", "kernels": []}
{"iteration": 2391, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:574|parameter:1:int:8", "kernels": []}
{"iteration": 2392, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-45", "kernels": []}
{"iteration": 2393, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 2394, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2395, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:-4.65|parameter:1:int:8", "kernels": []}
{"iteration": 2396, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2397, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:487|parameter:1:int:1", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2398, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:522|parameter:1:int:8", "kernels": []}
{"iteration": 2399, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:0.08", "kernels": []}
{"iteration": 2400, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.72|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2401, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:456|parameter:1:int:96", "kernels": []}
{"iteration": 2402, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.84|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2403, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2404, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:542|parameter:1:float:100000000000000000000.00", "kernels": []}
{"iteration": 2405, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:9", "kernels": []}
{"iteration": 2406, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:-inf", "kernels": []}
{"iteration": 2407, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:5", "kernels": []}
{"iteration": 2408, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2409, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-28", "kernels": []}
{"iteration": 2410, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2411, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-35", "kernels": []}
{"iteration": 2412, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:22", "kernels": []}
{"iteration": 2413, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:500|parameter:1:int:8", "kernels": []}
{"iteration": 2414, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2415, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:448|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2416, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:nan|parameter:1:int:8", "kernels": []}
{"iteration": 2417, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:16", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2418, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:63.00|input_signature:list:len3|parameter:0:int:473|parameter:1:int:8", "kernels": []}
{"iteration": 2419, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2420, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2421, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:-52", "kernels": []}
{"iteration": 2422, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2423, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:52", "kernels": []}
{"iteration": 2424, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:564|parameter:1:int:-12", "kernels": []}
{"iteration": 2425, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:float:0.15|parameter:1:int:56", "kernels": []}
{"iteration": 2426, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:502|parameter:1:int:-33", "kernels": []}
{"iteration": 2427, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-7|input_signature:list:len3|parameter:0:int:494|parameter:1:int:8", "kernels": []}
{"iteration": 2428, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2429, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:str:max|parameter:1:str:max", "kernels": []}
{"iteration": 2430, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1024", "kernels": []}
{"iteration": 2431, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:9", "kernels": []}
{"iteration": 2432, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-60|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2433, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:zeros|input_signature:list:len3|parameter:0:int:512|parameter:1:float:100000000000000000000.00", "kernels": []}
{"iteration": 2434, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2435, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2436, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:26", "kernels": []}
{"iteration": 2437, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:16|input_signature:list:len3|parameter:0:int:387|parameter:1:int:8", "kernels": []}
{"iteration": 2438, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.36|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 2439, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-2", "kernels": []}
{"iteration": 2440, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2441, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:519|parameter:1:int:8", "kernels": []}
{"iteration": 2442, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2443, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:460|parameter:1:int:8", "kernels": []}
{"iteration": 2444, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2445, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2446, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2447, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:477|parameter:1:int:-35", "kernels": []}
{"iteration": 2448, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1024", "kernels": []}
{"iteration": 2449, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2450, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:16", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2451, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.98|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2452, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:float:1.75|parameter:1:bool:False", "kernels": []}
{"iteration": 2453, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:1|parameter:1:int:8", "kernels": []}
{"iteration": 2454, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-50", "kernels": []}
{"iteration": 2455, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1024|parameter:1:int:29", "kernels": []}
{"iteration": 2456, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2457, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.64|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2458, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2459, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1024", "kernels": []}
{"iteration": 2460, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.52|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2461, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.87|input_signature:list:len3|parameter:0:int:532|parameter:1:int:8", "kernels": []}
{"iteration": 2462, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2463, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:519|parameter:1:bool:True", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2464, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2465, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2466, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:461|parameter:1:int:8", "kernels": []}
{"iteration": 2467, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2468, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.69|input_signature:list:len3|parameter:0:float:-1.68|parameter:1:int:8", "kernels": []}
{"iteration": 2469, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:-6.33", "kernels": []}
{"iteration": 2470, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:545|parameter:1:int:8", "kernels": []}
{"iteration": 2471, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.84|input_signature:list:len3|parameter:0:int:537|parameter:1:int:8", "kernels": []}
{"iteration": 2472, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-1087|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-16", "kernels": []}
{"iteration": 2473, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.16|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2474, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:str:reflect", "kernels": []}
{"iteration": 2475, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2476, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1024|parameter:1:int:-16", "kernels": []}
{"iteration": 2477, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:16|parameter:1:int:-24", "kernels": []}
{"iteration": 2478, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2479, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:555|parameter:1:bool:False", "kernels": []}
{"iteration": 2480, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:531|parameter:1:int:8", "kernels": []}
{"iteration": 2481, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:-1|parameter:1:int:-11", "kernels": []}
{"iteration": 2482, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:16", "kernels": []}
{"iteration": 2483, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-1024|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:False", "kernels": []}
{"iteration": 2484, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-29|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2485, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:1027.16|parameter:1:int:8", "kernels": []}
{"iteration": 2486, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2487, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:464|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2488, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:97|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2489, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2490, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:450|parameter:1:int:-1024", "kernels": []}
{"iteration": 2491, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.81|input_signature:list:len3|parameter:0:int:546|parameter:1:int:6", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2492, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-6", "kernels": []}
{"iteration": 2493, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:54|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 2494, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.03|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2495, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-39", "kernels": []}
{"iteration": 2496, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2497, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:524|parameter:1:int:43", "kernels": []}
{"iteration": 2498, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:538|parameter:1:int:8", "kernels": []}
{"iteration": 2499, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2500, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2501, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.03|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2502, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:492|parameter:1:str:max", "kernels": []}
{"iteration": 2503, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.55|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2504, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 2505, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.57|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-29", "kernels": []}
{"iteration": 2506, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2507, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 2508, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:1|parameter:1:int:43", "kernels": []}
{"iteration": 2509, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2510, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 2511, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 2512, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:63.00|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:-50", "kernels": []}
{"iteration": 2513, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:4|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2514, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2515, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.77|input_signature:list:len3|parameter:0:str:max|parameter:1:int:43", "kernels": []}
{"iteration": 2516, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-4", "kernels": []}
{"iteration": 2517, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:496|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2518, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2519, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.26|input_signature:list:len3|parameter:0:int:549|parameter:1:int:8", "kernels": []}
{"iteration": 2520, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:-0.51", "kernels": []}
{"iteration": 2521, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:539|parameter:1:int:8", "kernels": []}
{"iteration": 2522, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:543|parameter:1:int:8", "kernels": []}
{"iteration": 2523, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 2524, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:str:circular", "kernels": []}
{"iteration": 2525, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.14|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2526, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:479|parameter:1:int:8", "kernels": []}
{"iteration": 2527, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 2528, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.81|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 2529, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-1|input_signature:list:len3|parameter:0:int:456|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2530, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:1|parameter:1:int:8", "kernels": []}
{"iteration": 2531, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:534|parameter:1:int:8", "kernels": []}
{"iteration": 2532, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:524|parameter:1:int:8", "kernels": []}
{"iteration": 2533, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:506|parameter:1:int:53", "kernels": []}
{"iteration": 2534, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2535, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:16", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2536, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1|parameter:1:int:8", "kernels": []}
{"iteration": 2537, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:498|parameter:1:bool:True", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2538, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-16|parameter:1:int:8", "kernels": []}
{"iteration": 2539, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.63|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 2540, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:528|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2541, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:25", "kernels": []}
{"iteration": 2542, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:485|parameter:1:int:8", "kernels": []}
{"iteration": 2543, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1024", "kernels": []}
{"iteration": 2544, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:0.00", "kernels": []}
{"iteration": 2545, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2546, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:574|parameter:1:int:8", "kernels": []}
{"iteration": 2547, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2548, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.52|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-52", "kernels": []}
{"iteration": 2549, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:115", "kernels": []}
{"iteration": 2550, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.97|input_signature:list:len3|parameter:0:int:1024|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2551, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-25", "kernels": []}
{"iteration": 2552, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:3|parameter:1:int:8", "kernels": []}
{"iteration": 2553, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-19", "kernels": []}
{"iteration": 2554, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.14|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2555, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:0|parameter:1:bool:False", "kernels": []}
{"iteration": 2556, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-16|parameter:1:int:8", "kernels": []}
{"iteration": 2557, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-43", "kernels": []}
{"iteration": 2558, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1024|parameter:1:int:8", "kernels": []}
{"iteration": 2559, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2560, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1024", "kernels": []}
{"iteration": 2561, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.03|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-47", "kernels": []}
{"iteration": 2562, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-49", "kernels": []}
{"iteration": 2563, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2564, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2565, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:float:100000000000000000000.00|parameter:1:int:8", "kernels": []}
{"iteration": 2566, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:577|parameter:1:bool:False", "kernels": []}
{"iteration": 2567, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.56|input_signature:list:len3|parameter:0:int:512|parameter:1:int:50", "kernels": []}
{"iteration": 2568, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-27", "kernels": []}
{"iteration": 2569, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.54|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 2570, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2571, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-13|input_signature:list:len3|parameter:0:int:512|parameter:1:int:3", "kernels": []}
{"iteration": 2572, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:461|parameter:1:int:8", "kernels": []}
{"iteration": 2573, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-6", "kernels": []}
{"iteration": 2574, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2575, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-15", "kernels": []}
{"iteration": 2576, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:532|parameter:1:int:8", "kernels": []}
{"iteration": 2577, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:75", "kernels": []}
{"iteration": 2578, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:3", "kernels": []}
{"iteration": 2579, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1024.00|input_signature:list:len3|parameter:0:int:-1024|parameter:1:int:12", "kernels": []}
{"iteration": 2580, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:70", "kernels": []}
{"iteration": 2581, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-44|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2582, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2583, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:453|parameter:1:int:8", "kernels": []}
{"iteration": 2584, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.82|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2585, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:-16|parameter:1:int:8", "kernels": []}
{"iteration": 2586, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.67|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2587, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.97|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2588, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-41", "kernels": []}
{"iteration": 2589, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2590, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2591, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-2", "kernels": []}
{"iteration": 2592, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2593, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:488|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2594, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 2595, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 2596, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:512|parameter:1:int:14", "kernels": []}
{"iteration": 2597, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:14", "kernels": []}
{"iteration": 2598, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:103", "kernels": []}
{"iteration": 2599, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:-100000000000000000000.00", "kernels": []}
{"iteration": 2600, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2601, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.98|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 2602, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2603, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:47", "kernels": []}
{"iteration": 2604, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:52", "kernels": []}
{"iteration": 2605, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:0", "kernels": []}
{"iteration": 2606, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.23|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2607, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:518|parameter:1:int:67", "kernels": []}
{"iteration": 2608, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2609, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2610, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-52", "kernels": []}
{"iteration": 2611, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2612, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-64.45|input_signature:list:len3|parameter:0:int:513|parameter:1:int:8", "kernels": []}
{"iteration": 2613, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.63|input_signature:list:len3|parameter:0:int:0|parameter:1:int:8", "kernels": []}
{"iteration": 2614, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:570|parameter:1:int:57", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2615, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:548|parameter:1:int:8", "kernels": []}
{"iteration": 2616, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2617, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-38", "kernels": []}
{"iteration": 2618, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:2.18|parameter:1:int:8", "kernels": []}
{"iteration": 2619, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2620, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-15|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2621, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1|parameter:1:int:-27", "kernels": []}
{"iteration": 2622, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaDeviceSynchronize", "Activity Buffer Request", "cudaMalloc", "cudaStreamSynchronize", "cudaStreamIsCapturing"]}
{"iteration": 2623, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.00|input_signature:list:len3|parameter:0:int:504|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2624, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2625, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1024.00|input_signature:list:len3|parameter:0:int:470|parameter:1:int:8", "kernels": []}
{"iteration": 2626, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:4.02|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-39", "kernels": []}
{"iteration": 2627, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-37", "kernels": []}
{"iteration": 2628, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-15", "kernels": []}
{"iteration": 2629, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2630, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:nan|parameter:1:int:8", "kernels": []}
{"iteration": 2631, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:16", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2632, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:506|parameter:1:int:-5", "kernels": []}
{"iteration": 2633, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1024.00|input_signature:list:len3|parameter:0:int:466|parameter:1:int:8", "kernels": []}
{"iteration": 2634, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2635, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:487|parameter:1:int:8", "kernels": []}
{"iteration": 2636, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:546|parameter:1:int:8", "kernels": []}
{"iteration": 2637, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.15|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2638, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2639, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:26", "kernels": []}
{"iteration": 2640, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.79|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2641, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:mean|parameter:1:bool:True", "kernels": []}
{"iteration": 2642, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:415|parameter:1:int:8", "kernels": []}
{"iteration": 2643, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2644, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2645, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-16|parameter:1:int:8", "kernels": []}
{"iteration": 2646, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:449|parameter:1:int:-47", "kernels": []}
{"iteration": 2647, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 2648, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.92|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2649, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:sum|input_signature:list:len3|parameter:0:int:536|parameter:1:bool:False", "kernels": []}
{"iteration": 2650, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2651, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:8|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2652, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.91|input_signature:list:len3|parameter:0:int:451|parameter:1:int:42", "kernels": []}
{"iteration": 2653, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:67", "kernels": []}
{"iteration": 2654, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2655, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.25|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2656, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:49", "kernels": []}
{"iteration": 2657, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:0.00|parameter:1:int:1024", "kernels": []}
{"iteration": 2658, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-17|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2659, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2660, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 2661, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.03|input_signature:list:len3|parameter:0:int:-1|parameter:1:int:8", "kernels": []}
{"iteration": 2662, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:61", "kernels": []}
{"iteration": 2663, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1024", "kernels": []}
{"iteration": 2664, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:False", "kernels": []}
{"iteration": 2665, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2666, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2667, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-21", "kernels": []}
{"iteration": 2668, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.44|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2669, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2670, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2671, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1024", "kernels": []}
{"iteration": 2672, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.61|input_signature:list:len3|parameter:0:int:452|parameter:1:int:8", "kernels": []}
{"iteration": 2673, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.93|input_signature:list:len3|parameter:0:str:max|parameter:1:float:-inf", "kernels": []}
{"iteration": 2674, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:457|parameter:1:int:8", "kernels": []}
{"iteration": 2675, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2676, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:31", "kernels": []}
{"iteration": 2677, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2678, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:float:0.00|parameter:1:int:8", "kernels": []}
{"iteration": 2679, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 2680, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:-3.61", "kernels": []}
{"iteration": 2681, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 2682, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2683, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:int:63", "kernels": []}
{"iteration": 2684, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2685, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:-1024|parameter:1:int:52", "kernels": []}
{"iteration": 2686, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2687, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2688, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2689, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2690, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1", "kernels": []}
{"iteration": 2691, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:472|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2692, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:505|parameter:1:int:8", "kernels": []}
{"iteration": 2693, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:524|parameter:1:int:8", "kernels": []}
{"iteration": 2694, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.06|input_signature:list:len3|parameter:0:int:512|parameter:1:int:57", "kernels": []}
{"iteration": 2695, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2696, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2697, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-1|input_signature:list:len3|parameter:0:str:reflect|parameter:1:int:-25", "kernels": []}
{"iteration": 2698, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 2699, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-63.00|input_signature:list:len3|parameter:0:int:519|parameter:1:int:-16", "kernels": []}
{"iteration": 2700, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:495|parameter:1:str:reflect", "kernels": []}
{"iteration": 2701, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-36", "kernels": []}
{"iteration": 2702, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.30|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2703, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-1|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2704, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.34|input_signature:list:len3|parameter:0:int:512|parameter:1:int:26", "kernels": []}
{"iteration": 2705, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-16|parameter:1:int:8", "kernels": []}
{"iteration": 2706, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:464|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2707, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2708, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-76", "kernels": []}
{"iteration": 2709, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-11", "kernels": []}
{"iteration": 2710, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2711, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1|parameter:1:int:62", "kernels": []}
{"iteration": 2712, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 2713, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:544|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2714, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2715, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1", "kernels": []}
{"iteration": 2716, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:33", "kernels": []}
{"iteration": 2717, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1024.00|input_signature:list:len3|parameter:0:int:569|parameter:1:int:8", "kernels": []}
{"iteration": 2718, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.00|input_signature:list:len3|parameter:0:int:460|parameter:1:int:8", "kernels": []}
{"iteration": 2719, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2720, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2721, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 2722, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:mean|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2723, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:564|parameter:1:int:8", "kernels": []}
{"iteration": 2724, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2725, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.35|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2726, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:458|parameter:1:int:8", "kernels": []}
{"iteration": 2727, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.25|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1024", "kernels": []}
{"iteration": 2728, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:453|parameter:1:int:52", "kernels": []}
{"iteration": 2729, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:457|parameter:1:int:-38", "kernels": []}
{"iteration": 2730, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.86|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2731, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2732, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:407|parameter:1:int:8", "kernels": []}
{"iteration": 2733, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 2734, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2735, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "Memset (Device)", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "cudaDeviceSynchronize", "ampere_sgemm_128x64_tn"]}
{"iteration": 2736, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:564|parameter:1:int:8", "kernels": []}
{"iteration": 2737, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:34", "kernels": []}
{"iteration": 2738, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:zeros|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2739, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2740, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2741, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.99|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 2742, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:449|parameter:1:int:8", "kernels": []}
{"iteration": 2743, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:507|parameter:1:int:8", "kernels": []}
{"iteration": 2744, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1024", "kernels": []}
{"iteration": 2745, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.35|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 2746, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2747, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1|parameter:1:float:nan", "kernels": []}
{"iteration": 2748, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2749, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:511|parameter:1:int:8", "kernels": []}
{"iteration": 2750, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-39|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:False", "kernels": []}
{"iteration": 2751, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.85|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-19", "kernels": []}
{"iteration": 2752, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2753, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:526|parameter:1:int:8", "kernels": []}
{"iteration": 2754, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.81|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2755, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:551|parameter:1:int:8", "kernels": []}
{"iteration": 2756, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2757, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.65|input_signature:list:len3|parameter:0:int:496|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2758, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-63.00|input_signature:list:len3|parameter:0:int:467|parameter:1:int:12", "kernels": []}
{"iteration": 2759, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2760, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.78|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2761, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.14|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2762, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:49|parameter:1:int:8", "kernels": []}
{"iteration": 2763, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2764, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-2.63|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-32", "kernels": []}
{"iteration": 2765, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:reflect|parameter:1:int:8", "kernels": []}
{"iteration": 2766, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2767, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2768, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:7", "kernels": []}
{"iteration": 2769, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-117|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2770, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2771, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2772, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2773, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:1|parameter:1:int:-23", "kernels": []}
{"iteration": 2774, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:1|parameter:1:int:8", "kernels": []}
{"iteration": 2775, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1024", "kernels": []}
{"iteration": 2776, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2777, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.61|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2778, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:15", "kernels": []}
{"iteration": 2779, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2780, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:504|parameter:1:int:-1024", "kernels": []}
{"iteration": 2781, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2782, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:467|parameter:1:int:1", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2783, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:532|parameter:1:int:8", "kernels": []}
{"iteration": 2784, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1", "kernels": []}
{"iteration": 2785, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-47|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2786, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-28", "kernels": []}
{"iteration": 2787, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.32|input_signature:list:len3|parameter:0:int:504|parameter:1:bool:False", "kernels": []}
{"iteration": 2788, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 2789, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-inf|input_signature:list:len3|parameter:0:int:508|parameter:1:int:67", "kernels": []}
{"iteration": 2790, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2791, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:47", "kernels": []}
{"iteration": 2792, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2793, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.14|input_signature:list:len3|parameter:0:int:563|parameter:1:int:8", "kernels": []}
{"iteration": 2794, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.18|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2795, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.12|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2796, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2797, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2798, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2799, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:551|parameter:1:int:8", "kernels": []}
{"iteration": 2800, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.12|input_signature:list:len3|parameter:0:int:489|parameter:1:int:-1", "kernels": []}
{"iteration": 2801, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2802, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-1024|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2803, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2804, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:28", "kernels": []}
{"iteration": 2805, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:529|parameter:1:int:21", "kernels": []}
{"iteration": 2806, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.21|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2807, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.91|input_signature:list:len3|parameter:0:int:512|parameter:1:int:58", "kernels": []}
{"iteration": 2808, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:21", "kernels": []}
{"iteration": 2809, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.68|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:False", "kernels": []}
{"iteration": 2810, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:7", "kernels": []}
{"iteration": 2811, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.29|input_signature:list:len3|parameter:0:int:512|parameter:1:float:nan", "kernels": []}
{"iteration": 2812, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-16", "kernels": []}
{"iteration": 2813, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:521|parameter:1:int:8", "kernels": []}
{"iteration": 2814, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-49", "kernels": []}
{"iteration": 2815, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-41", "kernels": []}
{"iteration": 2816, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2817, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2818, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:565|parameter:1:int:8", "kernels": []}
{"iteration": 2819, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:5.07|parameter:1:int:16", "kernels": []}
{"iteration": 2820, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 2821, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2822, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.08|input_signature:list:len3|parameter:0:float:63.00|parameter:1:int:8", "kernels": []}
{"iteration": 2823, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:42", "kernels": []}
{"iteration": 2824, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.35|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2825, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2826, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-9|input_signature:list:len3|parameter:0:int:483|parameter:1:int:8", "kernels": []}
{"iteration": 2827, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.21|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2828, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2829, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:-1024.00|parameter:1:int:8", "kernels": []}
{"iteration": 2830, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:449|parameter:1:int:8", "kernels": []}
{"iteration": 2831, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 2832, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:559|parameter:1:int:0", "kernels": []}
{"iteration": 2833, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:550|parameter:1:int:8", "kernels": []}
{"iteration": 2834, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2835, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2836, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:498|parameter:1:int:8", "kernels": []}
{"iteration": 2837, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:451|parameter:1:int:8", "kernels": []}
{"iteration": 2838, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2839, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:16|parameter:1:int:48", "kernels": []}
{"iteration": 2840, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:37", "kernels": []}
{"iteration": 2841, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:497|parameter:1:int:-99", "kernels": []}
{"iteration": 2842, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.15|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 2843, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.97|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2844, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:31", "kernels": []}
{"iteration": 2845, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:True|parameter:1:int:8", "kernels": []}
{"iteration": 2846, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:416|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2847, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 2848, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1004", "kernels": []}
{"iteration": 2849, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:-1.00|parameter:1:int:8", "kernels": []}
{"iteration": 2850, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.11|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2851, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2852, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:11", "kernels": []}
{"iteration": 2853, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.82|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2854, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2855, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-inf|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2856, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:416|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2857, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.97|input_signature:list:len3|parameter:0:bool:False|parameter:1:int:8", "kernels": []}
{"iteration": 2858, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-73", "kernels": []}
{"iteration": 2859, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-6.22|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2860, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:484|parameter:1:int:8", "kernels": []}
{"iteration": 2861, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.98|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2862, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:479|parameter:1:int:8", "kernels": []}
{"iteration": 2863, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:16", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2864, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2865, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2866, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1023|parameter:1:int:-55", "kernels": []}
{"iteration": 2867, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2868, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:560|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2869, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2870, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.76|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2871, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2872, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2873, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1", "kernels": []}
{"iteration": 2874, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:519|parameter:1:int:-2", "kernels": []}
{"iteration": 2875, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:563|parameter:1:int:59", "kernels": []}
{"iteration": 2876, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2877, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:True", "kernels": []}
{"iteration": 2878, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-20", "kernels": []}
{"iteration": 2879, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.40|input_signature:list:len3|parameter:0:int:512|parameter:1:str:circular", "kernels": []}
{"iteration": 2880, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 2881, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:534|parameter:1:int:-31", "kernels": []}
{"iteration": 2882, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2883, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:-1024|parameter:1:int:8", "kernels": []}
{"iteration": 2884, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.23|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2885, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-24", "kernels": []}
{"iteration": 2886, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2887, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2888, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2889, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2890, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 2891, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:False|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2892, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:515|parameter:1:bool:True", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2893, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2894, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2895, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:561|parameter:1:int:8", "kernels": []}
{"iteration": 2896, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2897, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 2898, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:-inf|parameter:1:int:16", "kernels": []}
{"iteration": 2899, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, std::array<char*, 1ul> >(int, at::native::FillFunctor<float>, std::array<char*, 1ul>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})"]}
{"iteration": 2900, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:7", "kernels": []}
{"iteration": 2901, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.02|input_signature:list:len3|parameter:0:int:512|parameter:1:int:1", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2902, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.65|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2903, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:96|input_signature:list:len3|parameter:0:int:525|parameter:1:str:max", "kernels": []}
{"iteration": 2904, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:5", "kernels": []}
{"iteration": 2905, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:522|parameter:1:int:55", "kernels": []}
{"iteration": 2906, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2907, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.35|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2908, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:460|parameter:1:int:8", "kernels": []}
{"iteration": 2909, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:494|parameter:1:int:8", "kernels": []}
{"iteration": 2910, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-7", "kernels": []}
{"iteration": 2911, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:495|parameter:1:str:max", "kernels": []}
{"iteration": 2912, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1024.00|input_signature:list:len3|parameter:0:str:zeros|parameter:1:int:8", "kernels": []}
{"iteration": 2913, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2914, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:sum", "kernels": []}
{"iteration": 2915, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2916, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:11", "kernels": []}
{"iteration": 2917, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-1", "kernels": []}
{"iteration": 2918, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:False", "kernels": []}
{"iteration": 2919, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:542|parameter:1:int:8", "kernels": []}
{"iteration": 2920, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Activity Buffer Request", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2921, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:453|parameter:1:int:1024", "kernels": []}
{"iteration": 2922, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:str:max|parameter:1:int:8", "kernels": []}
{"iteration": 2923, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2924, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-16", "kernels": []}
{"iteration": 2925, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2926, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:2.87|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 2927, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2928, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)"]}
{"iteration": 2929, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:31", "kernels": []}
{"iteration": 2930, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:475|parameter:1:int:8", "kernels": []}
{"iteration": 2931, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2932, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:str:max", "kernels": []}
{"iteration": 2933, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2934, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:471|parameter:1:int:8", "kernels": []}
{"iteration": 2935, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.78|input_signature:list:len3|parameter:0:int:-46|parameter:1:int:8", "kernels": []}
{"iteration": 2936, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:472|parameter:1:int:68", "kernels": []}
{"iteration": 2937, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-56", "kernels": []}
{"iteration": 2938, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:13", "kernels": []}
{"iteration": 2939, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:529|parameter:1:int:43", "kernels": []}
{"iteration": 2940, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2941, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2942, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:14", "kernels": []}
{"iteration": 2943, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-5", "kernels": []}
{"iteration": 2944, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:485|parameter:1:int:8", "kernels": []}
{"iteration": 2945, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:576|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2946, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2947, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:7", "kernels": []}
{"iteration": 2948, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.34|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2949, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2950, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:560|parameter:1:int:-6", "kernels": []}
{"iteration": 2951, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:7", "kernels": []}
{"iteration": 2952, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-63", "kernels": []}
{"iteration": 2953, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2954, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:543|parameter:1:int:-55", "kernels": []}
{"iteration": 2955, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:6", "kernels": []}
{"iteration": 2956, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:nan|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2957, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:470|parameter:1:bool:False", "kernels": []}
{"iteration": 2958, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:60", "kernels": []}
{"iteration": 2959, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-37", "kernels": []}
{"iteration": 2960, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2961, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-3.80|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2962, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["void gemmSN_NN_kernel<float, 128, 2, 4, 8, 5, 4, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 10, 11, false, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float> >(cublasGemmSmallNParams<cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float const>, cublasGemvTensorStridedBatched<float>, float>)", "cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2963, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:bool:False|parameter:1:str:max", "kernels": []}
{"iteration": 2964, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:float:100000000000000000000.00|parameter:1:int:8", "kernels": []}
{"iteration": 2965, "strategy": "random", "source": "random", "valid": true, "features": "dropout:int:-8|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2966, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:494|parameter:1:int:8", "kernels": []}
{"iteration": 2967, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2968, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:bool:False", "kernels": []}
{"iteration": 2969, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-2", "kernels": []}
{"iteration": 2970, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2971, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:float:63.00", "kernels": []}
{"iteration": 2972, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:38", "kernels": []}
{"iteration": 2973, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": []}
{"iteration": 2974, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:43", "kernels": []}
{"iteration": 2975, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:-52", "kernels": []}
{"iteration": 2976, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1024.00|input_signature:list:len3|parameter:0:int:555|parameter:1:int:8", "kernels": []}
{"iteration": 2977, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.19|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2978, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
{"iteration": 2979, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-1.71|input_signature:list:len3|parameter:0:float:nan|parameter:1:int:36", "kernels": []}
{"iteration": 2980, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:1024.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2981, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:16|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2982, "strategy": "random", "source": "random", "valid": true, "features": "dropout:str:max|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2983, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.55|input_signature:list:len3|parameter:0:int:16|parameter:1:int:8", "kernels": []}
{"iteration": 2984, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2985, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:71", "kernels": []}
{"iteration": 2986, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:43", "kernels": []}
{"iteration": 2987, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:486|parameter:1:int:8", "kernels": []}
{"iteration": 2988, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:559|parameter:1:int:46", "kernels": []}
{"iteration": 2989, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:63.00|input_signature:list:len3|parameter:0:int:512|parameter:1:int:13", "kernels": []}
{"iteration": 2990, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:3.93|input_signature:list:len3|parameter:0:int:512|parameter:1:int:43", "kernels": []}
{"iteration": 2991, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:100000000000000000000.00|input_signature:list:len3|parameter:0:int:454|parameter:1:int:-1024", "kernels": []}
{"iteration": 2992, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:488|parameter:1:int:8", "kernels": ["Activity Buffer Request", "cudaDeviceSynchronize", "cudaStreamSynchronize"]}
{"iteration": 2993, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-0.74|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "ampere_sgemm_128x128_nn", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamSynchronize", "cudaDeviceSynchronize"]}
{"iteration": 2994, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:23", "kernels": []}
{"iteration": 2995, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "cudaStreamIsCapturing"]}
{"iteration": 2996, "strategy": "random", "source": "random", "valid": true, "features": "dropout:bool:True|input_signature:list:len3|parameter:0:int:452|parameter:1:int:8", "kernels": []}
{"iteration": 2997, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:0.10|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["ampere_sgemm_32x128_tn", "Memset (Device)", "ampere_sgemm_128x128_tn", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 5, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "cudaStreamSynchronize", "cudaStreamIsCapturing", "cudaDeviceSynchronize", "cudaLaunchKernel", "ampere_sgemm_128x128_nn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4, 4>)", "Activity Buffer Request", "cudaMemsetAsync", "void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})", "void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)"]}
{"iteration": 2998, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:-63.00|input_signature:list:len3|parameter:0:int:455|parameter:1:int:8", "kernels": []}
{"iteration": 2999, "strategy": "random", "source": "random", "valid": true, "features": "dropout:float:64.55|input_signature:list:len3|parameter:0:int:512|parameter:1:int:8", "kernels": ["cudaLaunchKernel", "void (anonymous namespace)::softmax_warp_forward<float, float, float, 4, false, false>(float*, float const*, int, int, int, bool const*, int, bool)", "ampere_sgemm_32x128_tn", "void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, std::array<char*, 2ul>)", "Memset (Device)", "ampere_sgemm_128x128_tn", "Activity Buffer Request", "cudaMemsetAsync", "cudaOccupancyMaxActiveBlocksPerMultiprocessor", "cudaStreamSynchronize", "ampere_sgemm_64x32_sliced1x4_tn", "cudaDeviceSynchronize"]}
